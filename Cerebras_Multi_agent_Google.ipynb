{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCSzTxEdx6mnsKWCzFStnn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrangayyan6/GenAI/blob/main/Cerebras_Multi_agent_Google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using AI to Streamline Research for Content Creation\n",
        "## The Problem\n",
        "Content creators, researchers, and marketers face a significant challenge when developing comprehensive material on specialized topics. The traditional research process is both time-consuming and labor-intensive:\n",
        "\n",
        "They must formulate effective search queries\n",
        "Sift through numerous search results manually\n",
        "Evaluate the relevance and credibility of sources\n",
        "Extract and organize key information\n",
        "Synthesize findings into coherent content\n",
        "Repeat this process multiple times to fill knowledge gaps\n",
        "\n",
        "This workflow can take hours or even days, delaying content production and limiting the number of topics a team can cover effectively. For small teams or individual creators without research assistants, this bottleneck severely impacts productivity.\n",
        "\n",
        "## The AI Solution\n",
        "Generative AI, as demonstrated in the code you shared, can transform this process through automated research assistance:\n",
        "\n",
        "- Query Optimization: The AI refines user queries to match search engine algorithms for better results (as shown in the format_search method)\n",
        "- Automated Information Gathering: Instead of manual searching, the AI conducts multiple search queries and aggregates the results\n",
        "- Intelligent Gap Analysis: The system evaluates the completeness of research and automatically identifies missing information (via the EditorAgent)\n",
        "- Iterative Research: The AI conducts multiple rounds of research until sufficient information is gathered, targeting different aspects of the topic with each iteration\n",
        "- Content Synthesis: When research is complete, the AI transforms raw research into well-structured content (via the WriterAgent)\n",
        "\n",
        "## Real-World Impact\n",
        "This AI-powered research workflow reduces what might take hours into minutes. Content creators can focus on refining and adding their unique perspective to AI-generated drafts rather than spending time on initial research and organization.\n",
        "The solution is particularly valuable for:\n",
        "\n",
        "- Marketing teams needing to create content across multiple product lines\n",
        "- Researchers exploring new domains quickly\n",
        "- Educational content creators covering diverse topics\n",
        "- Small businesses without dedicated research staff\n",
        "\n",
        "By increasing the number of search results (as you've requested), the system becomes even more effective, gathering a wider range of perspectives and information in each research iteration."
      ],
      "metadata": {
        "id": "YNwBFnJIAZAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Agentic Workflow with Cerebras, Google, LangChain and LangGraph\n",
        "\n",
        "Got early access to Meta’s latest model, Llama 4, running at 2611 tok/s, the fastest inference speed available at [cloud.cerebras.ai](https://cloud.cerebras.ai) and trying it out in this notebook.\n",
        "\n",
        "https://inference-docs.cerebras.ai/introduction"
      ],
      "metadata": {
        "id": "pcJCR3AFo7JW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cerebras API Key\n",
        "Get Cerebras API key at https://cloud.cerebras.ai/\n",
        "\n",
        "# LangChain key\n",
        "Follow steps in\n",
        "https://docs.smith.langchain.com/administration/how_to_guides/organization_management/create_account_api_key\n",
        "\n",
        "# Setting up Google Search API Credentials\n",
        "\n",
        "Before running the main code, you need to set up your Google Search API credentials:\n",
        "\n",
        "## Step 1: Get a Google API Key\n",
        "1. Go to the [Google Cloud Console](https://console.cloud.google.com/)\n",
        "2. Create a new project or select an existing one\n",
        "3. Enable the \"Custom Search API\" for your project\n",
        "4. Go to \"Credentials\" and create an API key\n",
        "\n",
        "## Step 2: Create a Programmable Search Engine\n",
        "1. Go to [Programmable Search Engine](https://programmablesearchengine.google.com/about/)\n",
        "2. Click \"Create a Programmable Search Engine\"\n",
        "3. Configure your search engine (you can search the entire web)\n",
        "4. After creation, find your \"Search engine ID\" (also called CSE ID)\n"
      ],
      "metadata": {
        "id": "4M2uZGPVrli0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_cerebras langchain_community langgraph langchain langchain-core langsmith langchain_experimental cerebras_cloud_sdk langchain-google-community google-search-results requests beautifulsoup4\n"
      ],
      "metadata": {
        "id": "FzQsjDvbrU4W"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wDczmKZko6NB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langgraph.graph import END\n",
        "from langchain_cerebras import ChatCerebras\n",
        "\n",
        "from google.colab import userdata\n",
        "from IPython.display import Markdown\n",
        "from typing import List, Dict, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure API Keys\n",
        "Add API keys in Secrets (left menu)"
      ],
      "metadata": {
        "id": "uGX1fbvpQ7Yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure these are set BEFORE creating any search wrappers\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = userdata.get('GOOGLE_CSE_ID')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLESEARCH_API_KEY')\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "api_key = userdata.get('CEREBRAS_API_KEY')"
      ],
      "metadata": {
        "id": "NcXxzRSVMS5M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enable Tracing\n",
        "\n",
        "LangChain offers an optional tracing feature that helps in debugging complex chains and workflows."
      ],
      "metadata": {
        "id": "j-0wD_8VRPMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add tracing in LangSmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
      ],
      "metadata": {
        "id": "8Y9vOq6aMcwu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Data Storage\n",
        "\n",
        "We initialize a simple in-memory list to store results from the agent workflow:"
      ],
      "metadata": {
        "id": "6xeOxRJXRcIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_result = []"
      ],
      "metadata": {
        "id": "l_7RgE4VMkBO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Shared State\n",
        "\n",
        "We use a TypedDict class to define and track the shared state between agents. This makes it easier to debug and enforce consistency."
      ],
      "metadata": {
        "id": "yZj4pEKHRgc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    query: Annotated[list, add_messages]\n",
        "    url: Annotated[list, add_messages]\n",
        "    index: int\n",
        "    research: Annotated[list, add_messages]\n",
        "    content: str\n",
        "    content_ready: bool\n",
        "    iteration_count: int     # Counter for iterations"
      ],
      "metadata": {
        "id": "hIZgiJzrMw95"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the Language Model\n",
        "\n",
        "We use Google's Gemini model via LangChain’s wrapper."
      ],
      "metadata": {
        "id": "-9Cw5huHRoiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ChatCerebras instance for language model\n",
        "llm = ChatCerebras(api_key=api_key, model=\"llama-4-scout-17b-16e-instruct\")"
      ],
      "metadata": {
        "id": "MUIM9VB7M1DE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Research Agent\n",
        "\n",
        "format_search(): Uses Gemini to transform natural queries into more search-optimized forms.\n",
        "\n",
        "search(): Executes a search via GoogleSearchRun and stores results in state.\n",
        "\n",
        "🔁 Iteration results are logged in final_result for each loop of query → search."
      ],
      "metadata": {
        "id": "Bf8n1Z0GRwod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "from langchain_google_community import GoogleSearchRun\n",
        "from langchain_core.messages import HumanMessage\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "class ResearchAgent:\n",
        "    def format_search(self, query: str) -> str:\n",
        "        prompt = (\n",
        "            \"You are an expert at optimizing search queries for Google. \"\n",
        "            \"Your task is to take a given query and return an optimized version of it, making it more likely to yield relevant results. \"\n",
        "            \"Do not include any explanations or extra text, only the optimized query.\\n\\n\"\n",
        "            \"Example:\\n\"\n",
        "            \"Original: best laptop 2023 for programming\\n\"\n",
        "            \"Optimized: top laptops 2023 for coding\\n\\n\"\n",
        "            \"Example:\\n\"\n",
        "            \"Original: how to train a puppy not to bite\\n\"\n",
        "            \"Optimized: puppy training tips to prevent biting\\n\\n\"\n",
        "            \"Now optimize the following query:\\n\"\n",
        "            f\"Original: {query}\\n\"\n",
        "            \"Optimized:\"\n",
        "        )\n",
        "\n",
        "        response = llm.invoke(prompt)\n",
        "        return response.content\n",
        "\n",
        "    def fetch_full_content(self, url: str) -> str:\n",
        "        try:\n",
        "            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'}\n",
        "            response = requests.get(url, headers=headers, timeout=30)\n",
        "            response.raise_for_status()  # Raise an exception for bad status codes\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            # Extract text content - you might need to adjust the selectors\n",
        "            text_parts = soup.find_all('p')  # Example: get all paragraph text\n",
        "            full_text = \"\\n\".join([part.get_text() for part in text_parts])\n",
        "            if full_text==\"\":\n",
        "                full_text = soup.get_text()[:5000]\n",
        "            return f\"{full_text[:5000]} \" # Limit content length\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            return f\"URL: {url}\\nError fetching content: {e}\"\n",
        "        except Exception as e:\n",
        "            return f\"URL: {url}\\nError parsing content: {e}\"\n",
        "\n",
        "    def search(self, state: State):    #  -> Dict[str, List[HumanMessage]]\n",
        "        google_search = GoogleSearchAPIWrapper(k=10)\n",
        "        optimized_query = self.format_search(state.get('query', \"\")[-1].content)\n",
        "        # state[\"query\"] = optimized_query\n",
        "        raw_results = google_search.results(optimized_query, 1)\n",
        "        # print(\"Raw results: \", raw_results)\n",
        "        # search_results: List[HumanMessage] = []\n",
        "\n",
        "        index = state.get(\"index\", 1)\n",
        "        # print(\"search - index: \", index, \"\\n\")\n",
        "        if index is None:\n",
        "            index = 0\n",
        "\n",
        "        if raw_results and raw_results[0].get('link'):\n",
        "            url = raw_results[0]['link']\n",
        "            # print(\"search - url: \",url,\"\\n\")\n",
        "            full_content = self.fetch_full_content(url)\n",
        "            # print(\"search - full_content: \",full_content,\"\\n\")\n",
        "            time.sleep(1) # Be respectful of website rate limits\n",
        "        else:\n",
        "            full_content = \"No content found\"\n",
        "            url = \"No url found\"\n",
        "\n",
        "        final_result.append({\"subheader\": f\"Research Iteration\", \"content\": [raw_results], \"time\": time.perf_counter() - time.perf_counter()}) # Correct the time calculation\n",
        "\n",
        "        return {\"research\": full_content, \"url\": url, \"query\": optimized_query, \"index\": index+1}\n"
      ],
      "metadata": {
        "id": "33OiBjGMM4Tq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Editor Agent\n",
        "Uses Gemini to inspect accumulated research.\n",
        "\n",
        "If results are sufficient, it sets content_ready = True.\n",
        "\n",
        "If insufficient, it generates a new improved query and continues the loop.\n",
        "\n",
        "🔐 Includes a hard limit of 10 iterations to prevent infinite loops."
      ],
      "metadata": {
        "id": "Dai5xIyxR53Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EditorAgent:\n",
        "    def evaluate_research(self, state: State):\n",
        "        query = '\\n'.join(message.content for message in state.get(\"query\"))\n",
        "        research_content = \"\\n\".join([message.content for message in state.get(\"research\")])\n",
        "        # print(\"Editor Agent - research_content: \", research_content, \"\\n\")\n",
        "        # print(\"Editor Agent - query: \", query, \"\\n\")\n",
        "\n",
        "        iteration_count = state.get(\"iteration_count\", 1)\n",
        "\n",
        "        if iteration_count is None:\n",
        "            iteration_count = 1\n",
        "\n",
        "        if iteration_count >= 3:\n",
        "            return {\"content_ready\": True}\n",
        "\n",
        "        prompt = (\n",
        "            \"You are an expert editor. Your task is to evaluate the research based on the query. \"\n",
        "            \"If the information is sufficient to create a comprehensive and accurate blog post, respond with 'sufficient'. \"\n",
        "            \"If the information is not sufficient, respond with 'insufficient' and provide a new, creative query suggestion to improve the results. \"\n",
        "            \"If the research results appear repetitive or not diverse enough, think about a very different kind of question that could yield more varied and relevant information. \"\n",
        "            \"Consider the depth, relevance, and completeness of the information when making your decision.\\n\\n\"\n",
        "            \"Example 1:\\n\"\n",
        "            \"Used queries: What are the benefits of a Mediterranean diet?\\n\"\n",
        "            \"Research: The Mediterranean diet includes fruits, vegetables, whole grains, and healthy fats.\\n\"\n",
        "            \"Evaluation: Insufficient\\n\"\n",
        "            \"New query: Detailed health benefits of a Mediterranean diet\\n\\n\"\n",
        "            \"Example 2:\\n\"\n",
        "            \"Used queries: How does solar power work?\\n\"\n",
        "            \"Research: Solar power works by converting sunlight into electricity using photovoltaic cells.\\n\"\n",
        "            \"Evaluation: Sufficient\\n\\n\"\n",
        "            \"Example 3:\\n\"\n",
        "            \"Used queries: Effects of climate change on polar bears?\\n\"\n",
        "            \"Research: Climate change is reducing sea ice, affecting polar bear habitats.\\n\"\n",
        "            \"Evaluation: Insufficient\\n\"\n",
        "            \"New query: How are polar bears adapting to the loss of sea ice due to climate change?\\n\\n\"\n",
        "            \"Now evaluate the following:\\n\"\n",
        "            f\"Used queries: {query}\\n\"\n",
        "            f\"Research: {research_content}\\n\\n\"\n",
        "            \"Evaluation (sufficient/insufficient):\\n\"\n",
        "            \"New query (if insufficient):\"\n",
        "        )\n",
        "\n",
        "        # print(\"Editor Agent - Prompt: \", prompt, \"\\n\")\n",
        "        start_time = time.perf_counter()\n",
        "        response = llm.invoke(prompt)\n",
        "        end_time = time.perf_counter()\n",
        "\n",
        "        evaluation = response.content.strip()\n",
        "\n",
        "        final_result.append({\"subheader\": f\"Editor Evaluation Iteration\", \"content\": evaluation, \"time\": end_time - start_time})\n",
        "\n",
        "        if \"new query:\" in evaluation.lower():\n",
        "            new_query = evaluation.split(\"New query:\", 1)[-1].strip()\n",
        "            return {\"query\": [new_query], \"iteration_count\": iteration_count + 1, \"evaluation\": evaluation}\n",
        "        else:\n",
        "            return {\"content_ready\": True, \"evaluation\": evaluation}\n"
      ],
      "metadata": {
        "id": "74eyzTO0M_d-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writer Agent\n",
        "Combines query and research into a single blog post.\n",
        "\n",
        "Uses Gemini to generate detailed, structured content (intro, body, conclusion)."
      ],
      "metadata": {
        "id": "UulIO80sSB7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WriterAgent:\n",
        "    def write_blogpost(self, state: Dict) -> Dict[str, str]:\n",
        "        # Handle query access more safely\n",
        "        query = state.get(\"query\", [\"\"])[0].content if isinstance(state.get(\"query\", [\"\"]), list) else state.get(\"query\", \"\")\n",
        "\n",
        "        # Safely handle research messages - check for both keys\n",
        "        indexes = state.get('iteration_count')\n",
        "        context = \"\\n\".join([f\"[{i+1}] {message.content} \\n\" for i, message in enumerate(state.get(\"research\", []))])\n",
        "        references = \"\\n\".join([f\"[{i+1}] {message.content} \\n\" for i, message in enumerate(state.get(\"url\", []))])\n",
        "\n",
        "\n",
        "        # print(\"WriterAgent - Query: \", query)\n",
        "        # print(\"WriterAgent - context: \", context)\n",
        "        # print(\"WriterAgent - references: \", references)\n",
        "        # print(\"WriterAgent - Indexes: \", indexes)\n",
        "\n",
        "\n",
        "        prompt = (\n",
        "            \"You are an expert blog post writer. Your task is to take a given query and context, and write a comprehensive, engaging, and informative short blog post about it. \"\n",
        "            \"Make sure to include an introduction, main body with detailed information, and a conclusion. Use a friendly and accessible tone, and ensure the content is well-structured and easy to read. \"\n",
        "            \"Cite the sources you used by referring to the number in the square brackets with References section at the bottom of the blog post.\"\n",
        "            \"Do not add anything other content not in the sources.\\n\\n\"\n",
        "            f\"Query: {query}\\n\\n\"\n",
        "            f\"Context:\\n{context}\\n\\n\"\n",
        "            f\"**References:**\\n{references}\"\n",
        "            \"Write a detailed and engaging blog post based on the above query and context.\"\n",
        "        )\n",
        "        # print(\"Prompt: \", prompt, \"\\n*****Prompt********\")\n",
        "        response = llm.invoke(prompt)\n",
        "\n",
        "        return {\"content\": response.content}"
      ],
      "metadata": {
        "id": "2ML1J5bTNIbp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the LangGraph\n",
        "🔄 This creates a loop between search_agent → editor_agent → (search or writer)."
      ],
      "metadata": {
        "id": "mMxi44PDSI0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the StateGraph\n",
        "graph = StateGraph(State)\n",
        "\n",
        "research_agent = ResearchAgent()\n",
        "writer_agent = WriterAgent()\n",
        "editor_agent = EditorAgent()\n",
        "\n",
        "graph.add_node(\"search_agent\", research_agent.search)\n",
        "graph.add_node(\"writer_agent\", writer_agent.write_blogpost)\n",
        "graph.add_node(\"editor_agent\", editor_agent.evaluate_research)\n",
        "\n",
        "graph.set_entry_point(\"search_agent\")\n",
        "\n",
        "graph.add_edge(\"search_agent\", \"editor_agent\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"editor_agent\",\n",
        "    lambda state: \"accept\" if state.get(\"content_ready\") else \"revise\",\n",
        "    {\n",
        "        \"accept\": \"writer_agent\",\n",
        "        \"revise\": \"search_agent\"\n",
        "    }\n",
        ")\n",
        "\n",
        "graph.add_edge(\"writer_agent\", END)\n",
        "\n",
        "graph = graph.compile()"
      ],
      "metadata": {
        "id": "lACVJ1PnqH6y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Invocation Function\n",
        "This function:\n",
        "\n",
        "Starts the LangGraph with the user’s query\n",
        "\n",
        "Automatically loops through agents until content_ready\n",
        "\n",
        "Returns the final blog post"
      ],
      "metadata": {
        "id": "yKHYOCAVSRTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invoke_graph(user_prompt):\n",
        "    start_time = time.perf_counter()\n",
        "    result = graph.invoke({\"query\": user_prompt})\n",
        "    end_time = time.perf_counter()\n",
        "    print(\"\\n\\n\")\n",
        "    print(f\"Total time: {end_time - start_time} seconds\")\n",
        "    print(\"\\n\\n\")\n",
        "    return result[\"content\"]"
      ],
      "metadata": {
        "id": "Tn5Ep7KaNU8c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Provide your prompt below"
      ],
      "metadata": {
        "id": "I7ggYONsq7ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Act as an expert in Financial Services, explain in detail on separately managed accounts using 5000 words or more.\""
      ],
      "metadata": {
        "id": "NT_Nwfuz6Y10"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# View response\n",
        "You will see the Google search results in the first section, and the blogpost generated in the next."
      ],
      "metadata": {
        "id": "Zm7pifmhQVuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(invoke_graph(user_prompt))"
      ],
      "metadata": {
        "id": "2KkYDObf8G0u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb49222d-67bc-44fe-d53c-d401fb71d7d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Total time: 6.738445214999956 seconds\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**The Power of Separately Managed Accounts: A Flexible and Tax-Efficient Investment Vehicle for High-Net-Worth Investors**\n\nAs a high-net-worth investor, selecting the right investment vehicle is crucial to achieving your financial goals. With various options available, it's essential to understand the benefits and drawbacks of each vehicle to make an informed decision. In this blog post, we'll delve into the world of separately managed accounts (SMAs), a popular investment vehicle among high-net-worth investors and family offices. We'll explore how SMAs work, their flexibility, tax efficiency, and liquidity, and why they may be an attractive option for investors seeking customization and control over their investments.\n\n**What is a Separately Managed Account (SMA)?**\n\nA separately managed account (SMA) is a single portfolio managed for one particular client, where the investor owns the securities directly [1]. This provides a critical benefit: flexibility. Unlike commingled funds, mutual funds, and exchange-traded funds (ETFs), where assets are pooled together and managed collectively, SMAs offer investors direct ownership of the underlying securities. This direct ownership enables investors to customize their portfolio to align with their personal values, risk tolerance, and investment objectives.\n\n**The Importance of Selecting the Right Investment Vehicle**\n\nWhen it comes to investing, high-net-worth investors and family offices often focus on selecting the right investment strategies, diversifying their portfolios, and integrating investment decisions with tax and estate planning. However, selecting the right investment vehicle often receives less attention, which can lead to unexpected taxes, increased costs, or limited flexibility [2]. The four primary investment vehicles available to investors are SMAs, commingled funds, mutual funds, and ETFs. Each vehicle has its advantages and disadvantages, and understanding these differences is crucial to making an informed decision.\n\n**Flexibility: A Key Benefit of SMAs**\n\nOne of the primary advantages of SMAs is their flexibility. Since investors own the securities directly, they have complete control over the holdings and can make changes as needed. This flexibility enables investors to:\n\n* Avoid overconcentration risk by excluding specific companies or industries\n* Customize their portfolio to align with their personal values and investment objectives\n* Make charitable contributions with appreciated stock\n\nIn contrast, commingled funds, mutual funds, and ETFs are pooled vehicles, where investors have limited control over the underlying holdings. These vehicles are best suited for investors who don't require customization or control over their investments.\n\n**Tax Efficiency: A Critical Consideration for High-Net-Worth Investors**\n\nFor high-net-worth investors, tax efficiency is a critical consideration. The difference between pre-tax and after-tax returns can be significant, and selecting the right investment vehicle can help minimize tax liabilities. SMAs are highly tax efficient due to their flexibility and direct ownership structure.\n\nUnlike mutual funds, which distribute gains to all investors, regardless of when they purchased the fund, SMAs enable investors to control taxable events. Investors can request that turnover be minimized or that capital losses be used to offset capital gains through tax-loss harvesting. Additionally, SMAs don't have embedded capital gains, which means investors are only taxed on realized gains achieved during the period they owned the securities.\n\n**Liquidity: A Key Consideration for Investors**\n\nLiquidity is another essential consideration for investors. SMAs and ETFs are the most liquid investment vehicles, as investors can quickly sell holdings to access cash. In contrast, mutual funds and commingled funds are less liquid, as purchases and redemptions occur only at the end of a trading day.\n\nWith SMAs, investors can work with their investment manager to sell holdings quickly, providing access to cash when needed. This liquidity is particularly important for high-net-worth investors who require flexibility and control over their investments.\n\n**Conclusion**\n\nSeparately managed accounts offer high-net-worth investors and family offices a flexible, tax-efficient, and liquid investment vehicle. With direct ownership of the underlying securities, SMAs provide investors with complete control over their portfolio, enabling them to customize their investments to align with their personal values and investment objectives. While SMAs require large minimum investments, their benefits make them an attractive option for investors seeking customization and control over their investments.\n\nIn conclusion, SMAs are a powerful investment vehicle that can help high-net-worth investors achieve their financial goals. By understanding the benefits and drawbacks of SMAs and other investment vehicles, investors can make informed decisions about their investments and select the vehicle that best meets their needs.\n\n**References:**\n\n[1] https://smartasset.com/investing/separately-managed-account\n\n[2] https://www.nepc.com/investment-vehicles-important-choice/"
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ygl9p60WIOuY"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}