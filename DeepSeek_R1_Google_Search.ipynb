{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "786c3b4a412747728662f0b238348b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28e754506837463ba25424b81263c6ec",
              "IPY_MODEL_95502982b22149c1a894a3fecacd7335",
              "IPY_MODEL_21ad291d56f2442281cb7a8845f4c31c"
            ],
            "layout": "IPY_MODEL_acaf6ce342a44983872b38b6d69e85a0"
          }
        },
        "28e754506837463ba25424b81263c6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b241373632d426b9a46638f2dc85c16",
            "placeholder": "​",
            "style": "IPY_MODEL_4feeb87ebeee4586bf2533a5d7b5efee",
            "value": "config.json: 100%"
          }
        },
        "95502982b22149c1a894a3fecacd7335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_537821bf61b649e083d2a98c41f08456",
            "max": 680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21c1f8a53d674d7a88f98831adbcdd01",
            "value": 680
          }
        },
        "21ad291d56f2442281cb7a8845f4c31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dab9ee74fb814f50bff1038b4b1a6c8d",
            "placeholder": "​",
            "style": "IPY_MODEL_f3a267adbc934ebfbc845cca04a84e36",
            "value": " 680/680 [00:00&lt;00:00, 53.9kB/s]"
          }
        },
        "acaf6ce342a44983872b38b6d69e85a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b241373632d426b9a46638f2dc85c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4feeb87ebeee4586bf2533a5d7b5efee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "537821bf61b649e083d2a98c41f08456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21c1f8a53d674d7a88f98831adbcdd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dab9ee74fb814f50bff1038b4b1a6c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3a267adbc934ebfbc845cca04a84e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7187a67dd124865a4967d1a78c197c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c16bb64aa4b4d4a8d97c29bb6c75ba7",
              "IPY_MODEL_b4d00889299e4e6bbbd6c0d06b32b63a",
              "IPY_MODEL_fd005cfd6dcc4b7ba0f1a6350e4c6414"
            ],
            "layout": "IPY_MODEL_12ab69b7c56141019cf0f0e91b4ec9aa"
          }
        },
        "6c16bb64aa4b4d4a8d97c29bb6c75ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_821ed867f2eb467ea257fa736a3e28fa",
            "placeholder": "​",
            "style": "IPY_MODEL_0b53c20adddd46ecbbd554b85135d59c",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "b4d00889299e4e6bbbd6c0d06b32b63a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62260aadfac34f8b98d69cac60e40759",
            "max": 28090,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b67618f0c0c4ed6bd31c3151b37836f",
            "value": 28090
          }
        },
        "fd005cfd6dcc4b7ba0f1a6350e4c6414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b32bfa065b514defab4d73988350af18",
            "placeholder": "​",
            "style": "IPY_MODEL_c6b91503178d44bab10d2c0b63ff8276",
            "value": " 28.1k/28.1k [00:00&lt;00:00, 2.02MB/s]"
          }
        },
        "12ab69b7c56141019cf0f0e91b4ec9aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821ed867f2eb467ea257fa736a3e28fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b53c20adddd46ecbbd554b85135d59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62260aadfac34f8b98d69cac60e40759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b67618f0c0c4ed6bd31c3151b37836f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b32bfa065b514defab4d73988350af18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6b91503178d44bab10d2c0b63ff8276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56754da7aff34923b1f3cb688c8f03b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7fbac93870e45e498f42b4fde54de30",
              "IPY_MODEL_2ea475dafea24ea38ddadbb4df6cfdf6",
              "IPY_MODEL_2d95739035d54f419f91cef170cfc122"
            ],
            "layout": "IPY_MODEL_8c1effdb78a24448a562b7f769cf51d0"
          }
        },
        "f7fbac93870e45e498f42b4fde54de30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2e042e2938f4a4e892be19ed93562ae",
            "placeholder": "​",
            "style": "IPY_MODEL_7631bbca8f464354a7324a52f9460a69",
            "value": "Downloading shards: 100%"
          }
        },
        "2ea475dafea24ea38ddadbb4df6cfdf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab0d1543f9cc4f82bc65aca5def866df",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14ee7bcdb1a24be286072f2de0eaa1d4",
            "value": 2
          }
        },
        "2d95739035d54f419f91cef170cfc122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0f75a51f1e4ebaa3f3cbdb1ee1ea0c",
            "placeholder": "​",
            "style": "IPY_MODEL_9443e995f25c46adbc49d21bbd2d8142",
            "value": " 2/2 [06:05&lt;00:00, 178.26s/it]"
          }
        },
        "8c1effdb78a24448a562b7f769cf51d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e042e2938f4a4e892be19ed93562ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7631bbca8f464354a7324a52f9460a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab0d1543f9cc4f82bc65aca5def866df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ee7bcdb1a24be286072f2de0eaa1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea0f75a51f1e4ebaa3f3cbdb1ee1ea0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9443e995f25c46adbc49d21bbd2d8142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a706b9d624e404c85c80ccc8d3bb6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd4372fbdaaf4c209ec11c89c6828e98",
              "IPY_MODEL_90fbd1d4b06249109a64b3ee5fee7f70",
              "IPY_MODEL_61b01c7c9e92481581fcc855b1b609fe"
            ],
            "layout": "IPY_MODEL_f3fdc997ff8542dc9a80e7134453f146"
          }
        },
        "cd4372fbdaaf4c209ec11c89c6828e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9676319e889f4798a01de533ae3e8dab",
            "placeholder": "​",
            "style": "IPY_MODEL_365faf994913416c8e6f0551d655cd67",
            "value": "model-00001-of-000002.safetensors: 100%"
          }
        },
        "90fbd1d4b06249109a64b3ee5fee7f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3410181d46d44a918a42146adb5c7c4d",
            "max": 8606596466,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_792c4940b599458099b7caf93edb1514",
            "value": 8606596466
          }
        },
        "61b01c7c9e92481581fcc855b1b609fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6079727ec50a420fb8d99685a603dcd7",
            "placeholder": "​",
            "style": "IPY_MODEL_7d79b69a63684847b59b802a0529fa7e",
            "value": " 8.61G/8.61G [03:26&lt;00:00, 43.4MB/s]"
          }
        },
        "f3fdc997ff8542dc9a80e7134453f146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9676319e889f4798a01de533ae3e8dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "365faf994913416c8e6f0551d655cd67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3410181d46d44a918a42146adb5c7c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "792c4940b599458099b7caf93edb1514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6079727ec50a420fb8d99685a603dcd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d79b69a63684847b59b802a0529fa7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec61005ce499442398efae0e69835da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09837fb995c54661b7831bcfc1744272",
              "IPY_MODEL_9acd36d17cd74688a1c6a20cd430978b",
              "IPY_MODEL_c8a27be6e27e43adbe582d4828572199"
            ],
            "layout": "IPY_MODEL_335e94068f7a4071857de8e317a7eec1"
          }
        },
        "09837fb995c54661b7831bcfc1744272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9884833da0564412b34b75f8ee1a816f",
            "placeholder": "​",
            "style": "IPY_MODEL_633e3ae9b4464b6ea926d393c53d718d",
            "value": "model-00002-of-000002.safetensors: 100%"
          }
        },
        "9acd36d17cd74688a1c6a20cd430978b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9106c4ecd93f41208a325c2dc7ace3d0",
            "max": 6624675384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8efc4ac0443d48caa2b830078b379402",
            "value": 6624675384
          }
        },
        "c8a27be6e27e43adbe582d4828572199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abbafe26f9e74226b6c562f85744f440",
            "placeholder": "​",
            "style": "IPY_MODEL_c1498f5512e746b0befe11aaca41246b",
            "value": " 6.62G/6.62G [02:37&lt;00:00, 43.1MB/s]"
          }
        },
        "335e94068f7a4071857de8e317a7eec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9884833da0564412b34b75f8ee1a816f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "633e3ae9b4464b6ea926d393c53d718d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9106c4ecd93f41208a325c2dc7ace3d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8efc4ac0443d48caa2b830078b379402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abbafe26f9e74226b6c562f85744f440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1498f5512e746b0befe11aaca41246b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c5e32f4e1c34803b08bcd03d7da20c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6050977cd81468bb66b14a59b10e425",
              "IPY_MODEL_d930f18e144e42eaae0a66b2782983ab",
              "IPY_MODEL_e013aa0fd3d04793ac16ba01dcdd9eb7"
            ],
            "layout": "IPY_MODEL_77872cece8f743cf9b6611895765e86b"
          }
        },
        "b6050977cd81468bb66b14a59b10e425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_271ddae54dde426abf5e8cacc0c5bfa9",
            "placeholder": "​",
            "style": "IPY_MODEL_ef1f31753a7647faa7d22aabbfe09866",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d930f18e144e42eaae0a66b2782983ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f1e8f2859654d5ba209ffe8922274d0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1f53898066a4d11b8900bf3552a68ff",
            "value": 2
          }
        },
        "e013aa0fd3d04793ac16ba01dcdd9eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e24ed1b4fd8f4d52ace574cc7d719c10",
            "placeholder": "​",
            "style": "IPY_MODEL_d1687343c78a4e10b04cae3d0e168d9b",
            "value": " 2/2 [00:08&lt;00:00,  4.22s/it]"
          }
        },
        "77872cece8f743cf9b6611895765e86b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "271ddae54dde426abf5e8cacc0c5bfa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef1f31753a7647faa7d22aabbfe09866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f1e8f2859654d5ba209ffe8922274d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f53898066a4d11b8900bf3552a68ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e24ed1b4fd8f4d52ace574cc7d719c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1687343c78a4e10b04cae3d0e168d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa1c754f40dd4ec6ac2a7e5edbc8f0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae7a153b183c4614955932a959b7e5da",
              "IPY_MODEL_eef343662d3249c096b182b2250e68b2",
              "IPY_MODEL_34a84fa38115475c800a65992590c42e"
            ],
            "layout": "IPY_MODEL_9781a6c12224415ebb792b4cdc71fa4e"
          }
        },
        "ae7a153b183c4614955932a959b7e5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a740b167aaa4ff1a9e4a61a475741b7",
            "placeholder": "​",
            "style": "IPY_MODEL_55db18e43228497198dfc0b6535bf7d2",
            "value": "generation_config.json: 100%"
          }
        },
        "eef343662d3249c096b182b2250e68b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e108485fdfaa4ca9a0ee29e81d3ef8c5",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c362dc47d42543e7bbfb9152073dc1ea",
            "value": 181
          }
        },
        "34a84fa38115475c800a65992590c42e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4a25a8864cb4293b0288ef86e058bc5",
            "placeholder": "​",
            "style": "IPY_MODEL_8eb60877815e470281d8cb320b6ecf96",
            "value": " 181/181 [00:00&lt;00:00, 15.8kB/s]"
          }
        },
        "9781a6c12224415ebb792b4cdc71fa4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a740b167aaa4ff1a9e4a61a475741b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55db18e43228497198dfc0b6535bf7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e108485fdfaa4ca9a0ee29e81d3ef8c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c362dc47d42543e7bbfb9152073dc1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4a25a8864cb4293b0288ef86e058bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eb60877815e470281d8cb320b6ecf96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "815d2182c47c4a82ad99e35dfd2a22c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_662fe13e2a914d549bbe9d865af4d0c1",
              "IPY_MODEL_49976adff63642a2a16bcb73035c1b3f",
              "IPY_MODEL_d8cdf6afcfcd41108284238f7e8ddecd"
            ],
            "layout": "IPY_MODEL_561a8c6ccc9b4b058d0e6745e5f6b374"
          }
        },
        "662fe13e2a914d549bbe9d865af4d0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea5803f62ce34fdbb19d73e4c00510ed",
            "placeholder": "​",
            "style": "IPY_MODEL_bda8d19fa84c40de8776b1bb6906f6b5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "49976adff63642a2a16bcb73035c1b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa685ca4eb3d4f18922eb28b2ec33480",
            "max": 3071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e0d581dab2644fdbc896219d474e8ef",
            "value": 3071
          }
        },
        "d8cdf6afcfcd41108284238f7e8ddecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64a2ad0da6684b93b08e4c7ef67d5fd4",
            "placeholder": "​",
            "style": "IPY_MODEL_33f04e094bb54d9a82ac3e80a9d55b84",
            "value": " 3.07k/3.07k [00:00&lt;00:00, 287kB/s]"
          }
        },
        "561a8c6ccc9b4b058d0e6745e5f6b374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea5803f62ce34fdbb19d73e4c00510ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda8d19fa84c40de8776b1bb6906f6b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa685ca4eb3d4f18922eb28b2ec33480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e0d581dab2644fdbc896219d474e8ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64a2ad0da6684b93b08e4c7ef67d5fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33f04e094bb54d9a82ac3e80a9d55b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "883ec6e9cbf94b2aae217e54d0099501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_475cbdf9babc45ef86f928e429864733",
              "IPY_MODEL_bfdab4ce1b2b48c0ab9e4dc6a220fa70",
              "IPY_MODEL_bee02868fa604f1083b964caf751748e"
            ],
            "layout": "IPY_MODEL_f6f414fafdb344718fd0453706e66a4b"
          }
        },
        "475cbdf9babc45ef86f928e429864733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d02d2629cc4e55bf6e693aa7611a30",
            "placeholder": "​",
            "style": "IPY_MODEL_859db5a864b14f71819333ba911271ce",
            "value": "tokenizer.json: 100%"
          }
        },
        "bfdab4ce1b2b48c0ab9e4dc6a220fa70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f92615f52574d9b9589c64b89fce4c8",
            "max": 7031660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f037cde48304f3397fd4c1dbe2a16a9",
            "value": 7031660
          }
        },
        "bee02868fa604f1083b964caf751748e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_691b706c4360488f9cd0f13c3ef84227",
            "placeholder": "​",
            "style": "IPY_MODEL_9e876be3a0e94e0d90b8b4c5c5561fa4",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 10.6MB/s]"
          }
        },
        "f6f414fafdb344718fd0453706e66a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d02d2629cc4e55bf6e693aa7611a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "859db5a864b14f71819333ba911271ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f92615f52574d9b9589c64b89fce4c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f037cde48304f3397fd4c1dbe2a16a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "691b706c4360488f9cd0f13c3ef84227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e876be3a0e94e0d90b8b4c5c5561fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrangayyan6/GenAI/blob/main/DeepSeek_R1_Google_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face DeepSeek R1 grounded with Google Search results\n",
        "\n",
        "Using DeepSeek-R1-Distill-Qwen-7B model from Hugging Face and 4-bit quantization\n",
        "\n",
        "Need L4 GPU\n",
        "\n",
        "Reference:\n",
        "- https://huggingface.co/deepseek-ai/DeepSeek-R1#deepseek-r1-distill-models\n",
        "- https://colab.research.google.com/drive/1r9GOGEmjtZZbcCXjiwNHj0jsMFp0l8Ok?usp=sharing"
      ],
      "metadata": {
        "id": "NLSjarkL-f1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Install the needed libraries\n",
        "# Avoiding versions mismatch\n",
        "!pip install -q accelerate==0.29.3\n",
        "!pip install -q bitsandbytes==0.43.1\n",
        "!pip install -q trl==0.8.6\n",
        "!pip install -q peft==0.10.0\n",
        "!pip install -q transformers==4.40.0"
      ],
      "metadata": {
        "id": "r463zisp-jNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b161574-e891-4101-b4dc-6b742dc3aedb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer\n",
        "from google.colab import userdata\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "fJPjP8CG_-tp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model that you want to train from the Hugging Face hub\n",
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# bitsandbytes parameters\n",
        "################################################################################\n",
        "\n",
        "# Activate 4-bit precision base model loading\n",
        "use_4bit = True\n",
        "\n",
        "# Compute dtype for 4-bit base models\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "\n",
        "# Quantization type to use\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "\n",
        "# Activate double quantization\n",
        "use_nested_quant = False"
      ],
      "metadata": {
        "id": "qZqxmRyUAACy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_map=\"auto\"   # Automatically distribute layers across GPUs\n",
        "\n",
        "\n",
        "# Load tokenizer and model with QLoRA configuration\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")"
      ],
      "metadata": {
        "id": "LFHVT2OFAi_w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get('HUGGING_FACE_TOKEN')  # add your huggingface token in Colab Secrets (left menu). Login to huggingface, and get your access token"
      ],
      "metadata": {
        "id": "OsCpsGccApEs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the model"
      ],
      "metadata": {
        "id": "jOML8pXTO7Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load DeepSeek model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map,\n",
        "    use_auth_token=hf_token  # Pass your Hugging Face token here\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "786c3b4a412747728662f0b238348b0b",
            "28e754506837463ba25424b81263c6ec",
            "95502982b22149c1a894a3fecacd7335",
            "21ad291d56f2442281cb7a8845f4c31c",
            "acaf6ce342a44983872b38b6d69e85a0",
            "5b241373632d426b9a46638f2dc85c16",
            "4feeb87ebeee4586bf2533a5d7b5efee",
            "537821bf61b649e083d2a98c41f08456",
            "21c1f8a53d674d7a88f98831adbcdd01",
            "dab9ee74fb814f50bff1038b4b1a6c8d",
            "f3a267adbc934ebfbc845cca04a84e36",
            "d7187a67dd124865a4967d1a78c197c2",
            "6c16bb64aa4b4d4a8d97c29bb6c75ba7",
            "b4d00889299e4e6bbbd6c0d06b32b63a",
            "fd005cfd6dcc4b7ba0f1a6350e4c6414",
            "12ab69b7c56141019cf0f0e91b4ec9aa",
            "821ed867f2eb467ea257fa736a3e28fa",
            "0b53c20adddd46ecbbd554b85135d59c",
            "62260aadfac34f8b98d69cac60e40759",
            "7b67618f0c0c4ed6bd31c3151b37836f",
            "b32bfa065b514defab4d73988350af18",
            "c6b91503178d44bab10d2c0b63ff8276",
            "56754da7aff34923b1f3cb688c8f03b6",
            "f7fbac93870e45e498f42b4fde54de30",
            "2ea475dafea24ea38ddadbb4df6cfdf6",
            "2d95739035d54f419f91cef170cfc122",
            "8c1effdb78a24448a562b7f769cf51d0",
            "f2e042e2938f4a4e892be19ed93562ae",
            "7631bbca8f464354a7324a52f9460a69",
            "ab0d1543f9cc4f82bc65aca5def866df",
            "14ee7bcdb1a24be286072f2de0eaa1d4",
            "ea0f75a51f1e4ebaa3f3cbdb1ee1ea0c",
            "9443e995f25c46adbc49d21bbd2d8142",
            "6a706b9d624e404c85c80ccc8d3bb6cc",
            "cd4372fbdaaf4c209ec11c89c6828e98",
            "90fbd1d4b06249109a64b3ee5fee7f70",
            "61b01c7c9e92481581fcc855b1b609fe",
            "f3fdc997ff8542dc9a80e7134453f146",
            "9676319e889f4798a01de533ae3e8dab",
            "365faf994913416c8e6f0551d655cd67",
            "3410181d46d44a918a42146adb5c7c4d",
            "792c4940b599458099b7caf93edb1514",
            "6079727ec50a420fb8d99685a603dcd7",
            "7d79b69a63684847b59b802a0529fa7e",
            "ec61005ce499442398efae0e69835da6",
            "09837fb995c54661b7831bcfc1744272",
            "9acd36d17cd74688a1c6a20cd430978b",
            "c8a27be6e27e43adbe582d4828572199",
            "335e94068f7a4071857de8e317a7eec1",
            "9884833da0564412b34b75f8ee1a816f",
            "633e3ae9b4464b6ea926d393c53d718d",
            "9106c4ecd93f41208a325c2dc7ace3d0",
            "8efc4ac0443d48caa2b830078b379402",
            "abbafe26f9e74226b6c562f85744f440",
            "c1498f5512e746b0befe11aaca41246b",
            "4c5e32f4e1c34803b08bcd03d7da20c8",
            "b6050977cd81468bb66b14a59b10e425",
            "d930f18e144e42eaae0a66b2782983ab",
            "e013aa0fd3d04793ac16ba01dcdd9eb7",
            "77872cece8f743cf9b6611895765e86b",
            "271ddae54dde426abf5e8cacc0c5bfa9",
            "ef1f31753a7647faa7d22aabbfe09866",
            "7f1e8f2859654d5ba209ffe8922274d0",
            "f1f53898066a4d11b8900bf3552a68ff",
            "e24ed1b4fd8f4d52ace574cc7d719c10",
            "d1687343c78a4e10b04cae3d0e168d9b",
            "aa1c754f40dd4ec6ac2a7e5edbc8f0fa",
            "ae7a153b183c4614955932a959b7e5da",
            "eef343662d3249c096b182b2250e68b2",
            "34a84fa38115475c800a65992590c42e",
            "9781a6c12224415ebb792b4cdc71fa4e",
            "5a740b167aaa4ff1a9e4a61a475741b7",
            "55db18e43228497198dfc0b6535bf7d2",
            "e108485fdfaa4ca9a0ee29e81d3ef8c5",
            "c362dc47d42543e7bbfb9152073dc1ea",
            "a4a25a8864cb4293b0288ef86e058bc5",
            "8eb60877815e470281d8cb320b6ecf96"
          ]
        },
        "id": "Ghmgpp__Arxd",
        "outputId": "8b2afae1-bc25-48b7-bdd3-545d866accb5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/680 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "786c3b4a412747728662f0b238348b0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7187a67dd124865a4967d1a78c197c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56754da7aff34923b1f3cb688c8f03b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-000002.safetensors:   0%|          | 0.00/8.61G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a706b9d624e404c85c80ccc8d3bb6cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-000002.safetensors:   0%|          | 0.00/6.62G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec61005ce499442398efae0e69835da6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c5e32f4e1c34803b08bcd03d7da20c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa1c754f40dd4ec6ac2a7e5edbc8f0fa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Qwen tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          trust_remote_code=True,\n",
        "                                          use_auth_token=hf_token)\n",
        "\n",
        "# Set them properly: Qwen\n",
        "#tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "815d2182c47c4a82ad99e35dfd2a22c3",
            "662fe13e2a914d549bbe9d865af4d0c1",
            "49976adff63642a2a16bcb73035c1b3f",
            "d8cdf6afcfcd41108284238f7e8ddecd",
            "561a8c6ccc9b4b058d0e6745e5f6b374",
            "ea5803f62ce34fdbb19d73e4c00510ed",
            "bda8d19fa84c40de8776b1bb6906f6b5",
            "fa685ca4eb3d4f18922eb28b2ec33480",
            "6e0d581dab2644fdbc896219d474e8ef",
            "64a2ad0da6684b93b08e4c7ef67d5fd4",
            "33f04e094bb54d9a82ac3e80a9d55b84",
            "883ec6e9cbf94b2aae217e54d0099501",
            "475cbdf9babc45ef86f928e429864733",
            "bfdab4ce1b2b48c0ab9e4dc6a220fa70",
            "bee02868fa604f1083b964caf751748e",
            "f6f414fafdb344718fd0453706e66a4b",
            "c4d02d2629cc4e55bf6e693aa7611a30",
            "859db5a864b14f71819333ba911271ce",
            "0f92615f52574d9b9589c64b89fce4c8",
            "9f037cde48304f3397fd4c1dbe2a16a9",
            "691b706c4360488f9cd0f13c3ef84227",
            "9e876be3a0e94e0d90b8b4c5c5561fa4"
          ]
        },
        "id": "neAHVZYVCy2l",
        "outputId": "fe6db65f-93a0-4fa6-d3ad-3cca98de6762"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py:757: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "815d2182c47c4a82ad99e35dfd2a22c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "883ec6e9cbf94b2aae217e54d0099501"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this function returns the outputs from the model received, and inputs.\n",
        "def get_outputs(model, inputs, max_new_tokens=32768):\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        repetition_penalty=1.1,\n",
        "        early_stopping=True, #Can stop before reach the max_length\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        do_sample=False\n",
        "    )\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "4GuED3ooAsaU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_model(system, user_input, max_new_tokens = 32768):\n",
        "  messages = [{\"role\": \"system\",\n",
        "                \"content\": system},\n",
        "                {\"role\": \"user\",\n",
        "                \"content\": user_input}\n",
        "                ]\n",
        "\n",
        "  prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "  #Inference original model\n",
        "  model_input = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
        "\n",
        "  foundational_outputs_sentence = get_outputs(model, model_input, max_new_tokens=max_new_tokens)\n",
        "  output = tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True)\n",
        "  return output"
      ],
      "metadata": {
        "id": "Cf9MfTGcCfKJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your inputs\n",
        "\n",
        "Provide the system prompt, your prompt and use Google search"
      ],
      "metadata": {
        "id": "TXRo-lsm0qJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"you are an expert python programmer\"\n",
        "user_prompt = \"\"\"\n",
        "You are a Python expert specializing in implementing Retrieval-Augmented Generation (RAG) with cutting-edge AI models and tools. Write a Python script to achieve the following:\n",
        "\n",
        "1. Objective: Build a Retrieval-Augmented Generation (RAG) system using the Google Gemini 1.5 Flash model, Chroma as the vector database, and Streamlit for the user interface. The system should enable users to input a query, retrieve relevant context from a document database using Chroma, and generate a context-aware response using the Google Gemini 1.5 Flash model.\n",
        "\n",
        "2. Requirements:\n",
        "   - Document Ingestion with Chroma:\n",
        "     - Use Chroma to store and manage a set of documents.\n",
        "     - Read PDF files from a specified folder, extract text from the PDFs, and embed the content using a suitable text embedding model compatible with Chroma.\n",
        "   - Query Workflow:\n",
        "     - When a user inputs a query through the Streamlit interface, retrieve the top-k most relevant documents from Chroma.\n",
        "   - Integration with Google Gemini 1.5 Flash:\n",
        "     - Use the retrieved documents as context to generate a response from the Google Gemini 1.5 Flash model.\n",
        "   - Streamlit Interface:\n",
        "     - Create an intuitive web interface with:\n",
        "       - A file upload feature for PDFs, which will automatically update the Chroma database with the newly added content.\n",
        "       - A text input box for user queries.\n",
        "       - A display area for both the retrieved documents and the generated response.\n",
        "   - Modularity:\n",
        "     - Structure the code with clear modular functions, such as:\n",
        "       - Extracting text from PDFs.\n",
        "       - Embedding and storing documents in Chroma.\n",
        "       - Querying Chroma for relevant documents.\n",
        "       - Generating responses using Google Gemini 1.5 Flash.\n",
        "       - Streamlit app setup and interaction.\n",
        "\n",
        "3. Assumptions:\n",
        "   - Google Gemini 1.5 Flash API access is available and properly configured.\n",
        "   - Chroma library is installed and accessible.\n",
        "   - Streamlit and a PDF parsing library like PyPDF2 or pdfplumber are installed and set up.\n",
        "\n",
        "4. Additional Considerations:\n",
        "   - Include error handling for cases where no relevant documents are found.\n",
        "   - Provide comments to explain the purpose of each function and important lines of code.\n",
        "   - Ensure the code is compatible with Python 3.8+.\n",
        "   - Ensure uploaded PDFs are processed dynamically without requiring a server restart.\n",
        "\n",
        "Please generate the Python code for the complete implementation.\n",
        "\"\"\"\n",
        "use_google_search = True  # Set to False if you don't want to use Google search"
      ],
      "metadata": {
        "id": "lQrb1HhTYM4f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Google search results and prompt model"
      ],
      "metadata": {
        "id": "gy6ANBhhfvkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q requests googlesearch-python"
      ],
      "metadata": {
        "id": "65KNV69BaxBK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googlesearch import search\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n"
      ],
      "metadata": {
        "id": "EwJqJujta2J1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_search_results(query, num_results=5):\n",
        "    results = []\n",
        "    for j in search(query, num_results=num_results):\n",
        "        results.append(j)\n",
        "    return results"
      ],
      "metadata": {
        "id": "lCkaWDKtaK2Q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_webpage_content(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        return soup.get_text()[:10000]  # Get first 10,000 characters\n",
        "    except:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "U49OFqspaOWM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_grounded_content(system_prompt, prompt):\n",
        "    # Get search results\n",
        "    search_results = get_search_results(prompt)\n",
        "\n",
        "    # Fetch content from search results\n",
        "    search_contents = [f\"Source {i+1}: {get_webpage_content(url)}\" for i, url in enumerate(search_results)]\n",
        "\n",
        "    # Combine prompt with search contents\n",
        "    grounded_prompt = f\"\"\"\n",
        "    Based on the following information, please answer the question or respond to the prompt:\n",
        "    Question/Prompt: {prompt}\n",
        "\n",
        "    Information from search:\n",
        "    {' '.join(search_contents)}\n",
        "\n",
        "    Please provide a response that incorporates information from these sources, and include citations in the format [Source X] where X is the source number.\n",
        "    \"\"\"\n",
        "\n",
        "    # Query the model\n",
        "    response = query_model(system_prompt, grounded_prompt)\n",
        "\n",
        "    return response, search_results"
      ],
      "metadata": {
        "id": "Fitjka72aS3N"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if use_google_search:\n",
        "  response, sources = generate_grounded_content(system_prompt, user_prompt)\n",
        "  print(\"\\nResponse:\")\n",
        "  pprint(response)\n",
        "\n",
        "  print(\"\\nSources:\")\n",
        "  for i, source in enumerate(sources, 1):\n",
        "    print(f\"[Source {i}] {source}\")\n",
        "else:\n",
        "  response = query_model(system_prompt, user_prompt)\n",
        "  print(\"\\nResponse:\")\n",
        "  pprint(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yupysnWmanD3",
        "outputId": "9c4ee805-f55a-4bf0-e5c4-0687662da92f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Response:\n",
            "['you are an expert python programmer<｜User｜>\\n'\n",
            " '    Based on the following information, please answer the question or '\n",
            " 'respond to the prompt:\\n'\n",
            " '    Question/Prompt: \\n'\n",
            " 'You are a Python expert specializing in implementing Retrieval-Augmented '\n",
            " 'Generation (RAG) with cutting-edge AI models and tools. Write a Python '\n",
            " 'script to achieve the following:\\n'\n",
            " '\\n'\n",
            " '1. Objective: Build a Retrieval-Augmented Generation (RAG) system using the '\n",
            " 'Google Gemini 1.5 Flash model, Chroma as the vector database, and Streamlit '\n",
            " 'for the user interface. The system should enable users to input a query, '\n",
            " 'retrieve relevant context from a document database using Chroma, and '\n",
            " 'generate a context-aware response using the Google Gemini 1.5 Flash model.\\n'\n",
            " '\\n'\n",
            " '2. Requirements:\\n'\n",
            " '   - Document Ingestion with Chroma:\\n'\n",
            " '     - Use Chroma to store and manage a set of documents.\\n'\n",
            " '     - Read PDF files from a specified folder, extract text from the PDFs, '\n",
            " 'and embed the content using a suitable text embedding model compatible with '\n",
            " 'Chroma.\\n'\n",
            " '   - Query Workflow:\\n'\n",
            " '     - When a user inputs a query through the Streamlit interface, retrieve '\n",
            " 'the top-k most relevant documents from Chroma.\\n'\n",
            " '   - Integration with Google Gemini 1.5 Flash:\\n'\n",
            " '     - Use the retrieved documents as context to generate a response from '\n",
            " 'the Google Gemini 1.5 Flash model.\\n'\n",
            " '   - Streamlit Interface:\\n'\n",
            " '     - Create an intuitive web interface with:\\n'\n",
            " '       - A file upload feature for PDFs, which will automatically update the '\n",
            " 'Chroma database with the newly added content.\\n'\n",
            " '       - A text input box for user queries.\\n'\n",
            " '       - A display area for both the retrieved documents and the generated '\n",
            " 'response.\\n'\n",
            " '   - Modularity:\\n'\n",
            " '     - Structure the code with clear modular functions, such as:\\n'\n",
            " '       - Extracting text from PDFs.\\n'\n",
            " '       - Embedding and storing documents in Chroma.\\n'\n",
            " '       - Querying Chroma for relevant documents.\\n'\n",
            " '       - Generating responses using Google Gemini 1.5 Flash.\\n'\n",
            " '       - Streamlit app setup and interaction.\\n'\n",
            " '\\n'\n",
            " '3. Assumptions:\\n'\n",
            " '   - Google Gemini 1.5 Flash API access is available and properly '\n",
            " 'configured.\\n'\n",
            " '   - Chroma library is installed and accessible.\\n'\n",
            " '   - Streamlit and a PDF parsing library like PyPDF2 or pdfplumber are '\n",
            " 'installed and set up.\\n'\n",
            " '\\n'\n",
            " '4. Additional Considerations:\\n'\n",
            " '   - Include error handling for cases where no relevant documents are '\n",
            " 'found.\\n'\n",
            " '   - Provide comments to explain the purpose of each function and important '\n",
            " 'lines of code.\\n'\n",
            " '   - Ensure the code is compatible with Python 3.8+.\\n'\n",
            " '   - Ensure uploaded PDFs are processed dynamically without requiring a '\n",
            " 'server restart.\\n'\n",
            " '\\n'\n",
            " 'Please generate the Python code for the complete implementation.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '    Information from search:\\n'\n",
            " '    Source 1: \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Build a Retrieval Augmented Generation (RAG) App: Part 1 | 🦜️🔗 LangChain\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Skip to main contentJoin us at  Interrupt: The Agent AI Conference by '\n",
            " 'LangChain on May 13 & 14 in San Francisco!IntegrationsAPI '\n",
            " 'ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain '\n",
            " 'HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a '\n",
            " 'Question Answering application over a Graph DatabaseTutorialsBuild a simple '\n",
            " 'LLM application with chat models and prompt templatesBuild a ChatbotBuild a '\n",
            " 'Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction '\n",
            " 'ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: '\n",
            " 'Part 1Build a semantic search engineBuild a Question/Answering system over '\n",
            " 'SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a '\n",
            " 'chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow '\n",
            " 'to use example selectorsHow to add a semantic layer over graph databaseHow '\n",
            " 'to invoke runnables in parallelHow to stream chat model responsesHow to add '\n",
            " 'default invocation args to a RunnableHow to add retrieval to chatbotsHow to '\n",
            " 'use few shot examples in chat modelsHow to do tool/function callingHow to '\n",
            " 'install LangChain packagesHow to add examples to the prompt for query '\n",
            " 'analysisHow to use few shot examplesHow to run custom functionsHow to use '\n",
            " 'output parsers to parse an LLM response into structured formatHow to handle '\n",
            " 'cases where no queries are generatedHow to route between sub-chainsHow to '\n",
            " 'return structured data from a modelHow to summarize text through '\n",
            " 'parallelizationHow to summarize text through iterative refinementHow to '\n",
            " 'summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool '\n",
            " 'calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor '\n",
            " '(Legacy)How to construct knowledge graphsHow to partially format prompt '\n",
            " 'templatesHow to handle multiple queries when doing query analysisHow to use '\n",
            " 'built-in tools and toolkitsHow to pass through arguments from one step to '\n",
            " 'the nextHow to compose prompts togetherHow to handle multiple retrievers '\n",
            " \"when doing query analysisHow to add values to a chain's stateHow to \"\n",
            " 'construct filters for query analysisHow to configure runtime chain '\n",
            " 'internalsHow deal with high cardinality categoricals when doing query '\n",
            " 'analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add '\n",
            " 'scores to retriever resultsCachingHow to use callbacks in async '\n",
            " 'environmentsHow to attach callbacks to a runnableHow to propagate callbacks  '\n",
            " 'constructorHow to dispatch custom callback eventsHow to pass callbacks in at '\n",
            " 'runtimeHow to split by characterHow to cache chat model responsesHow to '\n",
            " 'handle rate limitsHow to init any model in one lineHow to track token usage '\n",
            " 'in ChatModelsHow to add tools to chatbotsHow to split codeHow to do '\n",
            " 'retrieval with contextual compressionHow to convert Runnables to ToolsHow to '\n",
            " 'create custom callback handlersHow to create a custom chat model classCustom '\n",
            " 'EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create '\n",
            " 'toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a '\n",
            " 'directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load '\n",
            " 'Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a '\n",
            " 'dynamic (self-constructing) chainText embedding modelsHow to combine results '\n",
            " 'from multiple retrieversHow to select examples from a LangSmith datasetHow '\n",
            " 'to select examples by lengthHow to select examples by maximal marginal '\n",
            " 'relevance (MMR)How to select examples by n-gram overlapHow to select '\n",
            " 'examples by similarityHow to use reference examples when doing extractionHow '\n",
            " 'to handle long text when doing extractionHow to use prompting alone (no tool '\n",
            " 'calling) to do extractionHow to add fallbacks to a runnableHow to filter '\n",
            " 'messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect '\n",
            " 'runnablesLangChain Expression Language CheatsheetHow to cache LLM '\n",
            " 'responsesHow to track token usage for LLMsRun models locallyHow to get log '\n",
            " 'probabilitiesHow to reorder retrieved results to mitigate the \"lost in the '\n",
            " 'middle\" effectHow to split Markdown by HeadersHow to merge consecutive '\n",
            " 'messages of the same typeHow to add message historyHow to migrate from '\n",
            " 'legacy LangChain agents to LangGraphHow to retrieve using multiple vectors '\n",
            " 'per documentHow to pass multimodal data directly to modelsHow to use '\n",
            " 'multimodal promptsHow to create a custom Output ParserHow to use the '\n",
            " 'output-fixing parserHow to parse JSON outputHow to retry when a parsing '\n",
            " 'error occursHow to parse text from message objectsHow to parse XML outputHow '\n",
            " 'to parse YAML outputHow to use the Parent Document RetrieverHow to use '\n",
            " 'LangChain with different Pydantic versionsHow to add chat historyHow to get '\n",
            " 'a RAG application to add citationsHow to do per-user retrievalHow to get '\n",
            " 'your RAG application to return sourcesHow to stream results from your RAG '\n",
            " 'applicationHow to split JSON dataHow to recursively split text by '\n",
            " 'charactersResponse metadataHow to pass runtime secrets to runnablesHow to do '\n",
            " '\"self-querying\" retrievalHow to split text based on semantic similarityHow '\n",
            " 'to chain runnablesHow to save and load LangChain objectsHow to split text by '\n",
            " 'tokensHow to split HTMLHow to do question answering over CSVsHow to deal '\n",
            " 'with large databases when doing SQL question-answeringHow to better prompt '\n",
            " 'when doing SQL question-answeringHow to do query validation as part of SQL '\n",
            " 'question-answeringHow to stream runnablesHow to stream responses from an '\n",
            " 'LLMHow to use a time-weighted vector store retrieverHow to return artifacts '\n",
            " 'from a toolHow to use chat models to call toolsHow to disable parallel tool '\n",
            " 'callingHow to force models to call a toolHow to access the RunnableConfig '\n",
            " 'from a toolHow to pass tool outputs to chat modelsHow to pass run time '\n",
            " 'values to toolsHow to stream events from a toolHow to stream tool callsHow '\n",
            " 'to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use '\n",
            " 'few-shot prompting with tool callingHow to add a human-in-the-loop for '\n",
            " 'toolsHow to bind model-specific toolsHow to trim messagesHow to create and '\n",
            " 'query vector storesConceptual guideAgentsArchitectureAsync programming with '\n",
            " 'langchainCallbacksChat historyChat modelsDocument loadersEmbedding '\n",
            " 'modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value '\n",
            " 'storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput '\n",
            " 'parsersPrompt TemplatesRetrieval augmented generation '\n",
            " '(RAG)RetrievalRetrieversRunnable interfaceStreamingStructured '\n",
            " 'outputsTestingString-in, string-out llmsText splittersTokensTool '\n",
            " 'callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ '\n",
            " 'LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow '\n",
            " 'to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from '\n",
            " 'ConversationalChainMigrating from ConversationalRetrievalChainMigrating from '\n",
            " 'LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating '\n",
            " 'from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating '\n",
            " 'from MultiPromptChainMigrating from RefineDocumentsChainMigrating from '\n",
            " 'RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph '\n",
            " 'memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory '\n",
            " 'with LangGraphMigrating off ConversationBufferMemory or '\n",
            " 'ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory '\n",
            " 'or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or '\n",
            " 'ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease '\n",
            " 'policySecurity PolicyTutorialsBuild a Retrieval Augmented Generation (RAG) '\n",
            " 'App: Part 1On this pageBuild a Retrieval Augmented Generation (RAG) App: '\n",
            " 'Part 1\\n'\n",
            " 'One of the most powerful applications enabled by LLMs is sophisticated '\n",
            " 'question-answering (Q&A) chatbots. These are applications that can answer '\n",
            " 'questions about specific source information. These applications use a '\n",
            " 'technique known as Retrieval Augmented Generation, or RAG.\\n'\n",
            " 'This is a multi-part tutorial:\\n'\n",
            " '\\n'\n",
            " 'Part 1 (this guide) introduces RAG and walks through a minimal '\n",
            " 'implementation.\\n'\n",
            " 'Part 2 extends the implementation to accommodate conversation-style '\n",
            " 'interactions and multi-step retrieval processes.\\n'\n",
            " '\\n'\n",
            " 'This tutorial will show how to build a simple Q&A application\\n'\n",
            " 'over a text data source. Along the way we’ll go over a typical Q&A\\n'\n",
            " 'architecture and highlight additional resources for more advanced Q&A '\n",
            " 'techniques. We’ll also see\\n'\n",
            " 'how LangSmith can help us trace and understand our application.\\n'\n",
            " 'LangSmith will become increasingly helpful as our application grows in\\n'\n",
            " 'complexity.\\n'\n",
            " \"If you're already familiar with basic retrieval, you might also be \"\n",
            " 'interested in\\n'\n",
            " 'this high-level overview of different retrieval techniques.\\n'\n",
            " 'Note: Here we focus on Q&A for unstructured data. If you are interested for '\n",
            " 'RAG over structured data, check out our tutorial on doing question/answering '\n",
            " 'over SQL data.\\n'\n",
            " 'Overview\\u200b\\n'\n",
            " 'A typical RAG application has two main components:\\n'\n",
            " 'Indexing: a pipeline for ingesting data from a source and indexing it. This '\n",
            " 'usually happens offline.\\n'\n",
            " 'Retrieval and generation: the actual RAG chain, which takes the user query '\n",
            " 'at run time and retrieves the relevant data from the index, then passes that '\n",
            " 'to the model.\\n'\n",
            " 'Note: the indexing portion of this tutorial will largely follow the semantic '\n",
            " 'search tutorial.\\n'\n",
            " 'The most common full sequence from raw data to answer looks like:\\n'\n",
            " 'Indexing\\u200b\\n'\n",
            " '\\n'\n",
            " 'Load: First we need to load our data. This is done with Document Loaders.\\n'\n",
            " 'Split: Text splitters break large Documents into smaller chunks. This is '\n",
            " 'useful both for indexing data and passing it into a model, as large chunks '\n",
            " \"are harder to search over and won't fit in a model's finite context window.\\n\"\n",
            " 'Store: We need somewhere to store and index our splits, so that they can be '\n",
            " 'searched over later. This is often done using a VectorStore and Embeddings '\n",
            " 'model.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Retrieval and generation\\u200b\\n'\n",
            " '\\n'\n",
            " 'Retrieve: Given a user input, relevant splits are retrieved from storage '\n",
            " 'using a Retriever.\\n'\n",
            " 'Generate: A ChatModel / LLM produces an answer using a prompt that includes '\n",
            " 'both the question with the retrieved data\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " \"Once we've indexed our data, we will use LangGraph as  Source 2: \"\n",
            " 'Retrieval-Augmented Generation (RAG): From Theory to LangChain '\n",
            " 'Implementation | by Leonie Monigatti | TDS Archive | MediumOpen in appSign '\n",
            " 'upSign inWriteSign upSign inRetrieval-Augmented Generation (RAG): From '\n",
            " 'Theory to LangChain ImplementationFrom the theory of the original academic '\n",
            " 'paper to its Python implementation with OpenAI, Weaviate, and '\n",
            " 'LangChainLeonie Monigatti·FollowPublished inTDS Archive·7 min read·Nov 14, '\n",
            " '2023--15ListenShareRetrieval-Augmented Generation WorkflowSince the '\n",
            " 'realization that you can supercharge large language models (LLMs) with your '\n",
            " 'proprietary data, there has been some discussion on how to most effectively '\n",
            " 'bridge the gap between the LLM’s general knowledge and your proprietary '\n",
            " 'data. There has been a lot of debate around whether fine-tuning or '\n",
            " 'Retrieval-Augmented Generation (RAG) is more suited for this (spoiler alert: '\n",
            " 'it’s both).This article first focuses on the concept of RAG and first covers '\n",
            " 'its theory. Then, it goes on to showcase how you can implement a simple RAG '\n",
            " 'pipeline using LangChain for orchestration, OpenAI language models, and a '\n",
            " 'Weaviate vector database.What is Retrieval-Augmented '\n",
            " 'GenerationRetrieval-Augmented Generation (RAG) is the concept to provide '\n",
            " 'LLMs with additional information from an external knowledge source. This '\n",
            " 'allows them to generate more accurate and contextual answers while reducing '\n",
            " 'hallucinations.ProblemState-of-the-art LLMs are trained on large amounts of '\n",
            " 'data to achieve a broad spectrum of general knowledge stored in the neural '\n",
            " \"network's weights (parametric memory). However, prompting an LLM to generate \"\n",
            " 'a completion that requires knowledge that was not included in its training '\n",
            " 'data, such as newer, proprietary, or domain-specific information, can lead '\n",
            " 'to factual inaccuracies (hallucinations), as illustrated in the following '\n",
            " 'screenshot:ChatGPT’s answer to the question, “What did the president say '\n",
            " 'about Justice Breyer?”Thus, it is important to bridge the gap between the '\n",
            " 'LLM’s general knowledge and any additional context to help the LLM generate '\n",
            " 'more accurate and contextual completions while reducing '\n",
            " 'hallucinations.SolutionTraditionally, neural networks are adapted to '\n",
            " 'domain-specific or proprietary information by fine-tuning the model. '\n",
            " 'Although this technique is effective, it is also compute-intensive, '\n",
            " 'expensive, and requires technical expertise, making it less agile to adapt '\n",
            " 'to evolving information.In 2020, Lewis et al. proposed a more flexible '\n",
            " 'technique called Retrieval-Augmented Generation (RAG) in the paper '\n",
            " 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks [1]. In '\n",
            " 'this paper, the researchers combined a generative model with a retriever '\n",
            " 'module to provide additional information from an external knowledge source '\n",
            " 'that can be updated more easily.In simple terms, RAG is to LLMs what an '\n",
            " 'open-book exam is to humans. In an open-book exam, students are allowed to '\n",
            " 'bring reference materials, such as textbooks or notes, which they can use to '\n",
            " 'look up relevant information to answer a question. The idea behind an '\n",
            " 'open-book exam is that the test focuses on the students’ reasoning skills '\n",
            " 'rather than their ability to memorize specific information.Similarly, the '\n",
            " 'factual knowledge is separated from the LLM’s reasoning capability and '\n",
            " 'stored in an external knowledge source, which can be easily accessed and '\n",
            " 'updated:Parametric knowledge: Learned during training that is implicitly '\n",
            " \"stored in the neural network's weights.Non-parametric knowledge: Stored in \"\n",
            " 'an external knowledge source, such as a vector database.(By the way, I '\n",
            " 'didn’t come up with this genius comparison. As far as I know, this '\n",
            " 'comparison was first mentioned by JJ during the Kaggle — LLM Science Exam '\n",
            " 'competition.)The vanilla RAG workflow is illustrated '\n",
            " 'below:Retrieval-Augmented Generation WorkflowRetrieve: The user query is '\n",
            " 'used to retrieve relevant context from an external knowledge source. For '\n",
            " 'this, the user query is embedded with an embedding model into the same '\n",
            " 'vector space as the additional context in the vector database. This allows '\n",
            " 'to perform a similarity search, and the top k closest data objects from the '\n",
            " 'vector database are returned.Augment: The user query and the retrieved '\n",
            " 'additional context are stuffed into a prompt template.Generate: Finally, the '\n",
            " 'retrieval-augmented prompt is fed to the LLM.Retrieval-Augmented Generation '\n",
            " 'Implementation using LangChainThis section implements a RAG pipeline in '\n",
            " 'Python using an OpenAI LLM in combination with a Weaviate vector database '\n",
            " 'and an OpenAI embedding model. LangChain is used for orchestration.If you '\n",
            " 'are unfamiliar with LangChain or Weaviate, you might want to check out the '\n",
            " 'following two articles:Getting Started with LangChain: A Beginner’s Guide to '\n",
            " 'Building LLM-Powered ApplicationsA LangChain tutorial to build anything with '\n",
            " 'large language models in Pythontowardsdatascience.comGetting Started with '\n",
            " 'Weaviate: A Beginner’s Guide to Search with Vector DatabasesHow to use '\n",
            " 'vector databases for semantic search, question answering, and generative '\n",
            " 'search in Python with OpenAI and…towardsdatascience.comPrerequisitesMake '\n",
            " 'sure you have installed the required Python packages:langchain for '\n",
            " 'orchestrationopenai for the embedding model and LLMweaviate-client for the '\n",
            " 'vector database#!pip install langchain openai weaviate-clientAdditionally, '\n",
            " 'define your relevant environment variables in a .env file in your root '\n",
            " 'directory. To obtain an OpenAI API Key, you need an OpenAI account and then '\n",
            " '“Create new secret key” under API '\n",
            " 'keys.OPENAI_API_KEY=\"<YOUR_OPENAI_API_KEY>\"Then, run the following command '\n",
            " 'to load the relevant environment variables.import '\n",
            " 'dotenvdotenv.load_dotenv()PreparationAs a preparation step, you need to '\n",
            " 'prepare a vector database as an external knowledge source that holds all '\n",
            " 'additional information. This vector database is populated by following these '\n",
            " 'steps:Collect and load your dataChunk your documentsEmbed and store '\n",
            " 'chunksThe first step is to collect and load your data — For this example, '\n",
            " 'you will use President Biden’s State of the Union Address from 2022 as '\n",
            " 'additional context. The raw text document is available in LangChain’s GitHub '\n",
            " 'repository. To load the data, You can use one of LangChain’s many built-in '\n",
            " 'DocumentLoaders. A Document is a dictionary with text and metadata. To load '\n",
            " 'text, you will use LangChain’s TextLoader.import requestsfrom '\n",
            " 'langchain.document_loaders import TextLoaderurl = '\n",
            " '\"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/modules/state_of_the_union.txt\"res '\n",
            " '= requests.get(url)with open(\"state_of_the_union.txt\", \"w\") as f:    '\n",
            " \"f.write(res.text)loader = TextLoader('./state_of_the_union.txt')documents = \"\n",
            " 'loader.load()Next, chunk your documents — Because the Document, in its '\n",
            " 'original state, is too long to fit into the LLM’s context window, you need '\n",
            " 'to chunk it into smaller pieces. LangChain comes with many built-in text '\n",
            " 'splitters for this purpose. For this simple example, you can use the '\n",
            " 'CharacterTextSplitter with a chunk_size of about 500 and a chunk_overlap of '\n",
            " '50 to preserve text continuity between the chunks.from '\n",
            " 'langchain.text_splitter import CharacterTextSplittertext_splitter = '\n",
            " 'CharacterTextSplitter(chunk_size=500, chunk_overlap=50)chunks = '\n",
            " 'text_splitter.split_documents(documents)Lastly, embed and store the chunks — '\n",
            " 'To enable semantic search across the text chunks, you need to generate the '\n",
            " 'vector embeddings for each chunk and then store them together with their '\n",
            " 'embeddings. To generate the vector embeddings, you can use the OpenAI '\n",
            " 'embedding model, and to store them, you can use the Weaviate vector '\n",
            " 'database. By calling .from_documents() the vector database is automatically '\n",
            " 'populated with the chunks.from langchain.embeddings import '\n",
            " 'OpenAIEmbeddingsfrom langchain.vectorstores import Weaviateimport '\n",
            " 'weaviatefrom weaviate.embedded import EmbeddedOptionsclient = '\n",
            " 'weaviate.Client(  embedded_options = EmbeddedOptions())vectorstore = '\n",
            " 'Weaviate.from_documents(    client = client,        documents = chunks,    '\n",
            " 'embedding = OpenAIEmbeddings(),    by_text = False)Step 1: RetrieveOnce the '\n",
            " 'vector database is populated, you can define it as the retriever component, '\n",
            " 'which fetches the additional context based on the semantic similarity '\n",
            " 'between the user query and the embedded chunks.retriever = '\n",
            " 'vectorstore.as_retriever()Step 2: AugmentNext, to augment the prompt with '\n",
            " 'the additional context, you need to prepare a prompt template. The prompt '\n",
            " 'can be easily customized from a prompt template, as shown below.from '\n",
            " 'langchain.prompts import ChatPromptTemplatetemplate = \"\"\"You are an '\n",
            " 'assistant for question-answering tasks. Use the following pieces of '\n",
            " \"retrieved context to answer the question. If you don't know the answer, just \"\n",
            " \"say that you don't know. Use three sentences maximum and keep the answer \"\n",
            " 'concise.Question: {question} Context: {context} Answer:\"\"\"prompt = '\n",
            " 'ChatPromptTemplate.from_template(template)print(prompt)Step 3: '\n",
            " 'GenerateFinally, you can build a chain for the RAG pipeline, chaining '\n",
            " 'together the retriever, the prompt template and the LLM. Once the RAG chain '\n",
            " 'is defined, you can invoke it.from langchain.chat_models import '\n",
            " 'ChatOpenAIfrom langchain.schema.runnable import RunnablePassthroughfrom '\n",
            " 'langchain.schema.output_parser import StrOutputParserllm = '\n",
            " 'ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)rag_chain = (    '\n",
            " '{\"context\": retriever,  \"question\": RunnablePassthrough()}     | prompt     '\n",
            " '| llm    | StrOutputParser() )query = \"What did the president say about '\n",
            " 'Justice Breyer\"rag_chain.invoke(query)\"The president thanked Justice Breyer '\n",
            " 'for his service and acknowledged his dedication to serving the country. The '\n",
            " 'president also mentioned that he nominated Judge Ketanji Brown Jackson as a '\n",
            " 'successor to continue Justice Breyer\\'s legacy of excellence.\"You can see '\n",
            " 'the resulting RAG pipeline for this specific example illustrated '\n",
            " 'below:Retrieval-Augmented Generation WorkflowSummaryThis article covered the '\n",
            " 'concept of RAG, which was presented in the paper Retrieval-Augmented '\n",
            " 'Generation for Knowledge-Intensive NLP Tasks [1] from 2020. After covering '\n",
            " 'some  Source 3: \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'What is Retrieval-Augmented Generation (RAG)?\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " ' \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'DeepSeek\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Learning Paths\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'GenAI Pinnacle Program\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Agentic AI Pioneer Program\\n'\n",
            " 'New\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Login\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '                                Switch Mode\\n'\n",
            " '                            \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '                                Logout\\n'\n",
            " ' \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Interview PrepCareerGenAIPrompt EnggChatGPTLLMLangchainRAGAI AgentsMachine '\n",
            " 'LearningDeep LearningGenAI ToolsLLMOpsPythonNLPSQLAIML Projects \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Home\\n'\n",
            " '\\n'\n",
            " 'Artificial Intelligence                            \\n'\n",
            " '\\n'\n",
            " '                                What is Retrieval-Augmented Generation '\n",
            " '(RAG)?                                \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'What is Retrieval-Augmented Generation (RAG)?\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '                            Soumyadarshan Dash                             \\n'\n",
            " ' Last Updated : \\n'\n",
            " '                                06 Feb, 2025 \\n'\n",
            " '                            \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '  13  min read\\n'\n",
            " '                        \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Retrieval-Augmented Generation (RAG) is a smart AI technique that combines '\n",
            " 'two powerful tools: information retrieval and text generation. Imagine a '\n",
            " 'system that can search for relevant facts or data (like a librarian) and '\n",
            " 'then use that information to create clear, accurate, and detailed answers '\n",
            " '(like a writer). RAG is used in chatbots, virtual assistants, and other AI '\n",
            " 'tools to provide better, more informed responses. It’s like having a '\n",
            " 'super-smart helper that knows how to find and use the right information. In '\n",
            " 'this article, you will get to know all about Retrieval-Augmented Generation, '\n",
            " 'its uses, applications, and how it will shape the future of RAG and LLMs.\\n'\n",
            " 'This article was published as a part of the\\xa0Data Science Blogathon.\\n'\n",
            " 'Table of contentsWhat is Retrieval-Augmented Generation (RAG)?Why Use '\n",
            " 'RAG?The Fusion of Retrieval-Based and Generative ModelsRange of Data Sources '\n",
            " 'to Empower RAG ModelsBenefits of Retrieval-Augmented Generation '\n",
            " '(RAG)Enhanced LLM MemoryImproved ContextualizationUpdatable MemorySource '\n",
            " 'CitationsReduced HallucinationsDiverse Approaches in RAGEthical '\n",
            " 'Considerations in RAGApplications of Retrieval Augmented Generation (RAG)The '\n",
            " 'Future of RAGs and LLMsHow Does Retrieval-Augmented Generation '\n",
            " 'Work?Utilizing LangChain for Enhanced Retrieval-Augmented Generation '\n",
            " '(RAG)Installation of LangChain and OpenAI LibrariesWeb Data Loading for the '\n",
            " 'RAG Knowledge BaseSplit the Data into ChunksEmbedding and Vector Store '\n",
            " 'SetupEstablishing the Retrieval SystemInitializes the RAG SystemIssue '\n",
            " 'Queries to the RAG SystemRetrieves ResponsesFrequently Asked Questions\\n'\n",
            " 'What is Retrieval-Augmented Generation (RAG)?\\n'\n",
            " 'Retrieval-Augmented Generation, or RAG, represents a cutting-edge approach '\n",
            " 'to artificial intelligence (AI) and natural language processing (NLP). At '\n",
            " 'its core, RAG LLM is an innovative framework that combines the strengths of '\n",
            " 'retrieval-based and generative models, revolutionizing how AI systems '\n",
            " 'understand and generate human-like text.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Why Use RAG? \\n'\n",
            " 'The development of RAG is a direct response to the limitations of large '\n",
            " 'language models (LLMs) like GPT. While LLMs have shown impressive text '\n",
            " 'generation capabilities, they often struggle to provide contextually '\n",
            " 'relevant responses, hindering their utility in practical applications. RAG '\n",
            " 'LLM aims to bridge this gap by offering a solution that understands user '\n",
            " 'intent and delivers meaningful and context-aware replies.\\n'\n",
            " 'The Fusion of Retrieval-Based and Generative Models\\n'\n",
            " 'RAG is fundamentally a hybrid model that seamlessly integrates two critical '\n",
            " 'components. Retrieval-based methods involve accessing and extracting '\n",
            " 'information from external knowledge sources such as databases, articles, or '\n",
            " 'websites. \\n'\n",
            " 'On the other hand, generative models excel in generating coherent and '\n",
            " 'contextually relevant text. What distinguishes RAG Model is its ability to '\n",
            " 'harmonize these two components, creating a symbiotic relationship that '\n",
            " 'allows it to comprehend user queries deeply and produce responses that are '\n",
            " 'not just accurate but also contextually rich.\\n'\n",
            " 'Deconstructing RAG’s Mechanics\\n'\n",
            " 'To grasp the essence of RAG LLM, it’s essential to deconstruct its '\n",
            " 'operational mechanics. RAG operates through a series of well-defined steps:\\n'\n",
            " '\\n'\n",
            " 'Begin by receiving and processing user input.\\n'\n",
            " 'Analyze the user input to understand its meaning and intent.\\n'\n",
            " 'Utilize retrieval-based methods to access external knowledge sources. This '\n",
            " 'enriches the understanding of the user’s query.\\n'\n",
            " 'Use the retrieved external knowledge to enhance comprehension.\\n'\n",
            " 'Employ generative capabilities to craft responses. Ensure responses are '\n",
            " 'factually accurate, contextually relevant, and coherent.\\n'\n",
            " 'Combine all the information gathered to produce responses that are '\n",
            " 'meaningful and human-like.\\n'\n",
            " 'Ensure that the transformation of user queries into responses is done '\n",
            " 'effectively.\\n'\n",
            " '\\n'\n",
            " 'Checkout this article about the 12 Generative AI Models to Explore in 2025\\n'\n",
            " 'The Role of Language Models and User Input\\n'\n",
            " 'Central to understanding RAG is appreciating the role of Large Language '\n",
            " 'Models (LLMs) in AI systems. LLMs like GPT are the backbone of many NLP '\n",
            " 'applications, including chatbots and virtual assistants. They excel in '\n",
            " 'processing user input and generating text, but their accuracy and contextual '\n",
            " 'awareness are paramount for successful interactions. RAG strives to enhance '\n",
            " 'these essential aspects by integrating retrieval and generation.\\n'\n",
            " 'Incorporating External Knowledge Sources\\n'\n",
            " 'RAG’s distinguishing feature is its ability to integrate external knowledge '\n",
            " 'sources seamlessly. By drawing from vast information repositories, RAG '\n",
            " 'augments its understanding, enabling it to provide well-informed and '\n",
            " 'contextually nuanced responses. Incorporating external knowledge elevates '\n",
            " 'the quality of interactions and ensures that users receive relevant and '\n",
            " 'accurate information.\\n'\n",
            " 'Generating Contextual Responses\\n'\n",
            " 'Ultimately, RAG’s hallmark is its ability to generate contextual responses. '\n",
            " 'Moreover, it considers the broader context of user queries, leverages '\n",
            " 'external knowledge, and produces responses demonstrating a deep '\n",
            " 'understanding of the user’s needs. Consequently, these context-aware '\n",
            " 'responses are a significant advancement, as they facilitate more natural and '\n",
            " 'human-like interactions, making AI systems powered by RAG highly effective '\n",
            " 'in various domains.\\n'\n",
            " 'Retrieval Augmented Generation (RAG) is a transformative concept in AI and '\n",
            " 'NLP. Additionally, by harmonizing retrieval and generation components, RAG '\n",
            " 'addresses the limitations of existing language models and paves the way for '\n",
            " 'more intelligent and context-aware AI interactions. Furthermore, its ability '\n",
            " 'to seamlessly integrate external knowledge sources and generate responses '\n",
            " 'that align with user intent positions RAG as a game-changer in developing AI '\n",
            " 'systems that can truly understand and communicate with users in a human-like '\n",
            " 'manner.\\n'\n",
            " 'Range of Data Sources to Empower RAG Models\\n'\n",
            " 'In this section, we delve into the pivotal role of external data sources '\n",
            " 'within the Retrieval Augmented Generation (RAG) framework. We explore the '\n",
            " 'diverse range of data sources that can be harnessed to empower RAG-driven '\n",
            " 'models.\\n'\n",
            " 'APIs and Real-time Databases\\n'\n",
            " 'APIs (Application Programming Interfaces) and real-time databases are '\n",
            " 'dynamic sources that provide up-to-the-minute information to RAG-driven '\n",
            " 'models. They also allow models to access the latest data as it becomes '\n",
            " 'available.\\n'\n",
            " 'Document Repositories\\n'\n",
            " 'Document repositories serve as valuable knowledge stores, offering '\n",
            " 'structured and unstructured information. Additionally, they are fundamental '\n",
            " 'in expanding the knowledge base that RAG models can draw upon.\\n'\n",
            " 'Webpages and Scraping\\n'\n",
            " 'Web scraping is a method for extracting information from web pages. It '\n",
            " 'enables RAG LLM models to access dynamic web content, making it a crucial '\n",
            " 'source for real-time data retrieval.\\n'\n",
            " 'Databases and Structured Information\\n'\n",
            " 'Databases provide structured data that can be queried and extracted. '\n",
            " 'Additionally, RAG models can utilize databases to retrieve specific '\n",
            " 'information, enhancing their responses’ accuracy.\\n'\n",
            " 'Benefits of Retrieval-Augmented Generation (RAG)\\n'\n",
            " 'Let us now talk about the benefits of Retrieval Augmented Generation or RAG '\n",
            " 'Model.\\n'\n",
            " 'Enhanced LLM Memory\\n'\n",
            " 'RAG addresses the information capacity limitation of traditional Language '\n",
            " 'Models (LLMs). Traditional LLMs have a limited memory called “Parametric '\n",
            " 'memory.” RAG introduces a “Non-Parametric memory” by tapping into external '\n",
            " 'knowledge sources. This significantly expands the knowledge base of LLMs, '\n",
            " 'enabling them to provide more comprehensive and accurate responses.\\n'\n",
            " 'Improved Contextualization\\n'\n",
            " 'RAG enhances the contextual understanding of LLMs by retrieving and '\n",
            " 'integrating relevant contextual documents. This empowers the model to '\n",
            " 'generate responses that align seamlessly with the specific context of the '\n",
            " 'user’s input, resulting in accurate and contextually appropriate outputs.\\n'\n",
            " 'Updatable Memory\\n'\n",
            " 'A standout advantage of RAG is its ability to accommodate real-time updates '\n",
            " 'and fresh sources without extensive model retraining. Moreover, this keeps '\n",
            " 'the external knowledge base current and ensures that LLM-generated responses '\n",
            " 'are always based on the latest and most relevant information.\\n'\n",
            " 'Source Citations\\n'\n",
            " 'RAG-equipped models can provide sources for their responses, thereby '\n",
            " 'enhancing transparency and credibility. Moreover, users can access the '\n",
            " 'sources that inform the LLM’s responses, promoting transparency and trust in '\n",
            " 'AI-generated content.\\n'\n",
            " 'Reduced Hallucinations\\n'\n",
            " 'Studies have shown that RAG models exhibit fewer hallucinations and higher '\n",
            " 'response accuracy. They are also less likely to leak sensitive information. '\n",
            " 'Reduced hallucinations and increased accuracy make RAG models more reliable '\n",
            " 'in generating content.\\n'\n",
            " 'These benefits collectively make Retrieval Augmented Generation (RAG) a '\n",
            " 'transformative framework in Natural Language Processing. Consequently, it '\n",
            " 'overcomes the limitations of traditional language models and enhances the '\n",
            " 'capabilities of AI-powered applications.\\n'\n",
            " 'Diverse Approaches in RAG\\n'\n",
            " 'RAG Model offers a spectrum of approac Source 4: \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Build a Retrieval Augmented Generation (RAG) App | 🦜️🔗 LangChain\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Skip to main contentA newer LangChain version is out! Check out the latest '\n",
            " 'version.IntegrationsAPI '\n",
            " 'referenceLatestLegacyMorePeopleContributingCookbooks3rd party '\n",
            " 'tutorialsYouTubearXivv0.2Latestv0.2v0.1🦜️🔗LangSmithLangSmith DocsLangChain '\n",
            " 'HubJS/TS Docs💬SearchIntroductionTutorialsBuild a Question Answering '\n",
            " 'application over a Graph DatabaseTutorialsBuild a Simple LLM Application '\n",
            " 'with LCELBuild a Query Analysis SystemBuild a ChatbotConversational RAGBuild '\n",
            " 'an Extraction ChainBuild an AgentTaggingdata_generationBuild a Local RAG '\n",
            " 'ApplicationBuild a PDF ingestion and Question/Answering systemBuild a '\n",
            " 'Retrieval Augmented Generation (RAG) AppVector stores and retrieversBuild a '\n",
            " 'Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to '\n",
            " 'guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow '\n",
            " 'to add memory to chatbotsHow to use example selectorsHow to map values to a '\n",
            " 'graph databaseHow to add a semantic layer over graph databaseHow to invoke '\n",
            " 'runnables in parallelHow to stream chat model responsesHow to add default '\n",
            " 'invocation args to a RunnableHow to add retrieval to chatbotsHow to use few '\n",
            " 'shot examples in chat modelsHow to do tool/function callingHow to best '\n",
            " 'prompt for Graph-RAGHow to install LangChain packagesHow to add examples to '\n",
            " 'the prompt for query analysisHow to use few shot examplesHow to run custom '\n",
            " 'functionsHow to use output parsers to parse an LLM response into structured '\n",
            " 'formatHow to handle cases where no queries are generatedHow to route between '\n",
            " 'sub-chainsHow to return structured data from a modelHow to summarize text '\n",
            " 'through parallelizationHow to summarize text through iterative refinementHow '\n",
            " 'to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc '\n",
            " 'tool calling capability to LLMs and Chat ModelsBuild an Agent with '\n",
            " 'AgentExecutor (Legacy)How to construct knowledge graphsHow to partially '\n",
            " 'format prompt templatesHow to handle multiple queries when doing query '\n",
            " 'analysisHow to use built-in tools and toolkitsHow to pass through arguments '\n",
            " 'from one step to the nextHow to compose prompts togetherHow to handle '\n",
            " \"multiple retrievers when doing query analysisHow to add values to a chain's \"\n",
            " 'stateHow to construct filters for query analysisHow to configure runtime '\n",
            " 'chain internalsHow deal with high cardinality categoricals when doing query '\n",
            " 'analysisCustom Document LoaderHow to split by HTML headerHow to split by '\n",
            " 'HTML sectionsHow to use the MultiQueryRetrieverHow to add scores to '\n",
            " 'retriever resultsCachingHow to use callbacks in async environmentsHow to '\n",
            " 'attach callbacks to a runnableHow to propagate callbacks  constructorHow to '\n",
            " 'dispatch custom callback eventsHow to pass callbacks in at runtimeHow to '\n",
            " 'split by characterHow to cache chat model responsesHow to handle rate '\n",
            " 'limitsHow to init any model in one lineHow to track token usage in '\n",
            " 'ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval '\n",
            " 'with contextual compressionHow to convert Runnables as ToolsHow to create '\n",
            " 'custom callback handlersHow to create a custom chat model classHow to create '\n",
            " 'a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM '\n",
            " 'appsHow to load CSVsHow to load documents from a directoryHow to load '\n",
            " 'HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office '\n",
            " 'filesHow to load PDFsHow to create a dynamic (self-constructing) chainText '\n",
            " 'embedding modelsHow to combine results from multiple retrieversHow to select '\n",
            " 'examples from a LangSmith datasetHow to select examples by lengthHow to '\n",
            " 'select examples by maximal marginal relevance (MMR)How to select examples by '\n",
            " 'n-gram overlapHow to select examples by similarityHow to use reference '\n",
            " 'examples when doing extractionHow to handle long text when doing '\n",
            " 'extractionHow to use prompting alone (no tool calling) to do extractionHow '\n",
            " 'to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use '\n",
            " 'the LangChain indexing APIHow to inspect runnablesLangChain Expression '\n",
            " 'Language CheatsheetHow to cache LLM responsesHow to track token usage for '\n",
            " 'LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved '\n",
            " 'results to mitigate the \"lost in the middle\" effectHow to split Markdown by '\n",
            " 'HeadersHow to merge consecutive messages of the same typeHow to add message '\n",
            " 'historyHow to migrate from legacy LangChain agents to LangGraphHow to '\n",
            " 'retrieve using multiple vectors per documentHow to pass multimodal data '\n",
            " 'directly to modelsHow to use multimodal promptsHow to create a custom Output '\n",
            " 'ParserHow to use the output-fixing parserHow to parse JSON outputHow to '\n",
            " 'retry when a parsing error occursHow to parse XML outputHow to parse YAML '\n",
            " 'outputHow to use the Parent Document RetrieverHow to use LangChain with '\n",
            " 'different Pydantic versionsHow to add chat historyHow to get a RAG '\n",
            " 'application to add citationsHow to do per-user retrievalHow to get your RAG '\n",
            " 'application to return sourcesHow to stream results from your RAG '\n",
            " 'applicationHow to split JSON dataHow to recursively split text by '\n",
            " 'charactersResponse metadataHow to pass runtime secrets to runnablesHow to do '\n",
            " '\"self-querying\" retrievalHow to split text based on semantic similarityHow '\n",
            " 'to chain runnablesHow to save and load LangChain objectsHow to split text by '\n",
            " 'tokensHow to do question answering over CSVsHow to deal with large databases '\n",
            " 'when doing SQL question-answeringHow to better prompt when doing SQL '\n",
            " 'question-answeringHow to do query validation as part of SQL '\n",
            " 'question-answeringHow to stream runnablesHow to stream responses from an '\n",
            " 'LLMHow to use a time-weighted vector store retrieverHow to return artifacts '\n",
            " 'from a toolHow to use chat models to call toolsHow to disable parallel tool '\n",
            " 'callingHow to force models to call a toolHow to access the RunnableConfig '\n",
            " 'from a toolHow to pass tool outputs to chat modelsHow to pass run time '\n",
            " 'values to toolsHow to stream events from a toolHow to stream tool callsHow '\n",
            " 'to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use '\n",
            " 'few-shot prompting with tool callingHow to add a human-in-the-loop for '\n",
            " 'toolsHow to bind model-specific toolsHow to trim messagesHow to create and '\n",
            " 'query vector storesConceptual guideEcosystem🦜🛠️ LangSmith🦜🕸️ '\n",
            " 'LangGraphVersionsOverview of v0.2Release policyPydantic '\n",
            " 'compatibilityMigrating to v0.2Migrating to LangChain v0.2astream_events '\n",
            " 'v2ChangesMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating '\n",
            " 'from ConstitutionalChainMigrating from ConversationalChainMigrating from '\n",
            " 'ConversationalRetrievalChainMigrating from LLMChainMigrating from '\n",
            " 'LLMMathChainMigrating from LLMRouterChainMigrating from '\n",
            " 'MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from '\n",
            " 'MultiPromptChainMigrating from RefineDocumentsChainMigrating from '\n",
            " 'RetrievalQAMigrating from StuffDocumentsChainSecurityThis is documentation '\n",
            " 'for LangChain v0.2, which is no longer actively maintained.For the current '\n",
            " 'stable version, see this version (Latest).TutorialsBuild a Retrieval '\n",
            " 'Augmented Generation (RAG) AppOn this pageBuild a Retrieval Augmented '\n",
            " 'Generation (RAG) AppOne of the most powerful applications enabled by LLMs is '\n",
            " 'sophisticated question-answering (Q&A) chatbots. These are applications that '\n",
            " 'can answer questions about specific source information. These applications '\n",
            " 'use a technique known as Retrieval Augmented Generation, or RAG.This '\n",
            " 'tutorial will show how to build a simple Q&A application\\n'\n",
            " 'over a text data source. Along the way we’ll go over a typical Q&A\\n'\n",
            " 'architecture and highlight additional resources for more advanced Q&A '\n",
            " 'techniques. We’ll also see\\n'\n",
            " 'how LangSmith can help us trace and understand our application.\\n'\n",
            " 'LangSmith will become increasingly helpful as our application grows in\\n'\n",
            " \"complexity.If you're already familiar with basic retrieval, you might also \"\n",
            " 'be interested in\\n'\n",
            " 'this high-level overview of different retrieval techinques.What is '\n",
            " 'RAG?\\u200bRAG is a technique for augmenting LLM knowledge with additional '\n",
            " 'data.LLMs can reason about wide-ranging topics, but their knowledge is '\n",
            " 'limited to the public data up to a specific point in time that they were '\n",
            " 'trained on. If you want to build AI applications that can reason about '\n",
            " \"private data or data introduced after a model's cutoff date, you need to \"\n",
            " 'augment the knowledge of the model with the specific information it needs. '\n",
            " 'The process of bringing the appropriate information and inserting it into '\n",
            " 'the model prompt is known as Retrieval Augmented Generation (RAG).LangChain '\n",
            " 'has a number of components designed to help build Q&A applications, and RAG '\n",
            " 'applications more generally. Note: Here we focus on Q&A for unstructured '\n",
            " 'data. If you are interested for RAG over structured data, check out our '\n",
            " 'tutorial on doing question/answering over SQL data.Concepts\\u200bA typical '\n",
            " 'RAG application has two main components:Indexing: a pipeline for ingesting '\n",
            " 'data from a source and indexing it. This usually happens offline.Retrieval '\n",
            " 'and generation: the actual RAG chain, which takes the user query at run time '\n",
            " 'and retrieves the relevant data from the index, then passes that to the '\n",
            " 'model.The most common full sequence from raw data to answer looks '\n",
            " 'like:Indexing\\u200bLoad: First we need to load our data. This is done with '\n",
            " 'Document Loaders.Split: Text splitters break large Documents into smaller '\n",
            " 'chunks. This is useful both for indexing data and for passing it in to a '\n",
            " \"model, since large chunks are harder to search over and won't fit in a \"\n",
            " \"model's finite context window.Store: We need somewhere to store and index \"\n",
            " 'our splits, so that they can later be searched over. This is often done '\n",
            " 'using a VectorStore and Embeddings model.Retrieval and '\n",
            " 'generation\\u200bRetrieve: Given a user input, relevant splits are retrieved '\n",
            " 'from storage using a Retriever.Generate: A ChatModel / LLM produces an '\n",
            " 'answer using a prompt that includes the question and the retrieved '\n",
            " 'dataSetup\\u200bJupyter Notebook\\u200bThis guide (and most of the other '\n",
            " 'guides in the documentation) uses Jupyter notebooks and assumes the reader '\n",
            " 'is as well. Jupyter notebooks are perfect for learning how to work with LLM '\n",
            " 'systems because oftentimes things can go wrong (unexpecte Source 5: \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'How to Become a RAG Specialist in 2025? - Analytics Vidhya\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " ' \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'DeepSeek\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Learning Paths\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'GenAI Pinnacle Program\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Agentic AI Pioneer Program\\n'\n",
            " 'New\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Login\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '                                Switch Mode\\n'\n",
            " '                            \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '                                Logout\\n'\n",
            " ' \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Interview PrepCareerGenAIPrompt EnggChatGPTLLMLangchainRAGAI AgentsMachine '\n",
            " 'LearningDeep LearningGenAI ToolsLLMOpsPythonNLPSQLAIML Projects \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Home\\n'\n",
            " '\\n'\n",
            " 'RAG                            \\n'\n",
            " '\\n'\n",
            " '                                How to Become a RAG Specialist in '\n",
            " '2025?                                \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'How to Become a RAG Specialist in 2025?\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '                            Pankaj Singh                             \\n'\n",
            " ' Last Updated : \\n'\n",
            " '                                16 Dec, 2024 \\n'\n",
            " '                            \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '  26  min read\\n'\n",
            " '                        \\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'What does it take to become a specialist in a particular skill? It is said, '\n",
            " 'the learner should invest around 10,000 hours of focused practice to gain '\n",
            " 'expertise in a field. But in this fast-paced world, where time is the most '\n",
            " 'valuable thing, we need to work smarter to plan how a beginner can get a '\n",
            " 'strong hold on a tech-specific skill in a limited time. The answer lies in '\n",
            " 'having a clear Learning Path or a perfect Roadmap. It Worked for Me! Today, '\n",
            " 'I am going to talk about how you can become a RAG Specialist, and I will '\n",
            " 'provide a detailed roadmap for diving into the world of Retrieval Augmented '\n",
            " 'Generation (RAG).\\n'\n",
            " 'RAG Specialist Roadmap is for:\\xa0\\n'\n",
            " '\\n'\n",
            " 'Python developers & ML Engineers who want to build AI-driven applications '\n",
            " 'leveraging LLMs and custom enterprise data. \\n'\n",
            " 'Students and Learners willing to dive into RAG implementations and gain '\n",
            " 'hands-on experience with practical examples.\\n'\n",
            " '\\n'\n",
            " 'Table of contentsWhat is RAG, and Where is it Used?How RAG Works?Learning '\n",
            " 'Path to Become a RAG SpecialistStep 1. Programming Language ProficiencyStep '\n",
            " '2. Core Libraries and ToolsStep 3. Foundations of Machine Learning and Deep '\n",
            " 'Learning – with a Focus on Information RetrievalStep 4. Natural Language '\n",
            " 'Processing (NLP)Step 5. Introduction to RAG SystemsStep 6. '\n",
            " 'Retrieval-Augmented Generation (RAG) ArchitectureStep 7. Information '\n",
            " 'Retrieval (IR)Step 8. Building Retrieval SystemsStep 9. Integration into RAG '\n",
            " 'SystemsStep 10. RAG EvaluationStep 11. RAG Challenges and ImprovementsStep '\n",
            " '12. Practical ImplementationStep 13. Advanced RAGStep 14. Ongoing Learning '\n",
            " 'and ResourcesStep 15. Community and Continuous LearningStep 16. Hands-On '\n",
            " 'Capstone ProjectRAG Research PapersConclusionFrequently Asked Questions\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Click here to download the RAG Specialist roadmap!\\n'\n",
            " 'What is RAG, and Where is it Used?\\n'\n",
            " '\\n'\n",
            " 'RAG (Retrieval-Augmented Generation) is a technique that enhances the '\n",
            " 'performance of language models by combining them with an external retrieval '\n",
            " 'mechanism. This allows the model to pull in relevant information from large '\n",
            " 'document stores or knowledge bases at inference time, improving the quality '\n",
            " 'and factual accuracy of its generated responses.\\n'\n",
            " 'Key Components of RAG:\\n'\n",
            " '\\n'\n",
            " 'Retrieval Component: A retriever (typically based on similarity search) '\n",
            " 'scans a large corpus of documents or databases to find relevant passages '\n",
            " 'based on a query.\\n'\n",
            " 'Generation Component:\\n'\n",
            " '\\n'\n",
            " 'After retrieving the relevant documents or passages, a language model (e.g., '\n",
            " 'GPT-4o, Claude 3.5, Gemini 1.5, Llama 3.2) uses these passages as context to '\n",
            " 'generate a more informed response or output.\\n'\n",
            " 'The model can either generate a direct answer or summarize the retrieved '\n",
            " 'information depending on the task.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'The main advantage of RAG is that it allows the model to handle long-tail '\n",
            " 'knowledge and tasks that require factual accuracy or specialized knowledge, '\n",
            " 'which might not be directly encoded in the model’s parameters.\\n'\n",
            " 'Also read: Top 8 Applications of RAGs in Workplaces.\\n'\n",
            " 'How RAG Works?\\n'\n",
            " 'Here’s how RAG works:\\n'\n",
            " '\\n'\n",
            " 'When a query or prompt is received, the system first retrieves relevant '\n",
            " 'documents or information from a pre-indexed corpus (such as Wikipedia, '\n",
            " 'product catalogs, research papers, etc.).\\n'\n",
            " 'The language model then uses the retrieved information to generate a '\n",
            " 'response.\\n'\n",
            " 'The model might perform multiple retrieval steps (iterative retrieval) or '\n",
            " 'use a combination of different retrieval techniques to improve the quality '\n",
            " 'of the retrieved documents.\\n'\n",
            " '\\n'\n",
            " 'To know more about this, refer to this article: What is Retrieval-Augmented '\n",
            " 'Generation (RAG)?\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 Build a RAG '\n",
            " 'Pipeline With the LLama Index.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Learning Path to Become a RAG Specialist\\n'\n",
            " 'To become an RAG specialist, you’ll need to gain expertise in multiple '\n",
            " 'areas, ranging from foundational knowledge in machine learning and natural '\n",
            " 'language processing (NLP) to hands-on experience with RAG-specific '\n",
            " 'architectures and tools. Below is a comprehensive learning path tailored to '\n",
            " 'guide you through this journey to becoming an RAG Specialist:\\n'\n",
            " 'Step 1. Programming Language Proficiency\\n'\n",
            " 'Master the primary programming languages used in Retrieval-Augmented '\n",
            " 'Generation (RAG) development, with a strong focus on Python.\\n'\n",
            " 'Languages:\\n'\n",
            " '\\n'\n",
            " 'Python: The dominant language in AI/ML research and development. Python is '\n",
            " 'widely used for data science, machine learning, natural language processing '\n",
            " '(NLP), and creating systems that rely on RAG methods. Its simplicity, '\n",
            " 'combined with an extensive ecosystem of libraries, makes it the go-to choice '\n",
            " 'for AI and ML tasks.\\n'\n",
            " '\\n'\n",
            " 'Key Skills:\\n'\n",
            " '\\n'\n",
            " 'Data structures (lists, dictionaries, sets, tuples).\\n'\n",
            " 'File handling (text, JSON, CSV).\\n'\n",
            " 'Exception handling and debugging.\\n'\n",
            " 'Object-oriented programming (OOP) and functional programming concepts.\\n'\n",
            " 'Writing modular and reusable code.\\n'\n",
            " '\\n'\n",
            " 'Resources:\\n'\n",
            " '\\n'\n",
            " '“Automate the Boring Stuff with Python” by Al Sweigart – A great resource '\n",
            " 'for beginners that covers Python basics with real-world applications, '\n",
            " 'focusing on practical scripting for automation and productivity.\\n'\n",
            " '“Python Crash Course” by Eric Matthes – A beginner-friendly book that offers '\n",
            " 'a comprehensive introduction to Python, covering all essential topics and '\n",
            " 'providing hands-on projects to build your skills.\\n'\n",
            " '\\n'\n",
            " 'For more books: \\n'\n",
            " '\\n'\n",
            " '15 Best Python Books For You\\n'\n",
            " '8 Popular Tools for RAG Applications\\n'\n",
            " '\\n'\n",
            " 'Step 2. Core Libraries and Tools\\n'\n",
            " 'Gain familiarity with the libraries and tools crucial for building and '\n",
            " 'deploying Retrieval-Augmented Generation (RAG) systems. These libraries help '\n",
            " 'streamline the process of data processing, data retrieval, model '\n",
            " 'development, natural language processing (NLP), and integration with '\n",
            " 'large-scale systems.\\n'\n",
            " 'Key Libraries\\n'\n",
            " '\\n'\n",
            " 'Machine Learning & Deep Learning:\\n'\n",
            " '\\n'\n",
            " 'TensorFlow, PyTorch (for training and deploying models).\\n'\n",
            " 'Scikit-learn (for preprocessing and auxiliary tasks).\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'NLP-Specific:\\n'\n",
            " '\\n'\n",
            " 'Hugging Face Transformers (pretrained models like GPT-4o, Claude 3.5, Gemini '\n",
            " '1.5, Llama 3.2).\\n'\n",
            " 'SpaCy and NLTK (text preprocessing and linguistic features).\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Data Processing:\\n'\n",
            " '\\n'\n",
            " 'Pandas (data manipulation).\\n'\n",
            " 'NumPy (numerical computing).\\n'\n",
            " 'PyTorch Lightning (scalable ML workflows).\\n'\n",
            " 'PyTorch Litserve\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Resources\\n'\n",
            " '\\n'\n",
            " 'Official documentation for TensorFlow, PyTorch, Hugging Face, SpaCy, and '\n",
            " 'other libraries.\\n'\n",
            " 'GitHub repositories for RAG-specific frameworks (e.g., Haystack, PyTorch '\n",
            " 'Lightning, listserve, LangChain and LlamaIndex).\\n'\n",
            " 'Online tutorials and courses (e.g., Analytics Vidhya, Deeplearning.ai, '\n",
            " 'Coursera, edX, Fast.ai) covering deep learning, NLP, and RAG development.\\n'\n",
            " 'Course on Python: Introduction to Python\\n'\n",
            " '\\n'\n",
            " 'Also explore: Coding Essentials Course\\n'\n",
            " 'Step 3. Foundations of Machine Learning and Deep Learning – with a Focus on '\n",
            " 'Information Retrieval\\n'\n",
            " 'The foundations of Machine Learning and Deep Learning in RAG '\n",
            " '(Retriever-Augmented Generation) is to equip learners with the essential '\n",
            " 'knowledge of machine learning and deep learning techniques. This involves '\n",
            " 'understanding model architectures, data retrieval methods, and the '\n",
            " 'integration of generative models with information retrieval systems to '\n",
            " 'enhance the accuracy and efficiency of AI-driven responses and tasks.\\n'\n",
            " 'Key Topics:\\n'\n",
            " '\\n'\n",
            " 'Supervised Learning: Learning from labeled data to predict outcomes (e.g., '\n",
            " 'regression and classification).\\n'\n",
            " 'Unsupervised Learning: Identifying patterns and structures in unlabeled data '\n",
            " '(e.g., clustering and dimensionality reduction).\\n'\n",
            " 'Reinforcement Learning: Learning by interacting with an environment and '\n",
            " 'receiving feedback through rewards or penalties.\\n'\n",
            " 'Core Algorithms:\\n'\n",
            " '\\n'\n",
            " 'Linear Regression: For predicting continuous outcomes.\\n'\n",
            " 'Logistic Regression: For binary classification.\\n'\n",
            " 'Decision Trees: For decision-making based on data features.\\n'\n",
            " 'K-Means Clustering: For grouping similar data points.\\n'\n",
            " 'K-Nearest Neighbors (KNN): For classification based on proximity to labeled '\n",
            " 'data points.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Information Retrieval (IR) Systems: Information Retrieval refers to the '\n",
            " 'process of obtaining relevant information from large datasets or databases, '\n",
            " 'typically in response to a query. The core components include:\\n'\n",
            " '\\n'\n",
            " 'Search Engine Basics:\\n'\n",
            " '\\n'\n",
            " 'Indexing: Involves creating an index of all documents in a corpus to '\n",
            " 'facilitate fast retrieval based on the search terms.\\n'\n",
            " 'Query Processing: When a user enters a query, the system processes it, '\n",
            " 'matches it to relevant documents in the index, and ranks the documents based '\n",
            " 'on relevance.\\n'\n",
            " 'Ranking Algorithms: Ranking is typically based on algorithms like TF-IDF '\n",
            " '(Term Frequency-Inverse Document Frequency), which measures the importance '\n",
            " 'of a term in a document relative to its occurrence in the entire corpus.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " 'Vector Space Model (VSM): Documents and queries are represented as vectors '\n",
            " 'in a multi-dimensional space, where each dimension represents a term. The '\n",
            " 'similarity between a query and a document is determined using measures like '\n",
            " 'Cosine Similarity.\\n'\n",
            " 'Latent Semantic Analysis (LSA): A technique used to reduce dimensionality '\n",
            " 'and capture deeper semantic relationships between terms and documents '\n",
            " 'through Singular Value Decomposition (SVD).\\n'\n",
            " 'BM25, Cosine Similarity and PageRank for ranking document relevance.\\n'\n",
            " 'Clustering: Clustering is a type of unsupervised learning where data points '\n",
            " 'are grouped in\\n'\n",
            " '\\n'\n",
            " '    Please provide a response that incorporates information from these '\n",
            " 'sources, and include citations in the format [Source X] where X is the '\n",
            " 'source number.\\n'\n",
            " '    <｜Assistant｜><think>\\n'\n",
            " \"Okay, so I'm trying to figure out how to become a RAG specialist. I've heard \"\n",
            " 'a bit about RAG being cool because it helps AI understand more context by '\n",
            " \"pulling info from outside sources. But honestly, I'm not exactly sure where \"\n",
            " 'to start. Let me think through this.\\n'\n",
            " '\\n'\n",
            " 'First, what even is RAG? From what I remember, it stands for Retrieval '\n",
            " \"Augmented Generation. So, it's about using retrieval to make AI models \"\n",
            " 'smarter. That makes sense because sometimes models just spit out answers '\n",
            " 'without really thinking about the background info needed. RAG must help them '\n",
            " 'get that context from outside data.\\n'\n",
            " '\\n'\n",
            " 'So, if I want to specialize in RAG, I guess I need to learn how to make AI '\n",
            " 'models use that retrieval stuff effectively. But how? I mean, there are so '\n",
            " 'many parts involved—programming, machine learning, data handling, etc. Maybe '\n",
            " 'I should break it down into steps.\\n'\n",
            " '\\n'\n",
            " 'Hmm, maybe I should start with programming. I know Python is big in AI, so '\n",
            " 'probably need to get good at that. But wait, what else? Do I need to learn '\n",
            " 'something else besides Python? Like, maybe some libraries related to RAG? '\n",
            " \"I've heard of LangChain and LlamaIndex before. Those might be important \"\n",
            " 'tools for building RAG systems.\\n'\n",
            " '\\n'\n",
            " \"Then, there's the machine learning side. I guess I need to understand how \"\n",
            " \"models work, especially language models. But I'm not very familiar with how \"\n",
            " 'those models are trained or how they generate text. Maybe I should take some '\n",
            " 'courses or read some books on deep learning and NLP. But which ones? There '\n",
            " 'are so many options out there.\\n'\n",
            " '\\n'\n",
            " 'Wait, I saw something about information retrieval being a key part of RAG. '\n",
            " 'So, I probably need to learn how to search through large documents or '\n",
            " 'databases efficiently. That sounds like a separate skill from just coding. I '\n",
            " 'should look into how search engines work, maybe some algorithms behind IR, '\n",
            " 'like TF-IDF or BM25. But how does that tie into RAG specifically?\\n'\n",
            " '\\n'\n",
            " 'I think I need to connect the dots between retrieval and generation. Once I '\n",
            " 'have the relevant info pulled from outside sources, how do I get the model '\n",
            " \"to use it? Is there a standard architecture for RAG systems? I've heard of \"\n",
            " 'things like Haystack and LangChain. Maybe those platforms can help me '\n",
            " 'organize everything.\\n'\n",
            " '\\n'\n",
            " 'But before I jump into building anything, maybe I should solidify my '\n",
            " 'understanding of the basics. Like, what exactly is a language model? How do '\n",
            " 'they generate text? And why would adding external info make them better? I '\n",
            " \"guess because sometimes the model doesn't have enough context or the right \"\n",
            " 'facts to answer accurately. So, RAG bridges that gap by pulling in external '\n",
            " 'data.\\n'\n",
            " '\\n'\n",
            " 'So, to become a RAG specialist, I probably need to cover several areas: '\n",
            " 'programming, machine learning, information retrieval, and then put it all '\n",
            " 'together in a system. But where do I start? Should I begin with Python, then '\n",
            " 'move on to machine learning, and sprinkle in RAG concepts along the way?\\n'\n",
            " '\\n'\n",
            " 'I also wonder about the tools and frameworks. LangChain seems versatile '\n",
            " 'because it can integrate with various AI systems. LlamaIndex is another tool '\n",
            " \"I've heard about for indexing. But I'm not entirely sure how they all work \"\n",
            " 'together. Maybe I should look into specific tutorials or projects that use '\n",
            " 'both to see how they function in a real RAG system.\\n'\n",
            " '\\n'\n",
            " 'Another thought: certifications. I know there are courses and certifications '\n",
            " \"out there, like from DeepSeek or Analytics Vidya. But I'm not sure which \"\n",
            " 'ones are recognized or how they fit into the learning path. Should I aim for '\n",
            " 'a certification, or is it more about self-learning through structured '\n",
            " 'courses and projects?\\n'\n",
            " '\\n'\n",
            " 'I also need to consider the time aspect. How much time do I realistically '\n",
            " \"have to dedicate to learning all this? I don't want to underestimate it, but \"\n",
            " \"I also don't want to get overwhelmed. Maybe setting small, achievable goals \"\n",
            " 'each week would help. Like, week one focus on Python basics, week two on '\n",
            " 'machine learning fundamentals, and so on.\\n'\n",
            " '\\n'\n",
            " \"But wait, what about the math behind machine learning? I've heard that \"\n",
            " 'understanding linear algebra, calculus, and statistics is important for '\n",
            " 'getting into AI. Should I brush up on those areas before diving into '\n",
            " 'programming? Or can I learn them alongside?\\n'\n",
            " '\\n'\n",
            " \"I think starting with Python makes sense because it's the primary language. \"\n",
            " 'Then, maybe concurrently taking some math courses or brushing up on '\n",
            " \"necessary concepts. But I'm not sure if that's feasible. Perhaps online \"\n",
            " 'resources offer courses that combine programming and math, which could be '\n",
            " 'beneficial.\\n'\n",
            " '\\n'\n",
            " 'Also, experimenting with RAG systems myself would be crucial. Even if I '\n",
            " 'understand the theory, applying it practically would help solidify the '\n",
            " 'knowledge. So, finding a project or dataset to work on would be important. '\n",
            " 'Maybe starting with a simple RAG implementation using existing libraries '\n",
            " 'like LangChain and LlamaIndex.\\n'\n",
            " '\\n'\n",
            " \"But I'm still unclear on the exact steps. Do I need to start with data \"\n",
            " 'collection and indexing, then move on to model training, and finally '\n",
            " 'implement the RAG pipeline? Or is there a different flow? I think it varies '\n",
            " 'depending on the specific architecture, but generally, it involves gathering '\n",
            " 'data, indexing it, training a model to pull relevant info, and then using '\n",
            " \"that info to enhance the model's responses.\\n\"\n",
            " '\\n'\n",
            " 'I also realize that staying updated is important because technology changes '\n",
            " 'rapidly. Joining communities, following blogs, and attending webinars could '\n",
            " 'provide ongoing learning opportunities. Plus, networking with others who are '\n",
            " 'already in the field could offer insights and advice.\\n'\n",
            " '\\n'\n",
            " 'Overall, I think the key is to create a structured learning plan that covers '\n",
            " 'all the necessary areas, from programming to advanced RAG concepts, while '\n",
            " 'also allowing time for hands-on practice and experimentation. Starting small '\n",
            " \"and gradually building up skills seems like the way to go. But I'm still a \"\n",
            " 'bit overwhelmed by the breadth of what needs to be learned. Maybe breaking '\n",
            " 'it down into manageable chunks and focusing on one area at a time would '\n",
            " 'help.\\n'\n",
            " '</think>\\n'\n",
            " '\\n'\n",
            " 'To become a RAG specialist, follow this structured learning path, organized '\n",
            " 'into key areas and actionable steps:\\n'\n",
            " '\\n'\n",
            " '### 1. Programming Fundamentals (Python)\\n'\n",
            " '- **Objective:** Master Python as the primary language for AI and ML.\\n'\n",
            " '- **Steps:**\\n'\n",
            " '  - Learn syntax, data structures, and libraries.\\n'\n",
            " '  - Practice with books like \"Automate the Boring Stuff\" and \"Python Crash '\n",
            " 'Course.\"\\n'\n",
            " '  - Experiment with projects involving data manipulation and automation.\\n'\n",
            " '\\n'\n",
            " '### 2. Core Libraries and Tools\\n'\n",
            " '- **Objective:** Gain proficiency in libraries essential for RAG.\\n'\n",
            " '- **Steps:**\\n'\n",
            " '  - Study TensorFlow, PyTorch, and Scikit-learn for ML and DL.\\n'\n",
            " '  - Explore Hugging Face Transformers for NLP models.\\n'\n",
            " '  - Learn Pandas for data processing and NumPy for numerical operations.\\n'\n",
            " '  - Utilize LangChain and LlamaIndex for RAG-related functionalities.\\n'\n",
            " '\\n'\n",
            " '### 3. Machine Learning and Deep Learning Basics\\n'\n",
            " '- **Objective:** Understand ML and DL principles.\\n'\n",
            " '- **Steps:**\\n'\n",
            " '  - Learn supervised and unsupervised learning with Linear Regression, '\n",
            " 'Logistic Regression, Decision Trees, and K-Means.\\n'\n",
            " '  - Study reinforcement learning basics.\\n'\n",
            " '  - Use online courses from Coursera, edX, and Fast.ai.\\n'\n",
            " '\\n'\n",
            " '### 4. Information Retrieval (IR)\\n'\n",
            " '- **Objective:** Grasp IR techniques for efficient data retrieval.\\n'\n",
            " '- **Steps:**\\n'\n",
            " '  - Learn search engine basics, including indexing and query processing.\\n'\n",
            " '  - Study algorithms like TF-IDF, BM25, and PageRank.\\n'\n",
            " '  - Explore IR systems using resources like \"Introduction to Information '\n",
            " 'Retrieval.\"\\n'\n",
            " '\\n'\n",
            " '### 5. RAG Systems and Frameworks\\n'\n",
            " '- **Objective:** Understand RAG architecture and tools.\\n'\n",
            " '- **Steps:**\\n'\n",
            " '  - Explore Haystack, LangChain, and LlamaIndex for RAG implementation.\\n'\n",
            " '  - Follow tutorials and projects showcasing RAG in action.\\n'\n",
            " '\\n'\n",
            " '### 6. Hands-On Practice and Projects\\n'\n",
            " '- **Objective:** Apply RAG concepts practically.\\n'\n",
            " '- **Steps:**\\n'\n",
            " '  - Implement a simple RAG system using LangChain and LlamaIndex.\\n'\n",
            " '  - Experiment with datasets and refine models for better retrieval and '\n",
            " 'generation.\\n'\n",
            " '\\n'\n",
            " '### 7. Advanced RAG Concepts\\n'\n",
            " '- **Objective:** Deepen understanding of complex RAG applications.\\n'\n",
            " '- **Steps:**\\n'\n",
            " '  - Study case studies and research papers on RAG advancements.\\n'\n",
            " '  - Explore challenges and improvements in RAG systems.\\n'\n",
            " '\\n'\n",
            " '### 8. Certifications and Networking\\n'\n",
            " '- **Objective:** Enhance credentials and network.\\n'\n",
            " '- **Steps:**\\n'\n",
            " '  - Pursue certifications from reputable providers.\\n'\n",
            " '  - Engage with AI communities and attend webinars for ongoing learning.\\n'\n",
            " '\\n'\n",
            " '### 9. Ongoing Learning and Experimentation\\n'\n",
            " '- **Objective:** Stay updated and refine skills.\\n'\n",
            " '- **Steps:**\\n'\n",
            " '  - Regularly update skills with new technologies and methodologies.\\n'\n",
            " '  - Experiment with different RAG approaches and tools.\\n'\n",
            " '\\n'\n",
            " \"By systematically addressing each area, you'll build a comprehensive \"\n",
            " 'understanding of RAG, enabling you to become a proficient specialist in this '\n",
            " 'field.']\n",
            "\n",
            "Sources:\n",
            "[Source 1] https://python.langchain.com/docs/tutorials/rag/\n",
            "[Source 2] https://medium.com/towards-data-science/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2\n",
            "[Source 3] https://www.analyticsvidhya.com/blog/2023/09/retrieval-augmented-generation-rag-in-ai/\n",
            "[Source 4] https://python.langchain.com/v0.2/docs/tutorials/rag/\n",
            "[Source 5] https://www.analyticsvidhya.com/blog/2024/12/rag-specialist/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eES_HBC0dJCl"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}