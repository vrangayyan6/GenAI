{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMfN0V0rmnRLAoIkVA8WuE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrangayyan6/GenAI/blob/main/Deep_research_LangGraph_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Check out https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart/tree/main\n",
        "*   Create API key at https://ai.google.dev/"
      ],
      "metadata": {
        "id": "dBgU-KYJPAMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langgraph langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_05qva2TqOz",
        "outputId": "562ab664-fc20-43bc-f83d-0b37d8bff08e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# configuration.py\n",
        "\n",
        "import os\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Any, Optional\n",
        "\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "\n",
        "class Configuration(BaseModel):\n",
        "    \"\"\"The configuration for the agent.\"\"\"\n",
        "\n",
        "    query_generator_model: str = Field(\n",
        "        default=\"gemini-2.0-flash\",\n",
        "        metadata={\n",
        "            \"description\": \"The name of the language model to use for the agent's query generation.\"\n",
        "        },\n",
        "    )\n",
        "\n",
        "    reflection_model: str = Field(\n",
        "        default=\"gemini-2.5-flash-preview-05-20\",\n",
        "        metadata={\n",
        "            \"description\": \"The name of the language model to use for the agent's reflection.\"\n",
        "        },\n",
        "    )\n",
        "\n",
        "    answer_model: str = Field(\n",
        "        default=\"gemini-2.5-flash-preview-05-20\",                     # \"gemini-2.5-pro-preview-05-06\",\n",
        "        metadata={\n",
        "            \"description\": \"The name of the language model to use for the agent's answer.\"\n",
        "        },\n",
        "    )\n",
        "\n",
        "    number_of_initial_queries: int = Field(\n",
        "        default=3,\n",
        "        metadata={\"description\": \"The number of initial search queries to generate.\"},\n",
        "    )\n",
        "\n",
        "    max_research_loops: int = Field(\n",
        "        default=2,\n",
        "        metadata={\"description\": \"The maximum number of research loops to perform.\"},\n",
        "    )\n",
        "\n",
        "    @classmethod\n",
        "    def from_runnable_config(\n",
        "        cls, config: Optional[RunnableConfig] = None\n",
        "    ) -> \"Configuration\":\n",
        "        \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"\n",
        "        configurable = (\n",
        "            config[\"configurable\"] if config and \"configurable\" in config else {}\n",
        "        )\n",
        "\n",
        "        # Get raw values from environment or config\n",
        "        raw_values: dict[str, Any] = {\n",
        "            name: os.environ.get(name.upper(), configurable.get(name))\n",
        "            for name in cls.model_fields.keys()\n",
        "        }\n",
        "\n",
        "        # Filter out None values\n",
        "        values = {k: v for k, v in raw_values.items() if v is not None}\n",
        "\n",
        "        return cls(**values)"
      ],
      "metadata": {
        "id": "92Kz5BkiQVOe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# utils.py\n",
        "\n",
        "from typing import Any, Dict, List\n",
        "from langchain_core.messages import AnyMessage, AIMessage, HumanMessage\n",
        "\n",
        "\n",
        "def get_research_topic(messages: List[AnyMessage]) -> str:\n",
        "    \"\"\"\n",
        "    Get the research topic from the messages.\n",
        "    \"\"\"\n",
        "    # check if request has a history and combine the messages into a single string\n",
        "    if len(messages) == 1:\n",
        "        research_topic = messages[-1].content\n",
        "    else:\n",
        "        research_topic = \"\"\n",
        "        for message in messages:\n",
        "            if isinstance(message, HumanMessage):\n",
        "                research_topic += f\"User: {message.content}\\n\"\n",
        "            elif isinstance(message, AIMessage):\n",
        "                research_topic += f\"Assistant: {message.content}\\n\"\n",
        "    return research_topic\n",
        "\n",
        "\n",
        "def resolve_urls(urls_to_resolve: List[Any], id: int) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Create a map of the vertex ai search urls (very long) to a short url with a unique id for each url.\n",
        "    Ensures each original URL gets a consistent shortened form while maintaining uniqueness.\n",
        "    \"\"\"\n",
        "    prefix = f\"https://vertexaisearch.cloud.google.com/id/\"\n",
        "    urls = [site.web.uri for site in urls_to_resolve]\n",
        "\n",
        "    # Create a dictionary that maps each unique URL to its first occurrence index\n",
        "    resolved_map = {}\n",
        "    for idx, url in enumerate(urls):\n",
        "        if url not in resolved_map:\n",
        "            resolved_map[url] = f\"{prefix}{id}-{idx}\"\n",
        "\n",
        "    return resolved_map\n",
        "\n",
        "\n",
        "def insert_citation_markers(text, citations_list):\n",
        "    \"\"\"\n",
        "    Inserts citation markers into a text string based on start and end indices.\n",
        "\n",
        "    Args:\n",
        "        text (str): The original text string.\n",
        "        citations_list (list): A list of dictionaries, where each dictionary\n",
        "                               contains 'start_index', 'end_index', and\n",
        "                               'segment_string' (the marker to insert).\n",
        "                               Indices are assumed to be for the original text.\n",
        "\n",
        "    Returns:\n",
        "        str: The text with citation markers inserted.\n",
        "    \"\"\"\n",
        "    # Sort citations by end_index in descending order.\n",
        "    # If end_index is the same, secondary sort by start_index descending.\n",
        "    # This ensures that insertions at the end of the string don't affect\n",
        "    # the indices of earlier parts of the string that still need to be processed.\n",
        "    sorted_citations = sorted(\n",
        "        citations_list, key=lambda c: (c[\"end_index\"], c[\"start_index\"]), reverse=True\n",
        "    )\n",
        "\n",
        "    modified_text = text\n",
        "    for citation_info in sorted_citations:\n",
        "        # These indices refer to positions in the *original* text,\n",
        "        # but since we iterate from the end, they remain valid for insertion\n",
        "        # relative to the parts of the string already processed.\n",
        "        end_idx = citation_info[\"end_index\"]\n",
        "        marker_to_insert = \"\"\n",
        "        for segment in citation_info[\"segments\"]:\n",
        "            marker_to_insert += f\" [{segment['label']}]({segment['short_url']})\"\n",
        "        # Insert the citation marker at the original end_idx position\n",
        "        modified_text = (\n",
        "            modified_text[:end_idx] + marker_to_insert + modified_text[end_idx:]\n",
        "        )\n",
        "\n",
        "    return modified_text\n",
        "\n",
        "\n",
        "def get_citations(response, resolved_urls_map):\n",
        "    \"\"\"\n",
        "    Extracts and formats citation information from a Gemini model's response.\n",
        "\n",
        "    This function processes the grounding metadata provided in the response to\n",
        "    construct a list of citation objects. Each citation object includes the\n",
        "    start and end indices of the text segment it refers to, and a string\n",
        "    containing formatted markdown links to the supporting web chunks.\n",
        "\n",
        "    Args:\n",
        "        response: The response object from the Gemini model, expected to have\n",
        "                  a structure including `candidates[0].grounding_metadata`.\n",
        "                  It also relies on a `resolved_map` being available in its\n",
        "                  scope to map chunk URIs to resolved URLs.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary represents a citation\n",
        "              and has the following keys:\n",
        "              - \"start_index\" (int): The starting character index of the cited\n",
        "                                     segment in the original text. Defaults to 0\n",
        "                                     if not specified.\n",
        "              - \"end_index\" (int): The character index immediately after the\n",
        "                                   end of the cited segment (exclusive).\n",
        "              - \"segments\" (list[str]): A list of individual markdown-formatted\n",
        "                                        links for each grounding chunk.\n",
        "              - \"segment_string\" (str): A concatenated string of all markdown-\n",
        "                                        formatted links for the citation.\n",
        "              Returns an empty list if no valid candidates or grounding supports\n",
        "              are found, or if essential data is missing.\n",
        "    \"\"\"\n",
        "    citations = []\n",
        "\n",
        "    # Ensure response and necessary nested structures are present\n",
        "    if not response or not response.candidates:\n",
        "        return citations\n",
        "\n",
        "    candidate = response.candidates[0]\n",
        "    if (\n",
        "        not hasattr(candidate, \"grounding_metadata\")\n",
        "        or not candidate.grounding_metadata\n",
        "        or not hasattr(candidate.grounding_metadata, \"grounding_supports\")\n",
        "    ):\n",
        "        return citations\n",
        "\n",
        "    for support in candidate.grounding_metadata.grounding_supports:\n",
        "        citation = {}\n",
        "\n",
        "        # Ensure segment information is present\n",
        "        if not hasattr(support, \"segment\") or support.segment is None:\n",
        "            continue  # Skip this support if segment info is missing\n",
        "\n",
        "        start_index = (\n",
        "            support.segment.start_index\n",
        "            if support.segment.start_index is not None\n",
        "            else 0\n",
        "        )\n",
        "\n",
        "        # Ensure end_index is present to form a valid segment\n",
        "        if support.segment.end_index is None:\n",
        "            continue  # Skip if end_index is missing, as it's crucial\n",
        "\n",
        "        # Add 1 to end_index to make it an exclusive end for slicing/range purposes\n",
        "        # (assuming the API provides an inclusive end_index)\n",
        "        citation[\"start_index\"] = start_index\n",
        "        citation[\"end_index\"] = support.segment.end_index\n",
        "\n",
        "        citation[\"segments\"] = []\n",
        "        if (\n",
        "            hasattr(support, \"grounding_chunk_indices\")\n",
        "            and support.grounding_chunk_indices\n",
        "        ):\n",
        "            for ind in support.grounding_chunk_indices:\n",
        "                try:\n",
        "                    chunk = candidate.grounding_metadata.grounding_chunks[ind]\n",
        "                    resolved_url = resolved_urls_map.get(chunk.web.uri, None)\n",
        "                    citation[\"segments\"].append(\n",
        "                        {\n",
        "                            \"label\": chunk.web.title.split(\".\")[:-1][0],\n",
        "                            \"short_url\": resolved_url,\n",
        "                            \"value\": chunk.web.uri,\n",
        "                        }\n",
        "                    )\n",
        "                except (IndexError, AttributeError, NameError):\n",
        "                    # Handle cases where chunk, web, uri, or resolved_map might be problematic\n",
        "                    # For simplicity, we'll just skip adding this particular segment link\n",
        "                    # In a production system, you might want to log this.\n",
        "                    pass\n",
        "        citations.append(citation)\n",
        "    return citations"
      ],
      "metadata": {
        "id": "VDhafyh5PjtV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# state.py\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import TypedDict\n",
        "\n",
        "from langgraph.graph import add_messages\n",
        "from typing_extensions import Annotated\n",
        "\n",
        "\n",
        "import operator\n",
        "from dataclasses import dataclass, field\n",
        "from typing_extensions import Annotated\n",
        "\n",
        "\n",
        "class OverallState(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    search_query: Annotated[list, operator.add]\n",
        "    web_research_result: Annotated[list, operator.add]\n",
        "    sources_gathered: Annotated[list, operator.add]\n",
        "    initial_search_query_count: int\n",
        "    max_research_loops: int\n",
        "    research_loop_count: int\n",
        "    reasoning_model: str\n",
        "\n",
        "\n",
        "class ReflectionState(TypedDict):\n",
        "    is_sufficient: bool\n",
        "    knowledge_gap: str\n",
        "    follow_up_queries: Annotated[list, operator.add]\n",
        "    research_loop_count: int\n",
        "    number_of_ran_queries: int\n",
        "\n",
        "\n",
        "class Query(TypedDict):\n",
        "    query: str\n",
        "    rationale: str\n",
        "\n",
        "\n",
        "class QueryGenerationState(TypedDict):\n",
        "    query_list: list[Query]\n",
        "\n",
        "\n",
        "class WebSearchState(TypedDict):\n",
        "    search_query: str\n",
        "    id: str\n",
        "\n",
        "\n",
        "@dataclass(kw_only=True)\n",
        "class SearchStateOutput:\n",
        "    running_summary: str = field(default=None)  # Final report"
      ],
      "metadata": {
        "id": "cXSrKnMGRizE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jvWYW_-CO4FW"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# prompts.py\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# Get current date in a readable format\n",
        "def get_current_date():\n",
        "    return datetime.now().strftime(\"%B %d, %Y\")\n",
        "\n",
        "\n",
        "query_writer_instructions = \"\"\"Your goal is to generate sophisticated and diverse web search queries. These queries are intended for an advanced automated web research tool capable of analyzing complex results, following links, and synthesizing information.\n",
        "\n",
        "Instructions:\n",
        "- Always prefer a single search query, only add another query if the original question requests multiple aspects or elements and one query is not enough.\n",
        "- Each query should focus on one specific aspect of the original question.\n",
        "- Don't produce more than {number_queries} queries.\n",
        "- Queries should be diverse, if the topic is broad, generate more than 1 query.\n",
        "- Don't generate multiple similar queries, 1 is enough.\n",
        "- Query should ensure that the most current information is gathered. The current date is {current_date}.\n",
        "\n",
        "Format:\n",
        "- Format your response as a JSON object with ALL three of these exact keys:\n",
        "   - \"rationale\": Brief explanation of why these queries are relevant\n",
        "   - \"query\": A list of search queries\n",
        "\n",
        "Example:\n",
        "\n",
        "Topic: What revenue grew more last year apple stock or the number of people buying an iphone\n",
        "```json\n",
        "{{\n",
        "    \"rationale\": \"To answer this comparative growth question accurately, we need specific data points on Apple's stock performance and iPhone sales metrics. These queries target the precise financial information needed: company revenue trends, product-specific unit sales figures, and stock price movement over the same fiscal period for direct comparison.\",\n",
        "    \"query\": [\"Apple total revenue growth fiscal year 2024\", \"iPhone unit sales growth fiscal year 2024\", \"Apple stock price growth fiscal year 2024\"],\n",
        "}}\n",
        "```\n",
        "\n",
        "Context: {research_topic}\"\"\"\n",
        "\n",
        "\n",
        "web_searcher_instructions = \"\"\"Conduct targeted Google Searches to gather the most recent, credible information on \"{research_topic}\" and synthesize it into a verifiable text artifact.\n",
        "\n",
        "Instructions:\n",
        "- Query should ensure that the most current information is gathered. The current date is {current_date}.\n",
        "- Conduct multiple, diverse searches to gather comprehensive information.\n",
        "- Consolidate key findings while meticulously tracking the source(s) for each specific piece of information.\n",
        "- The output should be a well-written summary or report based on your search findings.\n",
        "- Only include the information found in the search results, don't make up any information.\n",
        "\n",
        "Research Topic:\n",
        "{research_topic}\n",
        "\"\"\"\n",
        "\n",
        "reflection_instructions = \"\"\"You are an expert research assistant analyzing summaries about \"{research_topic}\".\n",
        "\n",
        "Instructions:\n",
        "- Identify knowledge gaps or areas that need deeper exploration and generate a follow-up query. (1 or multiple).\n",
        "- If provided summaries are sufficient to answer the user's question, don't generate a follow-up query.\n",
        "- If there is a knowledge gap, generate a follow-up query that would help expand your understanding.\n",
        "- Focus on technical details, implementation specifics, or emerging trends that weren't fully covered.\n",
        "\n",
        "Requirements:\n",
        "- Ensure the follow-up query is self-contained and includes necessary context for web search.\n",
        "\n",
        "Output Format:\n",
        "- Format your response as a JSON object with these exact keys:\n",
        "   - \"is_sufficient\": true or false\n",
        "   - \"knowledge_gap\": Describe what information is missing or needs clarification\n",
        "   - \"follow_up_queries\": Write a specific question to address this gap\n",
        "\n",
        "Example:\n",
        "```json\n",
        "{{\n",
        "    \"is_sufficient\": true, // or false\n",
        "    \"knowledge_gap\": \"The summary lacks information about performance metrics and benchmarks\", // \"\" if is_sufficient is true\n",
        "    \"follow_up_queries\": [\"What are typical performance benchmarks and metrics used to evaluate [specific technology]?\"] // [] if is_sufficient is true\n",
        "}}\n",
        "```\n",
        "\n",
        "Reflect carefully on the Summaries to identify knowledge gaps and produce a follow-up query. Then, produce your output following this JSON format:\n",
        "\n",
        "Summaries:\n",
        "{summaries}\n",
        "\"\"\"\n",
        "\n",
        "answer_instructions = \"\"\"Generate a high-quality answer to the user's question based on the provided summaries.\n",
        "\n",
        "Instructions:\n",
        "- The current date is {current_date}.\n",
        "- You are the final step of a multi-step research process, don't mention that you are the final step.\n",
        "- You have access to all the information gathered from the previous steps.\n",
        "- You have access to the user's question.\n",
        "- Generate a high-quality answer to the user's question based on the provided summaries and the user's question.\n",
        "- you MUST include all the citations from the summaries in the answer correctly.\n",
        "\n",
        "User Context:\n",
        "- {research_topic}\n",
        "\n",
        "Summaries:\n",
        "{summaries}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# tools_and_schemas.py\n",
        "\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class SearchQueryList(BaseModel):\n",
        "    query: List[str] = Field(\n",
        "        description=\"A list of search queries to be used for web research.\"\n",
        "    )\n",
        "    rationale: str = Field(\n",
        "        description=\"A brief explanation of why these queries are relevant to the research topic.\"\n",
        "    )\n",
        "\n",
        "\n",
        "class Reflection(BaseModel):\n",
        "    is_sufficient: bool = Field(\n",
        "        description=\"Whether the provided summaries are sufficient to answer the user's question.\"\n",
        "    )\n",
        "    knowledge_gap: str = Field(\n",
        "        description=\"A description of what information is missing or needs clarification.\"\n",
        "    )\n",
        "    follow_up_queries: List[str] = Field(\n",
        "        description=\"A list of follow-up queries to address the knowledge gap.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "p0SpHWwcQEco"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# graph.py\n",
        "\n",
        "import os\n",
        "\n",
        "from langchain_core.messages import AIMessage\n",
        "from langgraph.types import Send\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph import START, END\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from google.genai import Client\n",
        "\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "if userdata.get(\"GOOGLE_API_KEY\") is None:\n",
        "    raise ValueError(\"GOOGLE_API_KEY is not set\")\n",
        "\n",
        "# Used for Google Search API\n",
        "genai_client = Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "# Nodes\n",
        "def generate_query(state: OverallState, config: RunnableConfig) -> QueryGenerationState:\n",
        "    \"\"\"LangGraph node that generates a search queries based on the User's question.\n",
        "\n",
        "    Uses Gemini 2.0 Flash to create an optimized search query for web research based on\n",
        "    the User's question.\n",
        "\n",
        "    Args:\n",
        "        state: Current graph state containing the User's question\n",
        "        config: Configuration for the runnable, including LLM provider settings\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with state update, including search_query key containing the generated query\n",
        "    \"\"\"\n",
        "    configurable = Configuration.from_runnable_config(config)\n",
        "\n",
        "    # check for custom initial search query count\n",
        "    if state.get(\"initial_search_query_count\") is None:\n",
        "        state[\"initial_search_query_count\"] = configurable.number_of_initial_queries\n",
        "\n",
        "    # init Gemini 2.0 Flash\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=configurable.query_generator_model,\n",
        "        temperature=1.0,\n",
        "        max_retries=2,\n",
        "        api_key=userdata.get(\"GOOGLE_API_KEY\"),            # os.getenv(\"GEMINI_API_KEY\"),\n",
        "    )\n",
        "    structured_llm = llm.with_structured_output(SearchQueryList)\n",
        "\n",
        "    # Format the prompt\n",
        "    current_date = get_current_date()\n",
        "    formatted_prompt = query_writer_instructions.format(\n",
        "        current_date=current_date,\n",
        "        research_topic=get_research_topic(state[\"messages\"]),\n",
        "        number_queries=state[\"initial_search_query_count\"],\n",
        "    )\n",
        "    # Generate the search queries\n",
        "    result = structured_llm.invoke(formatted_prompt)\n",
        "    return {\"query_list\": result.query}\n",
        "\n",
        "\n",
        "def continue_to_web_research(state: QueryGenerationState):\n",
        "    \"\"\"LangGraph node that sends the search queries to the web research node.\n",
        "\n",
        "    This is used to spawn n number of web research nodes, one for each search query.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        Send(\"web_research\", {\"search_query\": search_query, \"id\": int(idx)})\n",
        "        for idx, search_query in enumerate(state[\"query_list\"])\n",
        "    ]\n",
        "\n",
        "\n",
        "def web_research(state: WebSearchState, config: RunnableConfig) -> OverallState:\n",
        "    \"\"\"LangGraph node that performs web research using the native Google Search API tool.\n",
        "\n",
        "    Executes a web search using the native Google Search API tool in combination with Gemini 2.0 Flash.\n",
        "\n",
        "    Args:\n",
        "        state: Current graph state containing the search query and research loop count\n",
        "        config: Configuration for the runnable, including search API settings\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with state update, including sources_gathered, research_loop_count, and web_research_results\n",
        "    \"\"\"\n",
        "    # Configure\n",
        "    configurable = Configuration.from_runnable_config(config)\n",
        "    formatted_prompt = web_searcher_instructions.format(\n",
        "        current_date=get_current_date(),\n",
        "        research_topic=state[\"search_query\"],\n",
        "    )\n",
        "\n",
        "    # Uses the google genai client as the langchain client doesn't return grounding metadata\n",
        "    response = genai_client.models.generate_content(\n",
        "        model=configurable.query_generator_model,\n",
        "        contents=formatted_prompt,\n",
        "        config={\n",
        "            \"tools\": [{\"google_search\": {}}],\n",
        "            \"temperature\": 0,\n",
        "        },\n",
        "    )\n",
        "    # resolve the urls to short urls for saving tokens and time\n",
        "    resolved_urls = resolve_urls(\n",
        "        response.candidates[0].grounding_metadata.grounding_chunks, state[\"id\"]\n",
        "    )\n",
        "    # Gets the citations and adds them to the generated text\n",
        "    citations = get_citations(response, resolved_urls)\n",
        "    modified_text = insert_citation_markers(response.text, citations)\n",
        "    sources_gathered = [item for citation in citations for item in citation[\"segments\"]]\n",
        "\n",
        "    return {\n",
        "        \"sources_gathered\": sources_gathered,\n",
        "        \"search_query\": [state[\"search_query\"]],\n",
        "        \"web_research_result\": [modified_text],\n",
        "    }\n",
        "\n",
        "\n",
        "def reflection(state: OverallState, config: RunnableConfig) -> ReflectionState:\n",
        "    \"\"\"LangGraph node that identifies knowledge gaps and generates potential follow-up queries.\n",
        "\n",
        "    Analyzes the current summary to identify areas for further research and generates\n",
        "    potential follow-up queries. Uses structured output to extract\n",
        "    the follow-up query in JSON format.\n",
        "\n",
        "    Args:\n",
        "        state: Current graph state containing the running summary and research topic\n",
        "        config: Configuration for the runnable, including LLM provider settings\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with state update, including search_query key containing the generated follow-up query\n",
        "    \"\"\"\n",
        "    configurable = Configuration.from_runnable_config(config)\n",
        "    # Increment the research loop count and get the reasoning model\n",
        "    state[\"research_loop_count\"] = state.get(\"research_loop_count\", 0) + 1\n",
        "    # reasoning_model = state.get(\"reasoning_model\") or configurable.reasoning_model\n",
        "    # FIX: Use reflection_model from configuration as a fallback\n",
        "    reasoning_model = state.get(\"reasoning_model\") or configurable.reflection_model\n",
        "\n",
        "    # Format the prompt\n",
        "    current_date = get_current_date()\n",
        "    formatted_prompt = reflection_instructions.format(\n",
        "        current_date=current_date,\n",
        "        research_topic=get_research_topic(state[\"messages\"]),\n",
        "        summaries=\"\\n\\n---\\n\\n\".join(state[\"web_research_result\"]),\n",
        "    )\n",
        "    # init Reasoning Model\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=reasoning_model,\n",
        "        temperature=1.0,\n",
        "        max_retries=2,\n",
        "        api_key=userdata.get(\"GOOGLE_API_KEY\")               #os.getenv(\"GEMINI_API_KEY\"),\n",
        "    )\n",
        "    result = llm.with_structured_output(Reflection).invoke(formatted_prompt)\n",
        "\n",
        "    return {\n",
        "        \"is_sufficient\": result.is_sufficient,\n",
        "        \"knowledge_gap\": result.knowledge_gap,\n",
        "        \"follow_up_queries\": result.follow_up_queries,\n",
        "        \"research_loop_count\": state[\"research_loop_count\"],\n",
        "        \"number_of_ran_queries\": len(state[\"search_query\"]),\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate_research(\n",
        "    state: ReflectionState,\n",
        "    config: RunnableConfig,\n",
        ") -> OverallState:\n",
        "    \"\"\"LangGraph routing function that determines the next step in the research flow.\n",
        "\n",
        "    Controls the research loop by deciding whether to continue gathering information\n",
        "    or to finalize the summary based on the configured maximum number of research loops.\n",
        "\n",
        "    Args:\n",
        "        state: Current graph state containing the research loop count\n",
        "        config: Configuration for the runnable, including max_research_loops setting\n",
        "\n",
        "    Returns:\n",
        "        String literal indicating the next node to visit (\"web_research\" or \"finalize_summary\")\n",
        "    \"\"\"\n",
        "    configurable = Configuration.from_runnable_config(config)\n",
        "    max_research_loops = (\n",
        "        state.get(\"max_research_loops\")\n",
        "        if state.get(\"max_research_loops\") is not None\n",
        "        else configurable.max_research_loops\n",
        "    )\n",
        "    if state[\"is_sufficient\"] or state[\"research_loop_count\"] >= max_research_loops:\n",
        "        return \"finalize_answer\"\n",
        "    else:\n",
        "        return [\n",
        "            Send(\n",
        "                \"web_research\",\n",
        "                {\n",
        "                    \"search_query\": follow_up_query,\n",
        "                    \"id\": state[\"number_of_ran_queries\"] + int(idx),\n",
        "                },\n",
        "            )\n",
        "            for idx, follow_up_query in enumerate(state[\"follow_up_queries\"])\n",
        "        ]\n",
        "\n",
        "\n",
        "def finalize_answer(state: OverallState, config: RunnableConfig):\n",
        "    \"\"\"LangGraph node that finalizes the research summary.\n",
        "\n",
        "    Prepares the final output by deduplicating and formatting sources, then\n",
        "    combining them with the running summary to create a well-structured\n",
        "    research report with proper citations.\n",
        "\n",
        "    Args:\n",
        "        state: Current graph state containing the running summary and sources gathered\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with state update, including running_summary key containing the formatted final summary with sources\n",
        "    \"\"\"\n",
        "    configurable = Configuration.from_runnable_config(config)\n",
        "    # reasoning_model = state.get(\"reasoning_model\") or configurable.reasoning_model\n",
        "    # FIX: Use answer_model from configuration as a fallback\n",
        "    reasoning_model = state.get(\"reasoning_model\") or configurable.answer_model\n",
        "\n",
        "    # Format the prompt\n",
        "    current_date = get_current_date()\n",
        "    formatted_prompt = answer_instructions.format(\n",
        "        current_date=current_date,\n",
        "        research_topic=get_research_topic(state[\"messages\"]),\n",
        "        summaries=\"\\n---\\n\\n\".join(state[\"web_research_result\"]),\n",
        "    )\n",
        "\n",
        "    # init Reasoning Model, default to Gemini 2.5 Flash\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=reasoning_model,\n",
        "        temperature=0,\n",
        "        max_retries=2,\n",
        "        api_key=userdata.get(\"GOOGLE_API_KEY\"),               # os.getenv(\"GEMINI_API_KEY\"),\n",
        "    )\n",
        "    result = llm.invoke(formatted_prompt)\n",
        "\n",
        "    # Replace the short urls with the original urls and add all used urls to the sources_gathered\n",
        "    unique_sources = []\n",
        "    for source in state[\"sources_gathered\"]:\n",
        "        if source[\"short_url\"] in result.content:\n",
        "            result.content = result.content.replace(\n",
        "                source[\"short_url\"], source[\"value\"]\n",
        "            )\n",
        "            unique_sources.append(source)\n",
        "\n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=result.content)],\n",
        "        \"sources_gathered\": unique_sources,\n",
        "    }\n",
        "\n",
        "\n",
        "# Create our Agent Graph\n",
        "builder = StateGraph(OverallState, config_schema=Configuration)\n",
        "\n",
        "# Define the nodes we will cycle between\n",
        "builder.add_node(\"generate_query\", generate_query)\n",
        "builder.add_node(\"web_research\", web_research)\n",
        "builder.add_node(\"reflection\", reflection)\n",
        "builder.add_node(\"finalize_answer\", finalize_answer)\n",
        "\n",
        "# Set the entrypoint as `generate_query`\n",
        "# This means that this node is the first one called\n",
        "builder.add_edge(START, \"generate_query\")\n",
        "# Add conditional edge to continue with search queries in a parallel branch\n",
        "builder.add_conditional_edges(\n",
        "    \"generate_query\", continue_to_web_research, [\"web_research\"]\n",
        ")\n",
        "# Reflect on the web research\n",
        "builder.add_edge(\"web_research\", \"reflection\")\n",
        "# Evaluate the research\n",
        "builder.add_conditional_edges(\n",
        "    \"reflection\", evaluate_research, [\"web_research\", \"finalize_answer\"]\n",
        ")\n",
        "# Finalize the answer\n",
        "builder.add_edge(\"finalize_answer\", END)\n",
        "\n",
        "graph = builder.compile(name=\"pro-search-agent\")"
      ],
      "metadata": {
        "id": "15nkRjxDQjZG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enter your prompt below"
      ],
      "metadata": {
        "id": "RiX4CqozeFic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = \"Explain in detail on usecases that can leverage LangGraph with Google Gemini models.\""
      ],
      "metadata": {
        "id": "bCTUS2L6dKeh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt1}], \"max_research_loops\": 3, \"initial_search_query_count\": 3})"
      ],
      "metadata": {
        "id": "QfruGmSYSKnj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(state[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "ETM-ukepSXhx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a255da52-db37-4997-bd92-8a4c5771c7eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "LangGraph, an extension of LangChain, provides a robust framework for developing stateful, multi-actor applications powered by Large Language Models (LLMs), including Google's Gemini models [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGstQdA0G2NyxK6qUIW_vpur4t1Hgws_-BBGtChcA31WONzZsUmD1HqLVLRLGVZ3FlfCXofkY_xZjvCItpgpMJRqxCujbqUqvWWNAQ5qnJlPuKYCinAK2N5TDbEwWRN45t0WFY47ISa94DIltgD3-iJFZxGK-ajW_QEZAsoEWP3qrYHRSS3Dwl7-SOxDXM-WAuTMcz6Qg==) [huggingface](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvmt16SMtPU94AGZM_itbIt0Tr9h1xwoyIGpQC5D2zWuU54W02gicL4wcKcvnDYsln0wi8tz-LS_YzZ0x9FwQPeWoeQIPslIcfZ_rx5hdRXbaJESjyOl4RBIwHQutMcQp-frlBv6Bhv7qJc72dkxVds2yCzG8w_Qk8EsPl8L_Q8RE=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHJNK6udwSk_6juzloBhem_FucJpnHusQwZmqJ22mlAXNoJib4KdGXaF7T6KN-etYm1xve1TRwDX1klAl-OkmVYdeozJLy6a_C5I3DxMZ4hd8GYekjgDtHsI84c1pWSvAhxp7YWUFuhbraQIHE4H40E) [1, 5]. It models workflows as graphs, where each node represents a step (e.g., an LLM call or tool execution) and edges define the flow of control [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGstQdA0G2NyxK6qUIW_vpur4t1Hgws_-BBGtChcA31WONzZsUmD1HqLVLRLGVZ3FlfCXofkY_xZjvCItpgpMJRqxCujbqUqvWWNAQ5qnJlPuKYCinAK2N5TDbEwWRN45t0WFY47ISa94DIltgD3-iJFZxGK-ajW_QEZAsoEWP3qrYHRSS3Dwl7-SOxDXM-WAuTMcz6Qg==) [1, 5]. This graph-based approach is particularly beneficial for complex, stateful workflows that require clear visibility and control over an agent's reasoning process [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGstQdA0G2NyxK6qUIW_vpur4t1Hgws_-BBGtChcA31WONzZsUmD1HqLVLRLGVZ3FlfCXofkY_xZjvCItpgpMJRqxCujbqUqvWWNAQ5qnJlPuKYCinAK2N5TDbEwWRN45t0WFY47ISa94DIltgD3-iJFZxGK-ajW_QEZAsoEWP3qrYHRSS3Dwl7-SOxDXM-WAuTMcz6Qg==) [1].\n\nHere are detailed use cases that can leverage LangGraph with Google Gemini models:\n\n### Core Concepts and Architectural Patterns\n\nLangGraph's design facilitates the creation of sophisticated AI applications through its fundamental components:\n*   **State:** A shared data structure (often a TypedDict or Pydantic BaseModel) that maintains the application's current snapshot, persisting across different nodes in a workflow [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGp1wwnv1OYMUuBXqO7VKXvq3dGMf0knV6Qhl8apFr1y6sTCkwmlA9YereGAQvr6cfd5DkSqePZJZCJXnoNECu1I0e2LsozuOxNPw8f0nxS_PVLeK3u08M_zyHh-sYJsSqWG38WWIEWRsJp6VV0JawH_oQRJJo=) [1, 4]. The `AgentState` dataclass, for instance, tracks fields like the user's query, retrieved context, analysis, generated response, and recommended next action [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHpv5J4jgfQ2fp5z59nugTSmEQDrRkEyJ6F07UAqmx6r_FwERzTNWb_FAmeyzrntLYgzAXy3nD9npmGvJs4SFgZ54VdOtTzXn1STp2UQtUWzOVfKeNYeHOKrTlBEbr2HyksJuEx2_YXF9ZWLEvjZvmXpk9G2tAZDgtQ2A_f78QZoVeBEOSg5clwMqMXvKlXaDeV5_M5764pYwhSOcgxWL-HYnovn3SFkv7V846Lh0O6Gw3xXPnI1uRfSOtYbOPxE4RVtMCeb18=) [3].\n*   **Nodes:** These encapsulate the logic of individual agents or steps within the workflow. Nodes receive the current State as input, perform computations (such as LLM calls or tool invocations), and return an updated State [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGp1wwnv1OYMUuBXqO7VKXvq3dGMf0knV6Qhl8apFr1y6sTCkwmlA9YereGAQvr6cfd5DkSqePZJZCJXnoNECu1I0e2LsozuOxNPw8f0nxS_PVLeK3u08M_zyHh-sYJsSqWG38WWIEWRsJp6VV0JawH_oQRJJo=) [1, 4].\n*   **Edges:** Edges dictate the flow of control, defining which node executes next based on the current State. This allows for both fixed transitions and dynamic, conditional logic [1, 2, 4].\n\nThese components enable several powerful architectural patterns:\n\n*   **AI Agents:** LangGraph, combined with Gemini models, forms a strong foundation for building AI agents capable of perceiving their environment, making decisions, and executing actions to achieve specific goals [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGstQdA0G2NyxK6qUIW_vpur4t1Hgws_-BBGtChcA31WONzZsUmD1HqLVLRLGVZ3FlfCXofkY_xZjvCItpgpMJRqxCujbqUqvWWNAQ5qnJlPuKYCinAK2N5TDbEwWRN45t0WFY47ISa94DIltgD3-iJFZxGK-ajW_QEZAsoEWP3qrYHRSS3Dwl7-SOxDXM-WAuTMcz6Qg==) [ubos](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx1RAAvUKSuVJjH9gfvFtjmKgvnKWlhGiaXXyqDvt6NJZoNo47sjt7HolaUg9IBbBF-sB0fycf9vz2s4tTw6k7Vgy6D_Q6jFUewNO8MT88l-1VgBiY5JAgcI-uE36xmq0pU3n-Og2MEXjir-l1TdVI1sgMHiIeTsriwQBD0dma--Hk4psXR5y5rYui2YOlEQzTqmumGdDo8YKz) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHOa4cCbkDSMCEZpMRXQ15l0f_zal1Cz7G2WC-GZYKXXk5XQw0KsHooVpYpMFeTlccvQ_yrCMmORnWW2Qu1U3ftX3VBbdA6eafpGWfsC_M3KULUR5Bc8iD90k1wC5uKHgszYq1pONz1CdT-IhvmREx68FvnpAQ=) [1].\n*   **Stateful Workflows:** LangGraph and Gemini models structure AI reasoning into stateful workflows, allowing an incoming query to progress through a series of nodes for tasks like routing, analysis, research, response generation, and validation [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHpv5J4jgfQ2fp5z59nugTSmEQDrRkEyJ6F07UAqmx6r_FwERzTNWb_FAmeyzrntLYgzAXy3nD9npmGvJs4SFgZ54VdOtTzXn1STp2UQtUWzOVfKeNYeHOKrTlBEbr2HyksJuEx2_YXF9ZWLEvjZvmXpk9G2tAZDgtQ2A_f78QZoVeBEOSg5clwMqMXvKlXaDeV5_M5764pYwhSOcgxWL-HYnovn3SFkv7V846Lh0O6Gw3xXPnI1uRfSOtYbOPxE4RVtMCeb18=) [ubos](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx1RAAvUKSuVJjH9gfvFtjmKgvnKWlhGiaXXyqDvt6NJZoNo47sjt7HolaUg9IBbBF-sB0fycf9vz2s4tTw6k7Vgy6D_Q6jFUewNO8MT88l-1VgBiY5JAgcI-uE36xmq0pU3n-Og2MEXjir-l1TdVI1sgMHiIeTsriwQBD0dma--Hk4psXR5y5rYui2YOlEQzTqmumGdDo8YKz) [2, 3]. The `GraphAIAgent` class, for example, orchestrates nodes such as router, analyzer, researcher, responder, and validator [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHpv5J4jgfQ2fp5z59nugTSmEQDrRkEyJ6F07UAqmx6r_FwERzTNWb_FAmeyzrntLYgzAXy3nD9npmGvJs4SFgZ54VdOtTzXn1STp2UQtUWzOVfKeNYeHOKrTlBEbr2HyksJuEx2_YXF9ZWLEvjZvmXpk9G2tAZDgtQ2A_f78QZoVeBEOSg5clwMqMXvKlXaDeV5_M5764pYwhSOcgxWL-HYnovn3SFkv7V846Lh0O6Gw3xXPnI1uRfSOtYbOPxE4RVtMCeb18=) [ubos](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx1RAAvUKSuVJjH9gfvFtjmKgvnKWlhGiaXXyqDvt6NJZoNo47sjt7HolaUg9IBbBF-sB0fycf9vz2s4tTw6k7Vgy6D_Q6jFUewNO8MT88l-1VgBiY5JAgcI-uE36xmq0pU3n-Og2MEXjir-l1TdVI1sgMHiIeTsriwQBD0dma--Hk4psXR5y5rYui2YOlEQzTqmumGdDo8YKz) [2].\n*   **ReAct Agents:** LangGraph is particularly well-suited for constructing ReAct (Reasoning and Acting) Agents. These agents combine LLM reasoning with action execution, iteratively thinking, using tools, and acting on observations to dynamically adapt and achieve user goals [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGk3U4LFwGzRE509Ya98ghoYuI7ooo5planG5atbjq6P62m0swaoH1mspiuBkTOnCo3p3F09OtvOr8TBtjcoK_fTskXnk1ccKtpDDeU74yjvCiNz-WzFL2VWHl9Bk6K7dIFZxaPhYFThyzgCxeP5yjsr6I=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHOa4cCbkDSMCEZpMRXQ15l0f_zal1Cz7G2WC-GZYKXXk5XQw0KsHooVpYpMFeTlccvQ_yrCMmORnWW2Qu1U3ftX3VBbdA6eafpGWfsC_M3KULUR5Bc8iD90k1wC5uKHgszYq1pONz1CdT-IhvmREx68FvnpAQ=) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [huggingface](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH69nCSvxyR6rjSd4enlgbupDmKMNBZ4tFFf_WDNomOdWCxP32s1BltCF_8U4maHtyfoJcL2tSPl5gdaNMulHv9-DQR55Pz1Zuvfa8EDlHzJp27VZCmNwQet1LPRLKkcGmuAGg_fzShLqonlmnhZGcXfDNK-uHDOoF6ajDyBE0YKYU=) [4, 9].\n*   **Multi-Agent Systems:** LangGraph simplifies the development of multi-agent systems by enabling the definition of agents with specific roles and goals, and then assigning tasks to them [1]. Several architectures can be employed for connecting agents:\n    *   **Network:** Each agent can communicate with every other agent, and any agent can decide which other agent to call next [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0QPL8ULBPwdLoKyg60Dna8Fyw0_R_7_flSZB5FjLxU9HgKG3aY4ICe3C7dkDOAkmcOpTbkhZgWVGXDrKw9rt-qO-g4KkPiaMWSx1CR28Q9ajZajQ9O3vzT6kHxjjJUz9DThf08G3V2FS-D9iJRh299i3VJO0Au7tc) [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE5HgrK8nj4KMKRsSsbJNmVwIXC04cAa6fqN5aeeCjKx5lHvoV-N2YarqDv9EymXK0uv2iWZu2jaN3dyGbGMfKiKfmnDVK_EPeqaG37ZsgR_tOnpxITbEDkXb5uzl8dUFvLAX9McFMATQ4Am3sakmPPdYGVGL4KII6Yl3LQbSARwpccia1KjegvPLrCTdrqC4djGHPHZwIgeVUU0QpG) [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEx-Ke30g0yCSKbfGD233KQpBDliiSepkXX8xqBlOOJC90Yi4TWvhN3idVeCswgI728UuLicjBymTYSJcNg-4lipvtsxU7vCi74STU02MORTo4LXU_IP9CZTdY9lHsSE6Hrvh8G36saYQRrdX7jxicv7I18JKF8tETxdrAaSmENqfxKNcDT5qGxMLS2sF5O42911JD2c3WYer1mGh-fTYzpJQ1LXWGduuc1lnVhZTmQCcxmgQbx31ZWS0ZO7Rm87QcwUgiDDgTcnofTitcXCCvTHgr-c4KGf_rPuJ8rEndL_Q==) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0QPL8ULBPwdLoKyg60Dna8Fyw0_R_7_flSZB5FjLxU9HgKG3aY4ICe3C7dkDOAkmcOpTbkhZgWVGXDrKw9rt-qO-g4KkPiaMWSx1CR28Q9ajZajQ9O3vzT6kHxjjJUz9DThf08G3V2FS-D9iJRh299i3VJO0Au7tc) [langchain](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhewNsTDggem59eN_--oak0eZgE7ebTqXpl0grM-jt-xSsO0HNxMNPNG3ilcmZWnFBq_h_PQw60D8l10awO7z4K4_tlK36LXP9-ZuN2xsjByoxFza3VdKC6b0SZ1ds8rPBkhZo2CUR19I=) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGlLcJk-j2I5AbMnP4SNQqic6NYMCJKi_5FRkWByuz8_oemFLtc4V_dHwRePkGEzPAkkI4RunZ6VUk5024qiWZpZT_DHoBxcYCpigAz3qP4Ou_Lgigcj0Ufo-MV93fLGn8coACIPYVtr7tNP4f6cWQ6fvRhfZbV73slWo_vcTRxmM3iqvbaU3HiDz1nM6FLcOVSNrfaIFv9cNhqXDEPrCF2jAjKz95mi2syHolVUrEXZxs4) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFzeCK4r-cyJe4yJGzU4L-nHGcLZbfv8cd3zsMg0BlTMxmamjVuW-9Uam0RwjArvnj41irG22w0_3O1EXzipDC95fw9LaegR92IRMVg5RxTY-PgzsVpEfg7CI2JGRTbmsqJZlU637hPL5dFoAo3J69OnMERjuCiaKjtvMi9YtdSnwE=) [analyticsvidhya](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=0) [9].\n    *   **Supervisor:** Each agent communicates with a single supervisor agent, which makes decisions on which agent should be called next [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0QPL8ULBPwdLoKyg60Dna8Fyw0_R_7_flSZB5FjLxU9HgKG3aY4ICe3C7dkDOAkmcOpTbkhZgWVGXDrKw9rt-qO-g4KkPiaMWSx1CR28Q9ajZajQ9O3vzT6kHxjjJUz9DThf08G3V2FS-D9iJRh299i3VJO0Au7tc) [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE5HgrK8nj4KMKRsSsbJNmVwIXC04cAa6fqN5aeeCjKx5lHvoV-N2YarqDv9EymXK0uv2iWZu2jaN3dyGbGMfKiKfmnDVK_EPeqaG37ZsgR_tOnpxITbEDkXb5uzl8dUFvLAX9McFMATQ4Am3sakmPPdYGVGL4KII6Yl3LQbSARwpccia1KjegvPLrCTdrqC4djGHPHZwIgeVUU0QpG) [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEx-Ke30g0yCSKbfGD233KQpBDliiSepkXX8xqBlOOJC90Yi4TWvhN3idVeCswgI728UuLicjBymTYSJcNg-4lipvtsxU7vCi74STU02MORTo4LXU_IP9CZTdY9lHsSE6Hrvh8G36saYQRrdX7jxicv7I18JKF8tETxdrAaSmENqfxKNcDT5qGxMLS2sF5O42911JD2c3WYer1mGh-fTYzpJQ1LXWGduuc1lnVhZTmQCcxmgQbx31ZWS0ZO7Rm87QcwUgiDDgTcnofTitcXCCvTHgr-c4KGf_rPuJ8rEndL_Q==) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0QPL8ULBPwdLoKyg60Dna8Fyw0_R_7_flSZB5FjLxU9HgKG3aY4ICe3C7dkDOAkmcOpTbkhZgWVGXDrKw9rt-qO-g4KkPiaMWSx1CR28Q9ajZajQ9O3vzT6kHxjjJUz9DThf08G3V2FS-D9iJRh299i3VJO0Au7tc) [langchain](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhewNsTDggem59eN_--oak0eZgE7ebTqXpl0grM-jt-xSsO0HNxMNPNG3ilcmZWnFBq_h_PQw60D8l10awO7z4K4_tlK36LXP9-ZuN2xsjByoxFza3VdKC6b0SZ1ds8rPBkhZo2CUR19I=) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGlLcJk-j2I5AbMnP4SNQqic6NYMCJKi_5FRkWByuz8_oemFLtc4V_dHwRePkGEzPAkkI4RunZ6VUk5024qiWZpZT_DHoBxcYCpigAz3qP4Ou_Lgigcj0Ufo-MV93fLGn8coACIPYVtr7tNP4f6cWQ6fvRhfZbV73slWo_vcTRxmM3iqvbaU3HiDz1nM6FLcOVSNrfaIFv9cNhqXDEPrCF2jAjKz95mi2syHolVUrEXZxs4) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFzeCK4r-cyJe4yJGzU4L-nHGcLZbfv8cd3zsMg0BlTMxmamjVuW-9Uam0RwjArvnj41irG22w0_3O1EXzipDC95fw9LaegR92IRMVg5RxTY-PgzsVpEfg7CI2JGRTbmsqJZlU637hPL5dFoAo3J69OnMERjuCiaKjtvMi9YtdSnwE=) [analyticsvidhya](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=0) [9].\n    *   **Supervisor (tool-calling):** A specialized case where individual agents are represented as tools, and a supervisor agent uses a tool-calling LLM to decide which agent tool to invoke [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0QPL8ULBPwdLoKyg60Dna8Fyw0_R_7_flSZB5FjLxU9HgKG3aY4ICe3C7dkDOAkmcOpTbkhZgWVGXDrKw9rt-qO-g4KkPiaMWSx1CR28Q9ajZajQ9O3vzT6kHxjjJUz9DThf08G3V2FS-D9iJRh299i3VJO0Au7tc) [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE5HgrK8nj4KMKRsSsbJNmVwIXC04cAa6fqN5aeeCjKx5lHvoV-N2YarqDv9EymXK0uv2iWZu2jaN3dyGbGMfKiKfmnDVK_EPeqaG37ZsgR_tOnpxITbEDkXb5uzl8dUFvLAX9McFMATQ4Am3sakmPPdYGVGL4KII6Yl3LQbSARwpccia1KjegvPLrCTdrqC4djGHPHZwIgeVUU0QpG) [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEx-Ke30g0yCSKbfGD233KQpBDliiSepkXX8xqBlOOJC90Yi4TWvhN3idVeCswgI728UuLicjBymTYSJcNg-4lipvtsxU7vCi74STU02MORTo4LXU_IP9CZTdY9lHsSE6Hrvh8G36saYQRrdX7jxicv7I18JKF8tETxdrAaSmENqfxKNcDT5qGxMLS2sF5O42911JD2c3WYer1mGh-fTYzpJQ1LXWGduuc1lnVhZTmQCcxmgQbx31ZWS0ZO7Rm87QcwUgiDDgTcnofTitcXCCvTHgr-c4KGf_rPuJ8rEndL_Q==) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0QPL8ULBPwdLoKyg60Dna8Fyw0_R_7_flSZB5FjLxU9HgKG3aY4ICe3C7dkDOAkmcOpTbkhZgWVGXDrKw9rt-qO-g4KkPiaMWSx1CR28Q9ajZajQ9O3vzT6kHxjjJUz9DThf08G3V2FS-D9iJRh299i3VJO0Au7tc) [langchain](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhewNsTDggem59eN_--oak0eZgE7ebTqXpl0grM-jt-xSsO0HNxMNPNG3ilcmZWnFBq_h_PQw60D8l10awO7z4K4_tlK36LXP9-ZuN2xsjByoxFza3VdKC6b0SZ1ds8rPBkhZo2CUR19I=) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGlLcJk-j2I5AbMnP4SNQqic6NYMCJKi_5FRkWByuz8_oemFLtc4V_dHwRePkGEzPAkkI4RunZ6VUk5024qiWZpZT_DHoBxcYCpigAz3qP4Ou_Lgigcj0Ufo-MV93fLGn8coACIPYVtr7tNP4f6cWQ6fvRhfZbV73slWo_vcTRxmM3iqvbaU3HiDz1nM6FLcOVSNrfaIFv9cNhqXDEPrCF2jAjKz95mi2syHolVUrEXZxs4) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFzeCK4r-cyJe4yJGzU4L-nHGcLZbfv8cd3zsMg0BlTMxmamjVuW-9Uam0RwjArvnj41irG22w0_3O1EXzipDC95fw9LaegR92IRMVg5RxTY-PgzsVpEfg7CI2JGRTbmsqJZlU637hPL5dFoAo3J69OnMERjuCiaKjtvMi9YtdSnwE=) [analyticsvidhya](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=0) [9].\n    *   **Hierarchical:** A multi-agent system featuring a supervisor of supervisors, enabling more intricate control flows [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0QPL8ULBPwdLoKyg60Dna8Fyw0_R_7_flSZB5FjLxU9HgKG3aY4ICe3C7dkDOAkmcOpTbkhZgWVGXDrKw9rt-qO-g4KkPiaMWSx1CR28Q9ajZajQ9O3vzT6kHxjjJUz9DThf08G3V2FS-D9iJRh299i3VJO0Au7tc) [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE5HgrK8nj4KMKRsSsbJNmVwIXC04cAa6fqN5aeeCjKx5lHvoV-N2YarqDv9EymXK0uv2iWZu2jaN3dyGbGMfKiKfmnDVK_EPeqaG37ZsgR_tOnpxITbEDkXb5uzl8dUFvLAX9McFMATQ4Am3sakmPPdYGVGL4KII6Yl3LQbSARwpccia1KjegvPLrCTdrqC4djGHPHZwIgeVUU0QpG) [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEx-Ke30g0yCSKbfGD233KQpBDliiSepkXX8xqBlOOJC90Yi4TWvhN3idVeCswgI728UuLicjBymTYSJcNg-4lipvtsxU7vCi74STU02MORTo4LXU_IP9CZTdY9lHsSE6Hrvh8G36saYQRrdX7jxicv7I18JKF8tETxdrAaSmENqfxKNcDT5qGxMLS2sF5O42911JD2c3WYer1mGh-fTYzpJQ1LXWGduuc1lnVhZTmQCcxmgQbx31ZWS0ZO7Rm87QcwUgiDDgTcnofTitcXCCvTHgr-c4KGf_rPuJ8rEndL_Q==) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0QPL8ULBPwdLoKyg60Dna8Fyw0_R_7_flSZB5FjLxU9HgKG3aY4ICe3C7dkDOAkmcOpTbkhZgWVGXDrKw9rt-qO-g4KkPiaMWSx1CR28Q9ajZajQ9O3vzT6kHxjjJUz9DThf08G3V2FS-D9iJRh299i3VJO0Au7tc) [langchain](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhewNsTDggem59eN_--oak0eZgE7ebTqXpl0grM-jt-xSsO0HNxMNPNG3ilcmZWnFBq_h_PQw60D8l10awO7z4K4_tlK36LXP9-ZuN2xsjByoxFza3VdKC6b0SZ1ds8rPBkhZo2CUR19I=) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGlLcJk-j2I5AbMnP4SNQqic6NYMCJKi_5FRkWByuz8_oemFLtc4V_dHwRePkGEzPAkkI4RunZ6VUk5024qiWZpZT_DHoBxcYCpigAz3qP4Ou_Lgigcj0Ufo-MV93fLGn8coACIPYVtr7tNP4f6cWQ6fvRhfZbV73slWo_vcTRxmM3iqvbaU3HiDz1nM6FLcOVSNrfaIFv9cNhqXDEPrCF2jAjKz95mi2syHolVUrEXZxs4) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFzeCK4r-cyJe4yJGzU4L-nHGcLZbfv8cd3zsMg0BlTMxmamjVuW-9Uam0RwjArvnj41irG22w0_3O1EXzipDC95fw9LaegR92IRMVg5RxTY-PgzsVpEfg7CI2JGRTbmsqJZlU637hPL5dFoAo3J69OnMERjuCiaKjtvMi9YtdSnwE=) [analyticsvidhya](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=0) [9].\n\n### Key Use Cases and Implementation Examples\n\nLangGraph with Google Gemini models can be applied to a wide array of complex scenarios:\n\n*   **Research-Augmented Conversational AI (Deep Research Agent):** This is a prominent use case where LangGraph and Gemini models can build conversational AI that provides answers with a transparent research process and citations [huggingface](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvmt16SMtPU94AGZM_itbIt0Tr9h1xwoyIGpQC5D2zWuU54W02gicL4wcKcvnDYsln0wi8tz-LS_YzZ0x9FwQPeWoeQIPslIcfZ_rx5hdRXbaJESjyOl4RBIwHQutMcQp-frlBv6Bhv7qJc72dkxVds2yCzG8w_Qk8EsPl8L_Q8RE=) [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcYcpZdhIDia2dRPbxXFimlM3Rs-bXmZj7O5arNhyD3YJhfGK9Aiy_HDGjfUVm_EWaeI0dVganlVyFb7KhpNNUKWNa8oOL0Wh4Oq39L0R243yUciDn-5WLx2nFvA8gWZq7JJsKsgO1XL-69g2qBadUbjPQBm7cGZIG1FhqUydWYh8=) [5, 6]. An example project, the \"Gemini Fullstack LangGraph Quickstart,\" demonstrates a backend agent that performs in-depth research. This agent dynamically generates search terms, queries the web, evaluates gathered information, and iteratively refines its search strategy to deliver well-supported responses [huggingface](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvmt16SMtPU94AGZM_itbIt0Tr9h1xwoyIGpQC5D2zWuU54W02gicL4wcKcvnDYsln0wi8tz-LS_YzZ0x9FwQPeWoeQIPslIcfZ_rx5hdRXbaJESjyOl4RBIwHQutMcQp-frlBv6Bhv7qJc72dkxVds2yCzG8w_Qk8EsPl8L_Q8RE=) [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcYcpZdhIDia2dRPbxXFimlM3Rs-bXmZj7O5arNhyD3YJhfGK9Aiy_HDGjfUVm_EWaeI0dVganlVyFb7KhpNNUKWNa8oOL0Wh4Oq39L0R243yUciDn-5WLx2nFvA8gWZq7JJsKsgO1XL-69g2qBadUbjPQBm7cGZIG1FhqUydWYh8=) [5, 6, 7].\n*   **Multimodal Agents:** LangGraph can be combined with Gemini to create multimodal agents capable of detecting objects in images, audio, and video [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGlLcJk-j2I5AbMnP4SNQqic6NYMCJKi_5FRkWByuz8_oemFLtc4V_dHwRePkGEzPAkkI4RunZ6VUk5024qiWZpZT_DHoBxcYCpigAz3qP4Ou_Lgigcj0Ufo-MV93fLGn8coACIPYVtr7tNP4f6cWQ6fvRhfZbV73slWo_vcTRxmM3iqvbaU3HiDz1nM6FLcOVSNrfaIFv9cNhqXDEPrCF2jAjKz95mi2syHolVUrEXZxs4) [8]. This is valuable for applications like content moderation, multimedia search, and retrieval [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGlLcJk-j2I5AbMnP4SNQqic6NYMCJKi_5FRkWByuz8_oemFLtc4V_dHwRePkGEzPAkkI4RunZ6VUk5024qiWZpZT_DHoBxcYCpigAz3qP4Ou_Lgigcj0Ufo-MV93fLGn8coACIPYVtr7tNP4f6cWQ6fvRhfZbV73slWo_vcTRxmM3iqvbaU3HiDz1nM6FLcOVSNrfaIFv9cNhqXDEPrCF2jAjKz95mi2syHolVUrEXZxs4) [6]. Such systems often involve an Orchestrator Agent that dispatches tasks to specialized worker agents (e.g., `image_agent`, `audio_agent`, `video_agent`) for analyzing different file types [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE5HgrK8nj4KMKRsSsbJNmVwIXC04cAa6fqN5aeeCjKx5lHvoV-N2YarqDv9EymXK0uv2iWZu2jaN3dyGbGMfKiKfmnDVK_EPeqaG37ZsgR_tOnpxITbEDkXb5uzl8dUFvLAX9McFMATQ4Am3sakmPPdYGVGL4KII6Yl3LQbSARwpccia1KjegvPLrCTdrqC4djGHPHZwIgeVUU0QpG) [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEx-Ke30g0yCSKbfGD233KQpBDliiSepkXX8xqBlOOJC90Yi4TWvhN3idVeCswgI728UuLicjBymTYSJcNg-4lipvtsxU7vCi74STU02MORTo4LXU_IP9CZTdY9lHsSE6Hrvh8G36saYQRrdX7jxicv7I18JKF8tETxdrAaSmENqfxKNcDT5qGxMLS2sF5O42911JD2c3WYer1mGh-fTYzpJQ1LXWGduuc1lnVhZTmQCcxmgQbx31ZWS0ZO7Rm87QcwUgiDDgTcnofTitcXCCvTHgr-c4KGf_rPuJ8rEndL_Q==) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0QPL8ULBPwdLoKyg60Dna8Fyw0_R_7_flSZB5FjLxU9HgKG3aY4ICe3C7dkDOAkmcOpTbkhZgWVGXDrKw9rt-qO-g4KkPiaMWSx1CR28Q9ajZajQ9O3vzT6kHxjjJUz9DThf08G3V2FS-D9iJRh299i3VJO0Au7tc) [langchain](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhewNsTDggem59eN_--oak0eZgE7ebTqXpl0grM-jt-xSsO0HNxMNPNG3ilcmZWnFBq_h_PQw60D8l10awO7z4K4_tlK36LXP9-ZuN2xsjByoxFza3VdKC6b0SZ1ds8rPBkhZo2CUR19I=) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGlLcJk-j2I5AbMnP4SNQqic6NYMCJKi_5FRkWByuz8_oemFLtc4V_dHwRePkGEzPAkkI4RunZ6VUk5024qiWZpZT_DHoBxcYCpigAz3qP4Ou_Lgigcj0Ufo-MV93fLGn8coACIPYVtr7tNP4f6cWQ6fvRhfZbV73slWo_vcTRxmM3iqvbaU3HiDz1nM6FLcOVSNrfaIFv9cNhqXDEPrCF2jAjKz95mi2syHolVUrEXZxs4) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFzeCK4r-cyJe4yJGzU4L-nHGcLZbfv8cd3zsMg0BlTMxmamjVuW-9Uam0RwjArvnj41irG22w0_3O1EXzipDC95fw9LaegR92IRMVg5RxTY-PgzsVpEfg7CI2JGRTbmsqJZlU637hPL5dFoAo3J69OnMERjuCiaKjtvMi9YtdSnwE=) [analyticsvidhya](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=0) [6].\n*   **Intelligent Conversational Agents (e.g., Sightseeing Agent):** An intelligent, conversational sightseeing agent can be built using LangGraph, Gemini LLM, and Google Maps APIs. Its core logic is structured as a graph, explicitly defining the flow of information and actions needed to help a user plan a trip. This involves a defined state schema (e.g., `TravelPlanState`) and conditional edges for dynamic routing based on the agent's output [kaggle](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=1) [2].\n*   **Specialized Research Agents (e.g., Paper-to-Voice Assistant):** A research agent can be developed to summarize research papers, potentially using a vision model to infer information from documents, and then convert the summary to voice [analyticsvidhya](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=0) [5].\n*   **Educational Systems (e.g., Aidemy):** Multi-agent systems on Google Cloud can be created for educational purposes, such as generating on-demand quizzes and dynamic content, leveraging Gemini models within an event-driven architecture [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFzeCK4r-cyJe4yJGzU4L-nHGcLZbfv8cd3zsMg0BlTMxmamjVuW-9Uam0RwjArvnj41irG22w0_3O1EXzipDC95fw9LaegR92IRMVg5RxTY-PgzsVpEfg7CI2JGRTbmsqJZlU637hPL5dFoAo3J69OnMERjuCiaKjtvMi9YtdSnwE=) [8].\n*   **Modular Enterprise AI Assistants (e.g., Vodafone):** Companies like Vodafone have utilized LangGraph to construct modular AI assistants. These assistants are designed as subgraphs, with each subgraph containing specific tools responsible for a particular task. This modularity allows for easy addition of new capabilities, such as data collection, processing, report generation, and advanced reasoning using Retrieval-Augmented Generation (RAG) pipelines [langchain](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGhewNsTDggem59eN_--oak0eZgE7ebTqXpl0grM-jt-xSsO0HNxMNPNG3ilcmZWnFBq_h_PQw60D8l10awO7z4K4_tlK36LXP9-ZuN2xsjByoxFza3VdKC6b0SZ1ds8rPBkhZo2CUR19I=) [15].\n*   **Tool Integration:** Gemini models' function calling capabilities allow LangGraph agents to interact seamlessly with external tools, APIs, and data sources, enabling them to perform real-world actions. This includes integrating tools for web scraping, search, and specialized APIs for domains like finance and maps [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE68XprQniA6e1-BJqh4c-QIPHWDjq1SeyZIFyTb0JWc7IOGol45eMhXytr58Z8IX3lGwYnEImGi_ZEZucDV3rLvUK5A6LC_yiazMGtJMkcwxe6VnQmjamgGLz6pHC6Zyt3WKuZSNeYJiDjDWKUzL58muq-CK7yD3ojGRYc5vJmhvDS8Q-hX538kF01LDW4njeBdJxEtB2Zng2KIJcI4cqrBNOOJ38dgeBx-D3KtqTRXqQh_kkJ9UBYpTjPGXrSPPEO0aC0CbxYQ-YIxluKO12zdyWpZdky-edyeRaqfVFTKg==) [1, 12]. A simple ReAct agent for weather information, for instance, uses a tool to find current weather for a specified location, with the state maintaining conversation history and step count [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [1].\n\n### Practical Implementation Details\n\nWhen building LangGraph agents with Gemini, several practical aspects are key:\n\n*   **Node Configurations:** Common node types include `call_tool` (often using LangGraph's prebuilt `ToolNode`) for executing tool methods, and `call_model` for invoking the Gemini model [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGp1wwnv1OYMUuBXqO7VKXvq3dGMf0knV6Qhl8apFr1y6sTCkwmlA9YereGAQvr6cfd5DkSqePZJZCJXnoNECu1I0e2LsozuOxNPw8f0nxS_PVLeK3u08M_zyHh-sYJsSqWG38WWIEWRsJp6VV0JawH_oQRJJo=) [1]. Custom nodes can also be added for structured output or self-verification/reflection [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGp1wwnv1OYMUuBXqO7VKXvq3dGMf0knV6Qhl8apFr1y6sTCkwmlA9YereGAQvr6cfd5DkSqePZJZCJXnoNECu1I0e2LsozuOxNPw8f0nxS_PVLeK3u08M_zyHh-sYJsSqWG38WWIEWRsJp6VV0JawH_oQRJJo=) [1, 4]. A `user_input` node can display agent responses and prompt for the next user query [kaggle](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=1) [2].\n*   **Edge Configurations:** Edges define transitions. A `should_continue` edge can decide whether to call a tool or the model [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGp1wwnv1OYMUuBXqO7VKXvq3dGMf0knV6Qhl8apFr1y6sTCkwmlA9YereGAQvr6cfd5DkSqePZJZCJXnoNECu1I0e2LsozuOxNPw8f0nxS_PVLeK3u08M_zyHh-sYJsSqWG38WWIEWRsJp6VV0JawH_oQRJJo=) [1, 4]. Conditional edges enable dynamic workflow based on node outcomes [2, 8], while some transitions might be fixed (e.g., from tools back to the agent) [kaggle](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=1) [2].\n*   **State Management:** LangGraph provides helpers like `add_messages` for efficiently updating message lists within the agent's state [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [1].\n*   **Tool Integration:** Tools are bound to the LLM, allowing the Gemini model to understand their purpose and request their execution with appropriate arguments [kaggle](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=1) [2].\n*   **Dynamic Control Flow:** LangGraph empowers LLMs to influence parts of the application's control flow using `Command` objects [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF0QPL8ULBPwdLoKyg60Dna8Fyw0_R_7_flSZB5FjLxU9HgKG3aY4ICe3C7dkDOAkmcOpTbkhZgWVGXDrKw9rt-qO-g4KkPiaMWSx1CR28Q9ajZajQ9O3vzT6kHxjjJUz9DThf08G3V2FS-D9iJRh299i3VJO0Au7tc) [9].\n*   **Human-in-the-Loop:** LangGraph supports incorporating human intervention and oversight into agent workflows, which is crucial for complex or sensitive applications [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=2) [11].\n\n### Setting Up and Supporting Frameworks\n\nTo set up a LangGraph agent with Gemini models, you typically need to:\n1.  Install necessary packages: `pip install langgraph langchain-google-genai python-dotenv` [ubos](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx1RAAvUKSuVJjH9gfvFtjmKgvnKWlhGiaXXyqDvt6NJZoNo47sjt7HolaUg9IBbBF-sB0fycf9vz2s4tTw6k7Vgy6D_Q6jFUewNO8MT88l-1VgBiY5JAgcI-uE36xmq0pU3n-Og2MEXjir-l1TdVI1sgMHiIeTsriwQBD0dma--Hk4psXR5y5rYui2YOlEQzTqmumGdDo8YKz) [2].\n2.  Import essential modules, including `ChatGoogleGenerativeAI` for Gemini interaction and `StateGraph` for state management [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHpv5J4jgfQ2fp5z59nugTSmEQDrRkEyJ6F07UAqmx6r_FwERzTNWb_FAmeyzrntLYgzAXy3nD9npmGvJs4SFgZ54VdOtTzXn1STp2UQtUWzOVfKeNYeHOKrTlBEbr2HyksJuEx2_YXF9ZWLEvjZvmXpk9G2tAZDgtQ2A_f78QZoVeBEOSg5clwMqMXvKlXaDeV5_M5764pYwhSOcgxWL-HYnovn3SFkv7V846Lh0O6Gw3xXPnI1uRfSOtYbOPxE4RVtMCeb18=) [3].\n3.  Define the agent's state and workflow using a dataclass to track key fields [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHpv5J4jgfQ2fp5z59nugTSmEQDrRkEyJ6F07UAqmx6r_FwERzTNWb_FAmeyzrntLYgzAXy3nD9npmGvJs4SFgZ54VdOtTzXn1STp2UQtUWzOVfKeNYeHOKrTlBEbr2HyksJuEx2_YXF9ZWLEvjZvmXpk9G2tAZDgtQ2A_f78QZoVeBEOSg5clwMqMXvKlXaDeV5_M5764pYwhSOcgxWL-HYnovn3SFkv7V846Lh0O6Gw3xXPnI1uRfSOtYbOPxE4RVtMCeb18=) [2, 3].\n4.  Configure the Gemini model with desired settings (version, temperature, max output tokens) [10, 11].\n5.  Define and instantiate tools the agent can use [10].\n6.  Customize the prompt template to guide the agent's behavior and orchestrate the workflow by defining nodes and edges [10].\n7.  Access Google AI models, requiring a Google Account and a Google AI API key [langchain](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHfr_T5S_BDF_NO8bMd5fszd3exisQz8j6aH8olxRVtlIYpFEmuJliTujeriAtVxHan-CUmtXherblPnPiTWTZ11diJc26p2P7EZpjMEqwJm_f3Tpo2T8pMrFDkZL68r7m6J5nuZTFcSDH0sFwB49fDbzhEbMC5ZpMigQ4P6tTh8Ikmoto=) [7].\n\nSupporting frameworks and tools include:\n*   **LangChain:** Provides utilities to chain together LLM calls and external data sources [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGlLcJk-j2I5AbMnP4SNQqic6NYMCJKi_5FRkWByuz8_oemFLtc4V_dHwRePkGEzPAkkI4RunZ6VUk5024qiWZpZT_DHoBxcYCpigAz3qP4Ou_Lgigcj0Ufo-MV93fLGn8coACIPYVtr7tNP4f6cWQ6fvRhfZbV73slWo_vcTRxmM3iqvbaU3HiDz1nM6FLcOVSNrfaIFv9cNhqXDEPrCF2jAjKz95mi2syHolVUrEXZxs4) [6].\n*   **Agent Development Kit (ADK):** A new open-source framework from Google designed to simplify the full-stack, end-to-end development of agents and multi-agent systems [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE5HgrK8nj4KMKRsSsbJNmVwIXC04cAa6fqN5aeeCjKx5lHvoV-N2YarqDv9EymXK0uv2iWZu2jaN3dyGbGMfKiKfmnDVK_EPeqaG37ZsgR_tOnpxITbEDkXb5uzl8dUFvLAX9McFMATQ4Am3sakmPPdYGVGL4KII6Yl3LQbSARwpccia1KjegvPLrCTdrqC4djGHPHZwIgeVUU0QpG) [6, 14].\n*   **LiteLLM:** Allows integration with a wide selection of models from various providers beyond Google, such as Anthropic, Meta, Mistral AI, and AI21 Labs [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE5HgrK8nj4KMKRsSsbJNmVwIXC04cAa6fqN5aeeCjKx5lHvoV-N2YarqDv9EymXK0uv2iWZu2jaN3dyGbGMfKiKfmnDVK_EPeqaG37ZsgR_tOnpxITbEDkXb5uzl8dUFvLAX9McFMATQ4Am3sakmPPdYGVGL4KII6Yl3LQbSARwpccia1KjegvPLrCTdrqC4djGHPHZwIgeVUU0QpG) [14].\n\nBy leveraging these capabilities, developers can build highly sophisticated and adaptable AI applications with Google Gemini models and LangGraph."
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enter follow-up prompt"
      ],
      "metadata": {
        "id": "uKqlc4edePtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = \"Expand on usecases for Financial Services\""
      ],
      "metadata": {
        "id": "-qntJhATSk_n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = graph.invoke({\"messages\": state[\"messages\"] + [{\"role\": \"user\", \"content\": prompt2}]})\n",
        "Markdown(state[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "SED58dPXSpeX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f92ffd49-aacf-4f49-8757-bb024e76e1f7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "LangGraph, an extension of LangChain, provides a robust framework for developing stateful, multi-actor applications powered by Large Language Models (LLMs), including Google's Gemini models [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGstQdA0G2NyxK6qUIW_vpur4t1Hgws_-BBGtChcA31WONzZsUmD1HqLVLRLGVZ3FlfCXofkY_xZjvCItpgpMJRqxCujbqUqvWWNAQ5qnJlPuKYCinAK2N5TDbEwWRN45t0WFY47ISa94DIltgD3-iJFZxGK-ajW_QEZAsoEWP3qrYHRSS3Dwl7-SOxDXM-WAuTMcz6Qg==) [huggingface](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvmt16SMtPU94AGZM_itbIt0Tr9h1xwoyIGpQC5D2zWuU54W02gicL4wcKcvnDYsln0wi8tz-LS_YzZ0x9FwQPeWoeQIPslIcfZ_rx5hdRXbaJESjyOl4RBIwHQutMcQp-frlBv6Bhv7qJc72dkxVds2yCzG8w_Qk8EsPl8L_Q8RE=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHJNK6udwSk_6juzloBhem_FucJpnHusQwZmqJ22mlAXNoJib4KdGXaF7T6KN-etYm1xve1TRwDX1klAl-OkmVYdeozJLy6a_C5I3DxMZ4hd8GYekjgDtHsI8c1pWSvAhxp7YWUFuhbraQIHE4H40E) [1, 5]. It models workflows as graphs, where each node represents a step (e.g., an LLM call or tool execution) and edges define the flow of control [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGstQdA0G2NyxK6qUIW_vpur4t1Hgws_-BBGtChcA31WONzZsUmD1HqLVLRLGVZ3FlfCXofkY_xZjvCItpgpMJRqxCujbqUqvWWNAQ5qnJlPuKYCinAK2N5TDbEwWRN45t0WFY47ISa94DIltgD3-iJFZxGK-ajW_QEZAsoEWP3qrYHRSS3Dwl7-SOxDXM-WAuTMcz6Qg==) [1, 5]. This graph-based approach is particularly beneficial for complex, stateful workflows that require clear visibility and control over an agent's reasoning process [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGstQdA0G2NyxK6qUIW_vpur4t1Hgws_-BBGtChcA31WONzZsUmD1HqLVLRLGVZ3FlfCXofkY_xZjvCItpgpMJRqxCujbqUqvWWNAQ5qnJlPuKYCinAK2N5TDbEwWRN45t0WFY47ISa94DIltgD3-iJFZxGK-ajW_QEZAsoEWP3qrYHRSS3Dwl7-SOxDXM-WAuTMcz6Qg==) [1].\n\nIn the financial services sector, AI, including LLMs like Gemini, is increasingly integrated to transform operations and decision-making [aalpha](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG63zq4norX-hlgO3Xb9KOeim62y6DNLqzCp2b-kxhhEEPd7yHmnbR-NlPJEZnqkbOtT-DB36YnOxpRhiB3ZAuU5FIFrvELzb8DMmeTNZsGZ7XZH4r-zQndOXKjCyCKls2NMvyWCM3_Gx1m9iXhpNyb4yoSxpIX). LangGraph, often used with LangChain, provides the framework for building AI agent workflows, enabling more flexible and efficient AI application management in this domain [gocodeo](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE0tO3B64jjzugo1EGYjrFiAIgrtO-gLT9O49KSX-xb_GOcYNDZzpn7gDdCXcxppn8xvkJgcahpiFi5NbXa0jbVlvGO4hiB4oCXkmVfowqyOzDFVd5pjgaJbvnffo9sZsAcM4H6i4u83us4OoNZ5IjTZGOOC-q8Kt_ngn2XuWQI_5FSowEULPcNH3HWkFizOakbwhj93Q_hJ20=) [coursera](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFDtU8Sv7YYpO-kkZhqHsI2wdMZhD3oA953Hc_gVCGOJrZ98h6PkoKj_QH3zCpHwmnxX2bifYj19Etm8rVKa4cfJXWmxJbNJX5SVPkYE_SzFNx1zBG9XWMmRv7P19l5XGv7z7pNnw==).\n\nHere are detailed use cases that can leverage LangGraph with Google Gemini models in financial services:\n\n### Core Concepts Enabling Financial Use Cases\n\nLangGraph's design facilitates sophisticated AI applications through its fundamental components:\n*   **State:** A shared data structure (often a TypedDict or Pydantic BaseModel) that maintains the application's current snapshot, persisting across different nodes in a workflow [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGp1wwnv1OYMUuBXqO7VKXvq3dGMf0knV6Qhl8apFr1y6sTCkwmlA9YereGAQvr6cfd5DkSqePZJZCJXnoNECu1I0e2LsozuOxNPw8f0nxS_PVLeK3u08M_zyHh-sYJsSqWG38WWIEWRsJp6VV0JawH_oQRJJo=) [1, 4]. This is crucial for maintaining context in long-running financial processes.\n*   **Nodes:** These encapsulate the logic of individual agents or steps within the workflow. Nodes receive the current State as input, perform computations (such as LLM calls or tool invocations), and return an updated State [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGp1wwnv1OYMUuBXqO7VKXvq3dGMf0knV6Qhl8apFr1y6sTCkwmlA9YereGAQvr6cfd5DkSqePZJZCJXnoNECu1I0e2LsozuOxNPw8f0nxS_PVLeK3u08M_zyHh-sYJsSqWG38WWIEWRsJp6VV0JawH_oQRJJo=) [1, 4].\n*   **Edges:** Edges dictate the flow of control, defining which node executes next based on the current State. This allows for both fixed transitions and dynamic, conditional logic [1, 2, 4]. This enables complex decision trees common in finance.\n\nThese components enable several powerful architectural patterns for financial applications:\n*   **AI Agents:** LangGraph, combined with Gemini models, forms a strong foundation for building AI agents capable of perceiving their environment, making decisions, and executing actions to achieve specific goals [googleblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGstQdA0G2NyxK6qUIW_vpur4t1Hgws_-BBGtChcA31WONzZsUmD1HqLVLRLGVZ3FlfCXofkY_xZjvCItpgpMJRqxCujbqUqvWWNAQ5qnJlPuKYCinAK2N5TDbEwWRN45t0WFY47ISa94DIltgD3-iJFZxGK-ajW_QEZAsoEWP3qrYHRSS3Dwl7-SOxDXM-WAuTMcz6Qg==) [ubos](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx1RAAvUKSuVJjH9gfvFtjmKgvnKWlhGiaXXyqDvt6NJZoNo47sjt7HolaUg9IBbBF-sB0fycf9vz2s4tTw6k7Vgy6D_Q6jFUewNO8MT88l-1VgBiY5JAgcI-uE36xmq0pU3n-Og2MEXjir-l1TdVI1sgMHiIeTsriwQBD0dma--Hk4psXR5y5rYui2YOlEQzTqmumGdDo8YKz) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHOa4cCbkDSMCEZpMRXQ15l0f_zal1Cz7G2WC-GZYKXXk5XQw0KsHooVpYpMFeTlccvQ_yrCMmORnWW2Qu1U3ftX3VBbdA6eafpGWfsC_M3KULUR5Bc8iD90k1wC5uKHgszYq1pONz1CdT-IhvmREx68FvnpAQ=) [1].\n*   **Stateful Workflows:** LangGraph and Gemini models structure AI reasoning into stateful workflows, allowing an incoming query to progress through a series of nodes for tasks like routing, analysis, research, response generation, and validation [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHpv5J4jgfQ2fp5z59nugTSmEQDrRkEyJ6F07UAqmx6r_FwERzTNWb_FAmeyzrntLYgzAXy3nD9npmGvJs4SFgZ54VdOtTzXn1STp2UQtUWzOVfKeNYeHOKrTlBEbr2HyksJuEx2_YXF9ZWLEvjZvmXpk9G2tAZDgtQ2A_f78QZoVeBEOSg5clwMqMXvKlXaDeV5_M5764pYwhSOcgxWL-HYnovn3SFkv7V846Lh0O6Gw3xXPnI1uRfSOtYbOPxE4RVtMCeb18=) [ubos](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx1RAAvUKSuVJjH9gfvFtjmKgvnKWlhGiaXXyqDvt6NJZoNo47sjt7HolaUg9IBbBF-sB0fycf9vz2s4tTw6k7Vgy6D_Q6jFUewNO8MT88l-1VgBiY5JAgcI-uE36xmq0pU3n-Og2MEXjir-l1TdVI1sgMHiIeTsriwQBD0dma--Hk4psXR5y5rYui2YOlEQzTqmumGdDo8YKz) [2, 3].\n*   **ReAct Agents:** LangGraph is particularly well-suited for constructing ReAct (Reasoning and Acting) Agents, which combine LLM reasoning with action execution, iteratively thinking, using tools, and acting on observations to dynamically adapt and achieve user goals [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGk3U4LFwGzRE509Ya98ghoYuI7ooo5planG5atbjq6P62m0swaoH1mspiuBkTOnCo3p3F09OtvOr8TBtjcoK_fTskXnk1ccKtpDDeU74yjvCiNz-WzFL2VWHl9Bk6K7dIFZxaPhYFThyzgCxeP5yjsr6I=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHOa4cCbkDSMCEZpMRXQ15l0f_zal1Cz7G2WC-GZYKXXk5XQw0KsHooVpYpMFeTlccvQ_yrCMmORnWW2Qu1U3ftX3VBbdA6eafpGWfsC_M3KULUR5Bc8iD90k1wC5uKHgszYq1pONz1CdT-IhvmREx68FvnpAQ=) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [huggingface](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH69nCSvxyR6rjSd4enlgbupDmKMNBZ4tFFf_WDNomOdWCxP32s1BltCF_8U4maHtyfoJcL2tSPl5gdaNMulHv9-DQR55Pz1Zuvfa8EDlHzJp27VZCmNwQet1LPRLKkcGmuAGg_fzShLqonlmnhZGcXfDNK-uHDOoF6ajDyBE0YKYU=) [4, 9].\n*   **Multi-Agent Systems:** LangGraph simplifies the development of multi-agent systems by enabling the definition of agents with specific roles and goals, and then assigning tasks to them [1]. This is highly relevant for complex financial workflows.\n\n### Key Use Cases in Financial Services\n\nLangGraph with Google Gemini models can be applied to a wide array of complex scenarios within the financial sector:\n\n*   **Financial Data Analysis and Trading:**\n    *   LangGraph can orchestrate agents to analyze large financial datasets and execute trades based on predefined criteria [coursera](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFDtU8Sv7YYpO-kkZhqHsI2wdMZhD3oA953Hc_gVCGOJrZ98h6PkoKj_QH3zCpHwmnxX2bifYj19Etm8rVKa4cfJXWmxJbNJX5SVPkYE_SzFNx1zBG9XWMmRv7P19l5XGv7z7pNnw==) [coursera](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGAjhC6WZz8iCs8ijFyRNH2gqyR7pfqAbS7hwiQqb9TQvN-mx3XSeYA_d9CTPxJ1-qfj-y9lXFlKlDL50kpFr33HL1zhj-KBwm2pnBsOnnBgsa6uNd2Z8DcfQ39e5THC-HU8Z8E8mc=).\n    *   Agents can identify trends and patterns in real-time market data [coursera](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFDtU8Sv7YYpO-kkZhqHsI2wdMZhD3oA953Hc_gVCGOJrZ98h6PkoKj_QH3zCpHwmnxX2bifYj19Etm8rVKa4cfJXWmxJbNJX5SVPkYE_SzFNx1zBG9XWMmRv7P19l5XGv7z7pNnw==) [coursera](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGAjhC6WZz8iCs8ijFyRNH2gqyR7pfqAbS7hwiQqb9TQvN-mx3XSeYA_d9CTPxJ1-qfj-y9lXFlKlDL50kpFr33HL1zhj-KBwm2pnBsOnnBgsa6uNd2Z8DcfQ39e5THC-HU8Z8E8mc=).\n    *   Gemini models can gauge market sentiment by analyzing news, social media, and financial reports to anticipate market movements [coursera](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFDtU8Sv7YYpO-kkZhqHsI2wdMZhD3oA953Hc_gVCGOJrZ98h6PkoKj_QH3zCpHwmnxX2bifYj19Etm8rVKa4cfJXWmxJbNJX5SVPkYE_SzFNx1zBG9XWMmRv7P19l5XGv7z7pNnw==) [coursera](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGAjhC6WZz8iCs8ijFyRNH2gqyR7pfqAbS7hwiQqb9TQvN-mx3XSeYA_d9CTPxJ1-qfj-y9lXFlKlDL50kpFr33HL1zhj-KBwm2pnBsOnnBgsa6uNd2Z8DcfQ39e5THC-HU8Z8E8mc=).\n    *   AI-driven insights can lead to better investment decisions [analyticsvidhya](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEK9dxXEvu9NDeG3dwkAkmHaOivSdfXE8jIuyCcPL5rJg0SBfaRyKDirvcqmQr-_FronBbrDdmoc2y4Sm1UoZ8EVdIhXwtzL6MNrukPX-tzfz6qNjt9bMOIAH3sNYJmHYFV9-JpGvS51StHHXcfZHxmz_0K7Oy5HYPZHUFvmFqtxmA-9Yyjs-_KfsM=) [spendesk](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH724jeNIi_tHhYgF9zAF6_geiUXDK6N5nMXl__rQt4Ycbu78Pa60S5EmqXOiuL4ZH6LvOlAUdSjsrk_1Lp-2KIA5ni0n_ODzg46l2QCdObfOG4DxhgQRMBSLNBubH27X2RFxplI9lKbbmrHaJBeJzY5vYAdrM1OA==).\n    *   LangGraph enables algorithmic trading with explainable AI for transparency and risk management [spendesk](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH724jeNIi_tHhYgF9zAF6_geiUXDK6N5nMXl__rQt4Ycbu78Pa60S5EmqXOiuL4ZH6LvOlAUdSjsrk_1Lp-2KIA5ni0n_ODzg46l2QCdObfOG4DxhgQRMBSLNBubH27X2RFxplI9lKbbmrHaJBeJzY5vYAdrM1OA==). Gemini 2.5 Pro's \"Deep Think\" capabilities can enhance reasoning for complex trading strategies [revolgy](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE0tO3B64jjzugo1EGYjrFiAIgrtO-gLT9O49KSX-xb_GOcYNDZzpn7gDdCXcxppn8xvkJgcahpiFi5NbXa0jbVlvGO4hiB4oCXkmVfowqyOzDFVd5pjgaJbvnffo9sZsAcM4H6i4u83us4OoNZ5IjTZGOOC-q8Kt_ngn2XuWQI_5FSowEULPcNH3HWkFizOakbwhj93Q_hJ20=2).\n\n*   **Customer Service and Robo-Advisors:**\n    *   AI-driven chatbots can provide instant, personalized financial advice and customer support [arya](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFXzvRD8N3oAv4CT5T5H4ujvz3TD4COjJipGyhUX_6KkqqNbLbXbM4tXiYpX40xU0adK56TZ7RoNA3Z2qatTXi65uiQbVZeaDr1Md_qZZojiglO9fxA5AP3RwYTxNoRBoQTAdabm5w8V4KCj4DSaPnyiToOELY2Nm3SMcpXXi5Tv-nSXOp8eOg=).\n    *   Robo-advisors can assess risk, adjust portfolios, and explain decisions, with LangGraph managing the state and flow of these interactions [so-development](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFnUAO6EyPnQ1lr6V2WWOGfiJKLa1Ib3Hn03O5P8aPsvJKdkZWUJCgYTjvV1wFb0SQjSbX_EX3gTNGSdzoli50xF5ZwWDoO_0ALjtBcAAwOQtbqzi4ffqxerg9mZhJapt2GTHHviXSbR3Dyvf2EYaGG94W_Z54Yl0QljttPy1PiKbZat9jY1vn5PfknIGZB4A1UcuQ3L_xHMxATRwEY).\n    *   These systems can create personalized customer journeys [spendesk](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH724jeNIi_tHhYgF9zAF6_geiUXDK6N5nMXl__rQt4Ycbu78Pa60S5EmqXOiuL4ZH6LvOlAUdSjsrk_1Lp-2KIA5ni0n_ODzg46l2QCdObfOG4DxhgQRMBSLNBubH27X2RFxplI9lKbbmrHaJBeJzY5vYAdrM1OA==).\n\n*   **Risk Management and Fraud Detection:**\n    *   LangGraph facilitates predictive risk management by orchestrating agents that analyze vast amounts of market data and economic indicators [spendesk](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH724jeNIi_tHhYgF9zAF6_geiUXDK6N5nMXl__rQt4Ycbu78Pa60S5EmqXOiuL4ZH6LvOlAUdSjsrk_1Lp-2KIA5ni0n_ODzg46l2QCdObfOG4DxhgQRMBSLNBubH27X2RFxplI9lKbbmrHaJBeJzY5vYAdrM1OA==) [coursera](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGAjhC6WZz8iCs8ijFyRNH2gqyR7pfqAbS7hwiQqb9TQvN-mx3XSeYA_d9CTPxJ1-qfj-y9lXFlKlDL50kpFr33HL1zhj-KBwm2pnBsOnnBgsa6uNd2Z8DcfQ39e5THC-HU8Z8E8mc=).\n    *   It can be used to detect and prevent fraudulent activities [devoteam](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFOldk9T21-SFTcGTTNlrXdkmo0Fk-Plxl7qCKHyQi2a0NwMBbxw_fRITPpNa9uViv6LXNdlMqJC5TT9Opun9m5vA50hQ3C8sdO59fBTj4ivMTGUVWIvqFm3pstxcOWibAIEaxc9Wad8OyaQQAtJ5z1bJrh5toqo7u9) [lyzr](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGxKlyOPucCke49bqg1Ayk67TXlToFM4W5bZ_wPSisia65miqixE-416hw3dU7A_NAhbsar33v6WrSvqY1XnyPvPCXCTDC2BNhdPlQ7v1AXjFM-6LO0DsPerKhnUYfuA9NY).\n    *   Compliance monitoring, tracking insider trades, and reporting suspicious activity can be streamlined [so-development](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFnUAO6EyPnQ1lr6V2WWOGfiJKLa1Ib3Hn03O5P8aPsvJKdkZWUJCgYTjvV1wFb0SQjSbX_EX3gTNGSdzoli50xF5ZwWDoO_0ALjtBcAAwOQtbqzi4ffqxerg9mZhJapt2GTHHviXSbR3Dyvf2EYaGG94W_Z54Yl0QljttPy1PiKbZat9jY1vn5PfknIGZB4A1UcuQ3L_xHMxATRwEY).\n    *   AI-driven credit scoring and underwriting can also leverage these capabilities [aalpha](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG63zq4norX-hlgO3Xb9KOeim62y6DNLqzCp2b-kxhhEEPd7yHmnbR-NlPJEZnqkbOtT-DB36YnOxpRhiB3ZAuU5FIFrvELzb8DMmeTNZsGZ7XZH4r-zQndOXKjCyCKls2NMvyWCM3_Gx1m9iXhpNyb4yoSxpIX).\n\n*   **Automation and Efficiency:**\n    *   Automating data processing and financial operations, including data entry, removing duplicates, and ensuring accuracy [lyzr](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGxKlyOPucCke49bqg1Ayk67TXlToFM4W5bZ_wPSisia65miqixE-416hw3dU7A_NAhbsar33v6WrSvqY1XnyPvPCXCTDC2BNhdPlQ7v1AXjFM-6LO0DsPerKhnUYfuA9NY) [arya](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFXzvRD8N3oAv4CT5T5H4ujvz3TD4COjJipGyhUX_6KkqqNbLbXbM4tXiYpX40xU0adK56TZ7RoNA3Z2qatTXi65uiQbVZeaDr1Md_qZZojiglO9fxA5AP3RwYTxNoRBoQTAdabm5w8V4KCj4DSaPnyiToOELY2Nm3SMcpXXi5Tv-nSXOp8eOg=) [f9finance](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE9rW3xuvrHfSrhP9k9cG8SS7b13qkkJf_TrFjI-_ZSDvVLoXDJH6Q17drsoLCl2_-c9mI5mUE3C7MiOfQ7UlaFT5TYV1BVBRqRqK3DpWpQPoGbzhpGOsB13I97J7TGIjDgIQTULj561kSbXuoAHC0=).\n    *   Automating financial reporting and generating comprehensive reports using preset templates [arya](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFXzvRD8N3oAv4CT5T5H4ujvz3TD4COjJipGyhUX_6KkqqNbLbXbM4tXiYpX40xU0adK56TZ7RoNA3Z2qatTXi65uiQbVZeaDr1Md_qZZojiglO9fxA5AP3RwYTxNoRBoQTAdabm5w8V4KCj4DSaPnyiToOELY2Nm3SMcpXXi5Tv-nSXOp8eOg=) [f9finance](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE9rW3xuvrHfSrhP9k9cG8SS7b13qkkJf_TrFjI-_ZSDvVLoXDJH6Q17drsoLCl2_-c9mI5mUE3C7MiOfQ7UlaFT5TYV1BVBRqRqK3DpWpQPoGbzhpGOsB13I97J7TGIjDgIQTULj561kSbXuoAHC0=).\n    *   Streamlining compliance processes and improving regulatory reporting [devoteam](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFOldk9T21-SFTcGTTNlrXdkmo0Fk-Plxl7qCKHyQi2a0NwMBbxw_fRITPpNa9uViv6LXNdlMqJC5TT9Opun9m5vA50hQ3C8sdO59fBTj4ivMTGUVWIvqFm3pstxcOWibAIEaxc9Wad8OyaQQAtJ5z1bJrh5toqo7u9) [spendesk](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH724jeNIi_tHhYgF9zAF6_geiUXDK6N5nMXl__rQt4Ycbu78Pa60S5EmqXOiuL4ZH6LvOlAUdSjsrk_1Lp-2KIA5ni0n_ODzg46l2QCdObfOG4DxhgQRMBSLNBubH27X2RFxplI9lKbbmrHaJBeJzY5vYAdrM1OA==).\n    *   Automated bookkeeping and invoicing [aalpha](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG63zq4norX-hlgO3Xb9KOeim62y6DNLqzCp2b-kxhhEEPd7yHmnbR-NlPJEZnqkbOtT-DB36YnOxpRhiB3ZAuU5FIFrvELzb8DMmeTNZsGZ7XZH4r-zQndOXKjCyCKls2NMvyWCM3_Gx1m9iXhpNyb4yoSxpIX).\n\n*   **Customer Onboarding and KYC/AML Processes:**\n    *   AI agents can validate identity documents, cross-check user data against PEP/sanction lists, and flag high-risk profiles during onboarding [aalpha](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHoO5SMDDnUio3HUxRUoDNYbBe_I-ggIydazuWCBW-0o4_icyOXbdhxyBlgqiJhLpFemv97Hjngwtfu7jB8ujXD4r38QyMadVdPhJ4FSJAZMwEHZmRVnnh6iA4APkLHDsW-xulVWVwsNJJPRpgotudosrGGjtH-aA==) [lyzr](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEbwQnK_j167d88_A-u3Rd2DbwDwoT55jprxUT8oBXaC_RnefROUQml3hdUvttujzn9RVCK_uw_Inpf7Mavrr63a-VICJzO4IRASWkbHC2SUCUdtMNlG-efPXZTCzC7Mg2f).\n    *   LangGraph's multi-stage processing and conditional edges are ideal for guiding customers through complex verification steps based on their risk profile.\n\n*   **Investment Research:**\n    *   AI agents can analyze vast amounts of financial data to identify investment opportunities [researchgate](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFmYsmRpRja7n97iDNVmWzihx65Ar43cDS-xt99BjrMzPWK-iLC9wSpopZd4gh7Aknd_sdAPYVuUBHjtcn1fzmAZ8-fgNj13aH19RyLNnrQvubDg5UtsZj35lTC-IB6io-zK3rtxAlR11HdKEjbopj1U6kIsC-lW15klqa2iggqV2wjZUr4VBmsTOy8pa19lp0eWP0G3nMVPa5HwftMfxejaazMXfs5DhKO5MzBM1GmZmlI3dnnPuVfmT_PXBvZuQg9civiRGkZKfj-OrPfMtg_DDlSwge7vQSKRSJj5J659XBIc0s=).\n    *   LangGraph enables the creation of systems that scale insight generation and make services available to more clients [youtube](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGNcy9DD3ULlDV0tr1HDP0_3aLJZsTCz_H6e5qC7atxzKnTNKxhoB4YBwLLbypGnTf8bSZAWhNpEXRLPOJTBVj8xKwS_w-z31lIqaU1Svp3JOMpqHItJoT6Am10p6KyAn0yXpaQDFY=).\n    *   Gemini can aid in interpreting financial statements by automating data extraction and generating concise summaries [skillfine](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEA0RIlJD8Rqt8oEhGaL4Da4O1DKWNhfjLbU8yl0eBvwXEPjBkiETfCrFqLFPOmHzASUsclnowuX3Fz7PgXAlYvwGUM4DSqjKqzCDPcXvuH0GEqy3s4Q0cayjIHyb85EW_qjNzFrpdf7IGIQHoo0glrLMRsWpg7rQ==].\n\n*   **Multimodal Agents:**\n    *   LangGraph can be combined with Gemini to create multimodal agents capable of detecting objects in images, audio, and video [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE0tO3B64jjzugo1EGYjrFiAIgrtO-gLT9O49KSX-xb_GOcYNDZzpn7gDdCXcxppn8xvkJgcahpiFi5NbXa0jbVlvGO4hiB4oCXkmVfowqyOzDFVd5pjgaJbvnffo9sZsAcM4H6i4u83us4OoNZ5IjTZGOOC-q8Kt_ngn2XuWQI_5FSowEULPcNH3HWkFizOakbwhj93Q_hJ20=4) [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH8rvFr8qV0VwKCQyFWZgRcqVhTUpVGgfhC356sydoILM4WhYCXjUseegWVBKYke3AHsre7sLUKVMuq1F9t87qNgkvhxQm30p5dwUtjOepqNmH5tE6W-14xLFBYR9Bm4umT-loqzULot1NEngj-96G-QnLT5iWjPJ-jgQuADT_xeGxutV4lNBHJMhTCl5Z1sz6p1ktLGIe98iVrxp_nBLBX0jjZ-6fmFlO8JOAjjxaf22w=). This is valuable for financial applications like document verification (e.g., scanning IDs for KYC) or analyzing multimedia for compliance.\n\n*   **Tool Integration:**\n    *   Gemini models' function calling capabilities allow LangGraph agents to interact seamlessly with external tools, APIs, and data sources, enabling them to perform real-world actions. This includes integrating tools for web scraping, search, and specialized APIs for domains like finance (e.g., Yahoo Finance) [marktechpost](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE0tO3B64jjzugo1EGYjrFiAIgrtO-gLT9O49KSX-xb_GOcYNDZzpn7gDdCXcxppn8xvkJgcahpiFi5NbXa0jbVlvGO4hiB4oCXkmVfowqyOzDFVd5pjgaJbvnffo9sZsAcM4H6i4u83us4OoNZ5IjTZGOOC-q8Kt_ngn2XuWQI_5FSowEULPcNH3HWkFizOakbwhj93Q_hJ20=2) [creolestudios](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH8rvFr8qV0VwKCQyFWZgRcqVhTUpVGgfhC356sydoILM4WhYCXjUseegWVBKYke3AHsre7sLUKVMuq1F9t87qNgkvhxQm30p5dwUtjOepqNmH5tE6W-14xLFBYR9Bm4umT-loqzULot1NEngj-96G-QnLT5iWjPJ-jgQuADT_xeGxutV4lNBHJMhTCl5Z1sz6p1ktLGIe98iVrxp_nBLBX0jjZ-6fmFlO8JOAjjxaf22w=).\n\n### Practical Implementation Details\n\nWhen building LangGraph agents with Gemini for financial services, several practical aspects are key:\n*   **Node Configurations:** Common node types include `call_tool` (often using LangGraph's prebuilt `ToolNode`) for executing tool methods (e.g., financial API calls), and `call_model` for invoking the Gemini model for reasoning or generation [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGp1wwnv1OYMUuBXqO7VKXvq3dGMf0knV6Qhl8apFr1y6sTCkwmlA9YereGAQvr6cfd5DkSqePZJZCJXnoNECu1I0e2LsozuOxNPw8f0nxS_PVLeK3u08M_zyHh-sYJsSqWG38WWIEWRsJp6VV0JawH_oQRJJo=) [1].\n*   **Edge Configurations:** Edges define transitions. A `should_continue` edge can decide whether to call a tool or the model [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [philschmid](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGp1wwnv1OYMUuBXqO7VKXvq3dGMf0knV6Qhl8apFr1y6sTCkwmlA9YereGAQvr6cfd5DkSqePZJZCJXnoNECu1I0e2LsozuOxNPw8f0nxS_PVLeK3u08M_zyHh-sYJsSqWG38WWIEWRsJp6VV0JawH_oQRJJo=) [1, 4]. Conditional edges enable dynamic workflow based on node outcomes, crucial for adapting to financial market changes or customer profiles [2, 8].\n*   **State Management:** LangGraph provides helpers like `add_messages` for efficiently updating message lists within the agent's state [google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=) [1].\n*   **Human-in-the-Loop:** LangGraph supports incorporating human intervention and oversight into agent workflows [github](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyI2nJk5jlT8POmfXbVJscryUwfDqPkWpU-g8ZhDGyhz57FbsXFej79qMVodFS73Fm1CYCKL6uf_stobqMIyOwedD3d1K0SlhRkic9Fbt8wtaNoOjVcKMeYPW5lNIv0C4GZ1bIIgWQ17aC71QoCrRudXo=2) [11], which is crucial for complex or sensitive financial applications requiring expert review.\n\n### Challenges and Considerations\n\nWhile LangGraph and Gemini offer significant benefits, it's important to address challenges in financial services:\n*   **Data Privacy and Security:** Protecting sensitive customer and financial data is critical [12]. Gemini models becoming available on-premise (Google Distributed Cloud, public preview Q3 2025) can help address data residency and security concerns [capacitymedia](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE0tO3B64jjzugo1EGYjrFiAIgrtO-gLT9O49KSX-xb_GOcYNDZzpn7gDdCXcxppn8xvkJgcahpiFi5NbXa0jbVlvGO4hiB4oCXkmVfowqyOzDFVd5pjgaJbvnffo9sZsAcM4H6i4u83us4OoNZ5IjTZGOOC-q8Kt_ngn2XuWQI_5FSowEULPcNH3HWkFizOakbwhj93Q_hJ20=0) [googlecloudblog](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH8rvFr8qV0VwKCQyFWZgRcqVhTUpVGgfhC356sydoILM4WhYCXjUseegWVBKYke3AHsre7sLUKVMuq1F9t87qNgkvhxQm30p5dwUtjOepqNmH5tE6W-14xLFBYR9Bm4umT-loqzULot1NEngj-96G-QnLT5iWjPJ-jgQuADT_xeGxutV4lNBHJMhTCl5Z1sz6p1ktLGIe98iVrxp_nBLBX0jjZ-6fmFlO8JOAjjxaf22w=).\n*   **Regulatory Compliance:** Adhering to strict financial regulations is essential [spendesk](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH724jeNIi_tHhYgF9zAF6_geiUXDK6N5nMXl__rQt4Ycbu78Pa60S5EmqXOiuL4ZH6LvOlAUdSjsrk_1Lp-2KIA5ni0n_ODzg46l2QCdObfOG4DxhgQRMBSLNBubH27X2RFxplI9lKbbmrHaJBeJzY5vYAdrM1OA==).\n*   **Model Accuracy and Hallucinations:** Mitigating the risk of LLMs producing incorrect information is paramount in finance [12].\n*   **Integration Complexity:** Overcoming the complexity of integrating AI agents into existing legacy systems can be a barrier [aalpha](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG63zq4norX-hlgO3Xb9KOeim62y6DNLqzCp2b-kxhhEEPd7yHmnbR-NlPJEZnqkbOtT-DB36YnOxpRhiB3ZAuU5FIFrvELzb8DMmeTNZsGZ7XZH4r-zQndOXKjCyCKls2NMvyWCM3_Gx1m9iXhpNyb4yoSxpIX) [lyzr](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEbwQnK_j167d88_A-u3Rd2DbwDwoT55jprxUT8oBXaC_RnefROUQml3hdUvttujzn9RVCK_uw_Inpf7Mavrr63a-VICJzO4IRASWkbHC2SUCUdtMNlG-efPXZTCzC7Mg2f).\n\nIn summary, LangGraph and Google Gemini models are poised to significantly impact financial services by enabling the development of sophisticated, stateful AI agents. These agents can automate complex workflows, provide real-time insights, enhance customer experiences, and improve risk management, driving productivity and cost savings across the industry [promevo](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFJj7IDXYi_4Ro-_K-bTL50aBlS_4O2vSWepi57j3eJR6bKRwbyOesshq7wvzrb9KRNj_HMCAcmqOA0EuAOScoA7N5bUVK1lHbtnK37WDtfYv2E3A7BBY5i2ml4O8yvorKsnu6repi6rkvsidaSE36CBA==)."
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SIGiasusLeW3"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}